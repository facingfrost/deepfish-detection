{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3db6649e-8c42-4be9-b245-e68de952e289",
   "metadata": {},
   "source": [
    "# Imports and constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1ab41fd9-0c38-4a1d-a15b-23ed7e2d0d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import time\n",
    "import os\n",
    "from ultralytics import YOLO, solutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f978984e-e517-4eae-8262-fe3d3024260f",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 50\n",
    "IMG_SIZE = 640\n",
    "SLEEP = 0.1\n",
    "TRAIN_MODEL = True\n",
    "SEED = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eba26d80-85ce-46fc-ac2b-7f1dbad4e74d",
   "metadata": {},
   "source": [
    "# Train model\n",
    "\n",
    "We use `yolov8n.pt` as the starting pretrained model, and train it for `EPOCHS` epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6022c6e1-3bbb-483f-9483-b52be9fa61ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(pretrained_model: str, name: str):\n",
    "    \"\"\"\n",
    "    Procedure to train a model and persist in the `name` subdirectory.\n",
    "    `pretrained_model` indicates which version of the Yolo should be used.\n",
    "    \"\"\"\n",
    "    if TRAIN_MODEL:\n",
    "        model = YOLO(pretrained_model)\n",
    "        results = model.train(\n",
    "            data=\"data.yaml\",\n",
    "            epochs=EPOCHS,\n",
    "            imgsz=IMG_SIZE,\n",
    "            name=name,\n",
    "            exist_ok=True,\n",
    "            seed=SEED\n",
    "        )\n",
    "        # print(\"Metric:\", model.val(data='data.yaml'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01dc6e18-8f02-4f07-9a15-e610ef7350b6",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Original dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6226fc06-75f8-4a61-bd74-a18af2cbd031",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mv datasets/images/train_original datasets/images/train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1f0d484e-bf6c-451e-9d51-10a95d3ec5b1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.3.13 available üòÉ Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.2.89 üöÄ Python-3.11.2 torch-2.4.1+cu121 CUDA:0 (NVIDIA GeForce RTX 4060 Laptop GPU, 7943MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8n.pt, data=data.yaml, epochs=50, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=original, exist_ok=True, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=/home/dionisius/bdma/tue/data_challenge_3/deepfish-detection/runs/detect/original\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
      " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
      " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 22        [15, 18, 21]  1    751507  ultralytics.nn.modules.head.Detect           [1, [64, 128, 256]]           \n",
      "Model summary: 225 layers, 3,011,043 parameters, 3,011,027 gradients, 8.2 GFLOPs\n",
      "\n",
      "Transferred 319/355 items from pretrained weights\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /home/dionisius/bdma/tue/data_challenge_3/deepfish-detection/datasets/labels/train... 4568 images, 1391 backgrounds, 0 corrup\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /home/dionisius/bdma/tue/data_challenge_3/deepfish-detection/datasets/labels/train.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/dionisius/bdma/tue/data_challenge_3/deepfish-detection/datasets/labels/val.cache... 1304 images, 402 backgrounds, 0 corru\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING ‚ö†Ô∏è /home/dionisius/bdma/tue/data_challenge_3/deepfish-detection/datasets/images/val/9894_gerres_f000034_jpg.rf.077f365f7e09097b1627e75c4d237a57.jpg: 1 duplicate labels removed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to /home/dionisius/bdma/tue/data_challenge_3/deepfish-detection/runs/detect/original/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1m/home/dionisius/bdma/tue/data_challenge_3/deepfish-detection/runs/detect/original\u001b[0m\n",
      "Starting training for 50 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       1/50      2.19G      1.932      2.417      1.325         31        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 286/286 [00:38<00:00,  7.51it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 41/41 [00:04<00:00,  8.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1304       3033      0.554       0.38      0.371      0.176\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       2/50      2.19G        1.9       1.59      1.314         30        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 286/286 [00:37<00:00,  7.58it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 41/41 [00:04<00:00,  8.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1304       3033      0.726        0.6      0.643      0.297\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       3/50      2.24G      1.884      1.459       1.31         24        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 286/286 [00:38<00:00,  7.51it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 41/41 [00:04<00:00,  8.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1304       3033      0.779       0.61      0.691      0.327\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       4/50      2.24G      1.875      1.377      1.303         12        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 286/286 [\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1304       3033      0.745      0.558      0.617      0.284\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       5/50      2.23G      1.808      1.294      1.272         14        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 286/286 [\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1304       3033      0.769      0.622      0.689      0.322\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       6/50      2.23G      1.779      1.208      1.253         52        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 286/286 [\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1304       3033      0.833      0.679       0.77      0.383\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       7/50      2.21G      1.757      1.168      1.234         26        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 286/286 [\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1304       3033      0.813      0.647      0.751      0.376\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       8/50       2.2G      1.722      1.114      1.213         43        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 286/286 [\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1304       3033      0.818      0.698      0.775      0.383\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       9/50      2.18G      1.694      1.069      1.196         28        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 286/286 [\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1304       3033      0.847      0.709      0.793      0.413\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      10/50      2.18G      1.668      1.032      1.181         19        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 286/286 [\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1304       3033       0.86      0.729      0.819      0.424\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      11/50      2.21G       1.66      1.007      1.184         23        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 286/286 [\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1304       3033      0.871      0.719      0.816       0.42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      12/50       2.2G      1.638     0.9974      1.163         14        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 286/286 [\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1304       3033      0.842      0.735      0.822      0.433\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      13/50      2.23G       1.62     0.9632      1.153         56        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 286/286 [\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1304       3033      0.842      0.758      0.834       0.44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      14/50      2.18G       1.61     0.9566       1.16          9        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 286/286 [\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1304       3033      0.867      0.741      0.828      0.426\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      15/50      2.18G      1.581     0.9209      1.139         19        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 286/286 [\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1304       3033       0.88      0.781      0.852      0.463\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      16/50      2.18G      1.557     0.9072      1.136         10        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 286/286 [\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1304       3033      0.878      0.783      0.865      0.475\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      17/50       2.2G      1.575     0.8974      1.129         44        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 286/286 [\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1304       3033      0.863      0.738      0.828      0.445\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      18/50      2.21G      1.562     0.8938      1.127         27        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 286/286 [\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1304       3033       0.87      0.763      0.844      0.458\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      19/50       2.2G      1.542     0.8849      1.119         24        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 286/286 [\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1304       3033      0.878      0.792      0.858      0.474\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      20/50       2.2G      1.538     0.8666      1.116         11        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 286/286 [\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1304       3033      0.878      0.792      0.864      0.477\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      21/50      2.23G      1.515     0.8493      1.105         34        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 286/286 [\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1304       3033      0.888      0.783       0.87      0.477\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      22/50      2.29G       1.52     0.8391      1.109         45        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 286/286 [\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1304       3033      0.878      0.795      0.871      0.485\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      23/50      2.18G        1.5     0.8291      1.094         24        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 286/286 [\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1304       3033      0.881      0.816      0.882       0.49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      24/50       2.2G      1.501     0.8263      1.101         13        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 286/286 [\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1304       3033      0.891      0.816      0.884      0.489\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      25/50      2.16G      1.486     0.8011      1.091         19        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 286/286 [\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1304       3033      0.898      0.802      0.889      0.505\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      26/50      2.19G      1.456     0.7861      1.085         12        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 286/286 [\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1304       3033        0.9      0.803      0.888      0.498\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      27/50      2.18G      1.462     0.7819      1.083         39        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 286/286 [\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1304       3033      0.906      0.824      0.897      0.504\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      28/50      2.21G      1.466     0.7878      1.086         12        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 286/286 [\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1304       3033      0.901      0.813      0.894      0.511\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      29/50      2.21G      1.444     0.7673      1.074         19        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 286/286 [\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1304       3033      0.914      0.817      0.896      0.507\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      30/50       2.2G      1.434     0.7516      1.061         25        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 286/286 [\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1304       3033      0.908      0.834      0.906      0.512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      31/50      2.18G      1.424     0.7509      1.064         33        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 286/286 [\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1304       3033      0.902      0.842      0.903      0.512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      32/50      2.18G      1.414       0.74      1.062         29        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 286/286 [\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1304       3033      0.901      0.845       0.91      0.515\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      33/50      2.21G      1.404     0.7369      1.058          8        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 286/286 [\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1304       3033      0.915      0.841      0.909       0.52\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      34/50      2.18G      1.403     0.7323      1.055         16        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 286/286 [\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1304       3033        0.9      0.838      0.907      0.515\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      35/50      2.23G      1.407     0.7313      1.055         29        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 286/286 [\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1304       3033      0.919      0.842      0.915      0.527\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      36/50      2.18G      1.371     0.7136      1.048         20        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 286/286 [\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1304       3033      0.915      0.848      0.914      0.523\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      37/50      2.18G      1.378      0.707      1.049         24        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 286/286 [\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1304       3033      0.917      0.844      0.916      0.532\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      38/50      2.18G      1.375     0.7059      1.041         44        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 286/286 [\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1304       3033      0.908      0.852      0.918      0.529\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      39/50      2.16G      1.358     0.6872      1.038         25        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 286/286 [\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1304       3033      0.918      0.844      0.917      0.534\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      40/50      2.23G      1.344     0.6848      1.037          4        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 286/286 [\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1304       3033      0.925      0.859      0.923      0.541\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      41/50      2.18G      1.366     0.6693      1.052         23        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 286/286 [\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1304       3033      0.919       0.85      0.923      0.541\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      42/50      2.18G      1.347     0.6509      1.047         38        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 286/286 [\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1304       3033      0.924      0.853      0.924      0.547\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      43/50      2.18G      1.329      0.639      1.038         21        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 286/286 [\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1304       3033      0.929      0.846      0.924      0.549\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      44/50       2.2G      1.318     0.6281      1.033         10        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 286/286 [\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1304       3033      0.923       0.86      0.928       0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      45/50      2.18G        1.3     0.6175      1.027         21        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 286/286 [\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1304       3033      0.929      0.854      0.926      0.554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      46/50      2.18G      1.293     0.6155      1.027         15        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 286/286 [\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1304       3033      0.933      0.859       0.93      0.557\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      47/50      2.18G      1.288     0.6073      1.018         20        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 286/286 [\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1304       3033      0.939      0.862      0.934      0.561\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      48/50      2.17G      1.282     0.6054       1.02         22        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 286/286 [\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1304       3033      0.927      0.871      0.934      0.561\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      49/50      2.18G      1.273     0.5966      1.016         24        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 286/286 [\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1304       3033      0.927      0.868      0.935      0.564\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      50/50      2.16G      1.268     0.5922      1.012         19        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 286/286 [\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1304       3033       0.93      0.869      0.935      0.564\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "50 epochs completed in 0.588 hours.\n",
      "Optimizer stripped from /home/dionisius/bdma/tue/data_challenge_3/deepfish-detection/runs/detect/original/weights/last.pt, 6.2MB\n",
      "Optimizer stripped from /home/dionisius/bdma/tue/data_challenge_3/deepfish-detection/runs/detect/original/weights/best.pt, 6.2MB\n",
      "\n",
      "Validating /home/dionisius/bdma/tue/data_challenge_3/deepfish-detection/runs/detect/original/weights/best.pt...\n",
      "Ultralytics YOLOv8.2.89 üöÄ Python-3.11.2 torch-2.4.1+cu121 CUDA:0 (NVIDIA GeForce RTX 4060 Laptop GPU, 7943MiB)\n",
      "Model summary (fused): 168 layers, 3,005,843 parameters, 0 gradients, 8.1 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1304       3033       0.93      0.869      0.935      0.564\n",
      "Speed: 0.3ms preprocess, 2.0ms inference, 0.0ms loss, 0.2ms postprocess per image\n",
      "Results saved to \u001b[1m/home/dionisius/bdma/tue/data_challenge_3/deepfish-detection/runs/detect/original\u001b[0m\n",
      "CPU times: user 35min 54s, sys: 1min 16s, total: 37min 10s\n",
      "Wall time: 35min 32s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_model(pretrained_model=\"yolov8n.pt\", name=\"original\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9989e7c4-547c-4988-b557-72a482b4d54b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mv datasets/images/train datasets/images/train_original"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a025e3d5-d59a-45ca-a0fe-22f29ee2073b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Contrast dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "88c6e02e-6f0a-4ceb-a870-58f3c79b8c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mv datasets/images_preprocessed/contrast datasets/images/train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c35117c7-5c5b-47b3-9aaf-8d5a7c64d0c2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.3.13 available üòÉ Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.2.89 üöÄ Python-3.11.2 torch-2.4.1+cu121 CUDA:0 (NVIDIA GeForce RTX 4060 Laptop GPU, 7943MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8n.pt, data=data.yaml, epochs=50, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=contrast, exist_ok=True, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=/home/dionisius/bdma/tue/data_challenge_3/deepfish-detection/runs/detect/contrast\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
      " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
      " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 22        [15, 18, 21]  1    751507  ultralytics.nn.modules.head.Detect           [1, [64, 128, 256]]           \n",
      "Model summary: 225 layers, 3,011,043 parameters, 3,011,027 gradients, 8.2 GFLOPs\n",
      "\n",
      "Transferred 319/355 items from pretrained weights\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /home/dionisius/bdma/tue/data_challenge_3/deepfish-detection/datasets/labels/train... 456\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /home/dionisius/bdma/tue/data_challenge_3/deepfish-detection/datasets/labels/train.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/dionisius/bdma/tue/data_challenge_3/deepfish-detection/datasets/labels/val.cache... 1\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING ‚ö†Ô∏è /home/dionisius/bdma/tue/data_challenge_3/deepfish-detection/datasets/images/val/9894_gerres_f000034_jpg.rf.077f365f7e09097b1627e75c4d237a57.jpg: 1 duplicate labels removed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to /home/dionisius/bdma/tue/data_challenge_3/deepfish-detection/runs/detect/contrast/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1m/home/dionisius/bdma/tue/data_challenge_3/deepfish-detection/runs/detect/contrast\u001b[0m\n",
      "Starting training for 50 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       1/50      2.16G      2.014      2.559      1.369         31        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 286/286 [\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1304       3033      0.677      0.519      0.566      0.255\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       2/50      2.15G      1.998       1.74      1.345         30        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 286/286 [\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1304       3033      0.576      0.484      0.498      0.239\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       3/50      2.19G      1.989        1.6      1.358         24        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 286/286 [\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1304       3033      0.682      0.453      0.512      0.226\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       4/50      2.24G      1.974      1.506      1.353         12        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 286/286 [\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1304       3033      0.764      0.589      0.658      0.311\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       5/50      2.23G      1.891      1.388      1.307         14        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 286/286 [\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1304       3033      0.786      0.636      0.715      0.338\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       6/50      2.23G      1.869      1.331      1.296         52        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 286/286 [\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1304       3033      0.753      0.602      0.669      0.332\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       7/50      2.22G      1.853      1.284      1.278         26        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 286/286 [\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1304       3033      0.816      0.682      0.759      0.371\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       8/50      2.21G      1.817      1.211      1.259         43        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 286/286 [\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1304       3033      0.845      0.661      0.768      0.388\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       9/50      2.18G      1.785      1.181      1.242         28        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 286/286 [\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1304       3033      0.797      0.621      0.704      0.346\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      10/50      2.18G      1.748      1.128      1.219         19        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 286/286 [\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1304       3033      0.809      0.653      0.734      0.362\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      11/50      2.21G      1.724      1.092      1.214         23        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 286/286 [\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1304       3033      0.835      0.701      0.797       0.41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      12/50       2.2G      1.717      1.086      1.199         14        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 286/286 [\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1304       3033       0.85      0.715      0.805      0.409\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      13/50      2.23G      1.706      1.065       1.19         56        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 286/286 [\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1304       3033      0.873      0.726      0.821      0.428\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      14/50      2.18G      1.686      1.052      1.196          9        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 286/286 [\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1304       3033      0.843      0.719      0.798      0.407\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      15/50      2.18G      1.651      0.996      1.168         19        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 286/286 [\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1304       3033      0.856      0.742      0.822      0.422\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      16/50      2.19G      1.632          1      1.169         10        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 286/286 [\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1304       3033      0.845      0.739       0.82      0.417\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      17/50      2.21G      1.647      0.992      1.164         44        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 286/286 [\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1304       3033      0.856       0.76      0.838       0.45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      18/50      2.21G      1.644     0.9728      1.162         27        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 286/286 [\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1304       3033      0.882      0.755      0.841      0.447\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      19/50       2.2G      1.624     0.9701       1.16         24        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 286/286 [\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1304       3033      0.865      0.766      0.844      0.445\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      20/50       2.2G      1.617     0.9396      1.148         11        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 286/286 [\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1304       3033      0.873      0.763      0.836      0.453\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      21/50      2.23G      1.591     0.9309      1.139         34        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 286/286 [\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1304       3033      0.875      0.772      0.851      0.458\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      22/50      2.29G      1.602     0.9232      1.144         45        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 286/286 [\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1304       3033      0.894      0.773      0.857      0.464\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      23/50      2.18G      1.563     0.9006      1.122         24        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 286/286 [\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1304       3033      0.886      0.784      0.861      0.466\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      24/50       2.2G      1.567     0.8905      1.132         13        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 286/286 [\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1304       3033      0.888      0.783      0.866      0.469\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      25/50      2.16G      1.566      0.883      1.128         19        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 286/286 [\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1304       3033      0.877      0.788      0.861       0.47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      26/50      2.19G      1.532     0.8629      1.116         12        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 286/286 [\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1304       3033      0.877      0.797      0.871      0.476\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      27/50      2.18G      1.532     0.8555      1.113         39        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 286/286 [\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1304       3033      0.878      0.794       0.86      0.465\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      28/50      2.21G      1.541     0.8653      1.116         12        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 286/286 [\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1304       3033      0.894      0.795      0.877      0.484\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      29/50      2.21G      1.515     0.8451      1.106         19        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 286/286 [\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1304       3033      0.902        0.8      0.878      0.493\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      30/50       2.2G      1.501     0.8207      1.092         25        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 286/286 [\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1304       3033      0.898      0.806      0.878      0.488\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      31/50      2.18G      1.506     0.8217        1.1         33        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 286/286 [\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1304       3033        0.9      0.805      0.876      0.485\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      32/50      2.18G      1.489     0.8151      1.092         29        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 286/286 [\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1304       3033      0.907      0.805      0.881      0.491\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      33/50      2.21G      1.477     0.8122      1.087          8        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 286/286 [\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1304       3033      0.904      0.809      0.882      0.493\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      34/50      2.18G      1.474     0.8006      1.084         16        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 286/286 [\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1304       3033      0.908      0.825      0.893      0.499\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      35/50      2.23G      1.471     0.7941      1.084         29        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 286/286 [\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1304       3033      0.908      0.817      0.891      0.502\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      36/50      2.18G      1.453     0.7831       1.08         20        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 286/286 [\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1304       3033       0.91      0.806      0.884      0.498\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      37/50      2.18G      1.444     0.7682      1.074         24        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 286/286 [\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1304       3033      0.909      0.822      0.894      0.505\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      38/50      2.18G      1.443     0.7708      1.069         44        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 286/286 [\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1304       3033      0.915      0.814      0.893      0.508\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      39/50      2.16G      1.428      0.752      1.065         25        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 286/286 [\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1304       3033      0.911      0.828      0.893      0.503\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      40/50      2.23G      1.408     0.7525       1.06          4        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 286/286 [\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1304       3033      0.918      0.823      0.899      0.512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      41/50      2.18G      1.436     0.7367      1.083         23        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 286/286 [\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1304       3033      0.923      0.823      0.902      0.514\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      42/50      2.18G      1.407     0.7112      1.072         38        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 286/286 [\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1304       3033      0.919      0.832      0.904      0.522\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      43/50      2.18G      1.397     0.7009      1.071         21        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 286/286 [\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1304       3033      0.922      0.827      0.903      0.518\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      44/50       2.2G      1.388     0.6888      1.065         10        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 286/286 [\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1304       3033      0.918      0.825      0.899      0.518\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      45/50      2.18G      1.372     0.6789      1.059         21        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 286/286 [\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1304       3033      0.925      0.832      0.907      0.526\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      46/50      2.18G      1.364     0.6777      1.056         15        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 286/286 [\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1304       3033      0.925      0.831      0.901      0.525\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      47/50      2.18G      1.348     0.6658      1.048         20        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 286/286 [\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1304       3033      0.928      0.833      0.906      0.528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      48/50      2.18G       1.35      0.658      1.048         22        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 286/286 [\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1304       3033      0.926      0.835      0.907      0.528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      49/50      2.18G      1.335     0.6509      1.041         24        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 286/286 [\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1304       3033      0.923      0.834      0.907      0.532\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      50/50      2.16G      1.329     0.6482      1.036         19        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 286/286 [\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1304       3033      0.927      0.838      0.908      0.532\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "50 epochs completed in 0.587 hours.\n",
      "Optimizer stripped from /home/dionisius/bdma/tue/data_challenge_3/deepfish-detection/runs/detect/contrast/weights/last.pt, 6.2MB\n",
      "Optimizer stripped from /home/dionisius/bdma/tue/data_challenge_3/deepfish-detection/runs/detect/contrast/weights/best.pt, 6.2MB\n",
      "\n",
      "Validating /home/dionisius/bdma/tue/data_challenge_3/deepfish-detection/runs/detect/contrast/weights/best.pt...\n",
      "Ultralytics YOLOv8.2.89 üöÄ Python-3.11.2 torch-2.4.1+cu121 CUDA:0 (NVIDIA GeForce RTX 4060 Laptop GPU, 7943MiB)\n",
      "Model summary (fused): 168 layers, 3,005,843 parameters, 0 gradients, 8.1 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1304       3033      0.927      0.838      0.908      0.533\n",
      "Speed: 0.2ms preprocess, 1.9ms inference, 0.0ms loss, 0.4ms postprocess per image\n",
      "Results saved to \u001b[1m/home/dionisius/bdma/tue/data_challenge_3/deepfish-detection/runs/detect/contrast\u001b[0m\n",
      "CPU times: user 35min 51s, sys: 1min 16s, total: 37min 8s\n",
      "Wall time: 37min 25s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_model(pretrained_model=\"yolov8n.pt\", name=\"contrast\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "102aa22a-d0d0-4429-8e15-cd2345e081bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mv datasets/images/train datasets/images_preprocessed/contrast"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "474a9946-3bd8-4b4a-92b6-7a8c151f3486",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Histogram dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ff6d2810-05dd-4b7b-9510-292525340406",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mv datasets/images_preprocessed/histogram datasets/images/train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "83068a77-52df-4a33-9906-717bdd8127a3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.3.13 available üòÉ Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.2.89 üöÄ Python-3.11.2 torch-2.4.1+cu121 CUDA:0 (NVIDIA GeForce RTX 4060 Laptop GPU, 7943MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8n.pt, data=data.yaml, epochs=50, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=histogram, exist_ok=True, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=/home/dionisius/bdma/tue/data_challenge_3/deepfish-detection/runs/detect/histogram\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
      " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
      " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 22        [15, 18, 21]  1    751507  ultralytics.nn.modules.head.Detect           [1, [64, 128, 256]]           \n",
      "Model summary: 225 layers, 3,011,043 parameters, 3,011,027 gradients, 8.2 GFLOPs\n",
      "\n",
      "Transferred 319/355 items from pretrained weights\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /home/dionisius/bdma/tue/data_challenge_3/deepfish-detection/datasets/labels/train... 456\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /home/dionisius/bdma/tue/data_challenge_3/deepfish-detection/datasets/labels/train.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/dionisius/bdma/tue/data_challenge_3/deepfish-detection/datasets/labels/val.cache... 1\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING ‚ö†Ô∏è /home/dionisius/bdma/tue/data_challenge_3/deepfish-detection/datasets/images/val/9894_gerres_f000034_jpg.rf.077f365f7e09097b1627e75c4d237a57.jpg: 1 duplicate labels removed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to /home/dionisius/bdma/tue/data_challenge_3/deepfish-detection/runs/detect/histogram/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1m/home/dionisius/bdma/tue/data_challenge_3/deepfish-detection/runs/detect/histogram\u001b[0m\n",
      "Starting training for 50 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       1/50      2.18G      2.071      2.637      1.398         31        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 286/286 [\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1304       3033       0.48      0.309      0.318      0.122\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       2/50      2.15G       2.03      1.773      1.381         30        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 286/286 [\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1304       3033       0.58      0.323      0.362       0.16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       3/50      2.19G       2.01      1.635       1.37         24        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 286/286 [\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1304       3033      0.635      0.404      0.454      0.195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       4/50       2.2G      2.002      1.541      1.365         12        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 286/286 [\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1304       3033      0.636      0.394      0.446       0.19\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       5/50      2.21G      1.933      1.456      1.329         14        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 286/286 [\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1304       3033      0.511      0.366      0.406      0.178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       6/50      2.13G      1.896       1.39      1.318         52        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 286/286 [\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1304       3033      0.684      0.318      0.385      0.191\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       7/50      2.19G      1.883      1.305      1.293         26        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 286/286 [\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1304       3033      0.664      0.365      0.439      0.201\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       8/50      2.17G      1.834      1.264      1.274         43        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 286/286 [\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1304       3033      0.598       0.35      0.391      0.195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       9/50      2.14G      1.799      1.195      1.246         28        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 286/286 [\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1304       3033       0.55      0.349      0.368      0.166\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      10/50      2.19G       1.78      1.172      1.239         19        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 286/286 [\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1304       3033      0.541      0.355      0.388      0.186\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      11/50      2.18G      1.765      1.151      1.237         23        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 286/286 [\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1304       3033       0.63      0.472      0.523      0.246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      12/50      2.11G      1.732      1.113      1.209         14        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 286/286 [\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1304       3033      0.614       0.39      0.452      0.215\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      13/50      2.18G      1.728      1.109      1.205         56        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 286/286 [\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1304       3033      0.675      0.326      0.397      0.184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      14/50      2.24G      1.707      1.069      1.206          9        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 286/286 [\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1304       3033      0.601      0.336       0.39      0.194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      15/50      2.11G      1.693      1.048      1.188         19        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 286/286 [\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1304       3033      0.562      0.332      0.365      0.193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      16/50      2.17G      1.662      1.023      1.183         10        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 286/286 [\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1304       3033      0.585      0.377      0.438      0.223\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      17/50      2.17G      1.664     0.9978      1.171         44        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 286/286 [\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1304       3033      0.703      0.399      0.482      0.244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      18/50      2.17G      1.661     0.9979      1.167         27        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 286/286 [\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1304       3033      0.517      0.423      0.433      0.216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      19/50      2.23G      1.638     0.9958      1.165         24        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 286/286 [\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1304       3033      0.573      0.349      0.371      0.181\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      20/50      2.17G      1.644     0.9814      1.163         11        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 286/286 [\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1304       3033      0.736      0.409        0.5      0.251\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      21/50      2.14G      1.628     0.9655      1.155         34        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 286/286 [\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1304       3033      0.677      0.415      0.494      0.249\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      22/50      2.25G      1.607     0.9386      1.148         45        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 286/286 [\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1304       3033      0.622       0.33       0.38      0.196\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      23/50      2.17G       1.59     0.9259      1.131         24        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 286/286 [\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1304       3033        0.7      0.372      0.453      0.239\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      24/50      2.17G      1.586     0.9164       1.14         13        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 286/286 [\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1304       3033       0.74      0.435      0.534      0.271\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      25/50      2.17G      1.585     0.8999      1.132         19        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 286/286 [\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1304       3033      0.699      0.453      0.535      0.272\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      26/50      2.17G      1.556      0.886      1.128         12        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 286/286 [\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1304       3033      0.645      0.379      0.425      0.212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      27/50      2.17G      1.554     0.8792      1.124         39        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 286/286 [\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1304       3033      0.679      0.465      0.529      0.282\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      28/50      2.18G      1.552     0.8723      1.124         12        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 286/286 [\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1304       3033      0.698      0.438      0.501      0.257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      29/50      2.18G      1.528     0.8559      1.113         19        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 286/286 [\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1304       3033      0.679      0.388       0.45       0.23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      30/50      2.16G      1.527      0.842      1.099         25        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 286/286 [\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1304       3033      0.697      0.393      0.489      0.258\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      31/50      2.19G      1.524     0.8424      1.105         33        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 286/286 [\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1304       3033      0.718      0.449      0.533      0.274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      32/50      2.17G      1.503     0.8218      1.098         29        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 286/286 [\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1304       3033      0.639      0.432      0.479      0.248\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      33/50      2.25G      1.489     0.8179      1.093          8        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 286/286 [\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1304       3033      0.679      0.428      0.488      0.244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      34/50      2.25G      1.503     0.8202      1.094         16        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 286/286 [\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1304       3033      0.683      0.431      0.502      0.265\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      35/50       2.2G      1.491     0.8161      1.091         29        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 286/286 [\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1304       3033      0.718      0.421      0.512      0.271\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      36/50      2.17G      1.458     0.7943      1.083         20        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 286/286 [\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1304       3033      0.734      0.441      0.524      0.273\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      37/50      2.17G      1.463     0.7873      1.081         24        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 286/286 [\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1304       3033      0.727       0.45       0.54      0.287\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      38/50      2.19G      1.455     0.7817       1.07         44        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 286/286 [\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1304       3033       0.63      0.382      0.438      0.226\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      39/50      2.13G      1.442     0.7613      1.069         25        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 286/286 [\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1304       3033      0.675       0.45       0.52      0.266\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      40/50      2.17G      1.427     0.7576       1.07          4        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 286/286 [\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1304       3033      0.675      0.442      0.511      0.265\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      41/50       2.2G      1.443     0.7386      1.087         23        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 286/286 [\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1304       3033      0.773      0.469       0.57      0.299\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      42/50       2.1G      1.426      0.719      1.079         38        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 286/286 [\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1304       3033      0.771      0.431      0.541      0.296\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      43/50      2.09G      1.404     0.7062       1.07         21        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 286/286 [\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1304       3033      0.758      0.387      0.505      0.282\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      44/50      2.11G      1.405     0.7005       1.07         10        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 286/286 [\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1304       3033      0.746      0.386      0.494      0.277\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      45/50      2.11G      1.381     0.6863      1.063         21        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 286/286 [\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1304       3033      0.764      0.399      0.515      0.286\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      46/50       2.1G      1.372     0.6789      1.058         15        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 286/286 [\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1304       3033      0.793      0.394      0.515      0.285\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      47/50      2.11G      1.364     0.6705      1.052         20        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 286/286 [\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1304       3033      0.778      0.378        0.5       0.28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      48/50      2.08G      1.358     0.6682      1.051         22        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 286/286 [\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1304       3033      0.775      0.392      0.514      0.286\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      49/50      2.09G      1.348     0.6566      1.044         24        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 286/286 [\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1304       3033      0.796      0.399      0.528      0.292\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      50/50      2.07G      1.333     0.6515      1.038         19        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 286/286 [\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1304       3033      0.787      0.399      0.526      0.294\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "50 epochs completed in 0.586 hours.\n",
      "Optimizer stripped from /home/dionisius/bdma/tue/data_challenge_3/deepfish-detection/runs/detect/histogram/weights/last.pt, 6.2MB\n",
      "Optimizer stripped from /home/dionisius/bdma/tue/data_challenge_3/deepfish-detection/runs/detect/histogram/weights/best.pt, 6.2MB\n",
      "\n",
      "Validating /home/dionisius/bdma/tue/data_challenge_3/deepfish-detection/runs/detect/histogram/weights/best.pt...\n",
      "Ultralytics YOLOv8.2.89 üöÄ Python-3.11.2 torch-2.4.1+cu121 CUDA:0 (NVIDIA GeForce RTX 4060 Laptop GPU, 7943MiB)\n",
      "Model summary (fused): 168 layers, 3,005,843 parameters, 0 gradients, 8.1 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1304       3033      0.772      0.469       0.57      0.299\n",
      "Speed: 0.3ms preprocess, 2.0ms inference, 0.0ms loss, 0.3ms postprocess per image\n",
      "Results saved to \u001b[1m/home/dionisius/bdma/tue/data_challenge_3/deepfish-detection/runs/detect/histogram\u001b[0m\n",
      "CPU times: user 35min 50s, sys: 1min 14s, total: 37min 5s\n",
      "Wall time: 37min 23s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_model(pretrained_model=\"yolov8n.pt\", name=\"histogram\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "16559472-6a87-4cd9-b109-34dba0284ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mv datasets/images/train datasets/images_preprocessed/histogram"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1eb33f8-9f79-4ae5-aaed-865adb1f1ae8",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Adaptive dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4f7888ca-425e-490e-a34b-d72b14da0958",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mv datasets/images_preprocessed/adaptive datasets/images/train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "11f13095-a86e-40a2-af03-7c739b24b506",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.3.14 available üòÉ Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.2.89 üöÄ Python-3.11.2 torch-2.4.1+cu121 CUDA:0 (NVIDIA GeForce RTX 4060 Laptop GPU, 7943MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8n.pt, data=data.yaml, epochs=50, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=adaptive, exist_ok=True, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=/home/dionisius/bdma/tue/data_challenge_3/deepfish-detection/runs/detect/adaptive\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
      " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
      " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 22        [15, 18, 21]  1    751507  ultralytics.nn.modules.head.Detect           [1, [64, 128, 256]]           \n",
      "Model summary: 225 layers, 3,011,043 parameters, 3,011,027 gradients, 8.2 GFLOPs\n",
      "\n",
      "Transferred 319/355 items from pretrained weights\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /home/dionisius/bdma/tue/data_challenge_3/deepfish-detection/dat\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /home/dionisius/bdma/tue/data_challenge_3/deepfish-detection/datasets/labels/train.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/dionisius/bdma/tue/data_challenge_3/deepfish-detection/datas\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING ‚ö†Ô∏è /home/dionisius/bdma/tue/data_challenge_3/deepfish-detection/datasets/images/val/9894_gerres_f000034_jpg.rf.077f365f7e09097b1627e75c4d237a57.jpg: 1 duplicate labels removed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to /home/dionisius/bdma/tue/data_challenge_3/deepfish-detection/runs/detect/adaptive/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1m/home/dionisius/bdma/tue/data_challenge_3/deepfish-detection/runs/detect/adaptive\u001b[0m\n",
      "Starting training for 50 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       1/50      2.19G      1.929      2.389      1.317         31        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1304       3033       0.61      0.446      0.485       0.22\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       2/50      2.19G        1.9      1.579      1.305         30        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1304       3033      0.661      0.493      0.543      0.245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       3/50      2.24G      1.896       1.44       1.31         24        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1304       3033      0.673      0.509      0.557      0.244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       4/50      2.24G      1.861      1.343        1.3         12        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1304       3033      0.744      0.537      0.603       0.29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       5/50      2.23G      1.798      1.246      1.259         14        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1304       3033      0.821      0.613      0.703      0.345\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       6/50      2.22G      1.764      1.201      1.244         52        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1304       3033      0.807      0.615      0.705      0.346\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       7/50      2.21G      1.733       1.13       1.22         26        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1304       3033      0.786      0.603      0.695      0.334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       8/50       2.2G      1.707      1.093       1.21         43        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1304       3033      0.831      0.637      0.732      0.357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       9/50      2.18G      1.681      1.061      1.191         28        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1304       3033      0.748      0.617      0.698      0.362\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      10/50      2.18G       1.66      1.027      1.178         19        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1304       3033      0.805      0.665       0.76      0.375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      11/50      2.21G      1.644      1.001      1.181         23        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1304       3033      0.863      0.681      0.798      0.412\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      12/50       2.2G      1.616     0.9754      1.155         14        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1304       3033      0.839      0.669      0.777        0.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      13/50      2.22G      1.603      0.947      1.144         56        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1304       3033       0.83       0.71      0.793      0.412\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      14/50      2.18G      1.589     0.9445      1.151          9        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1304       3033       0.85       0.69      0.793      0.412\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      15/50      2.18G      1.574     0.9187      1.135         19        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1304       3033      0.818      0.693      0.781      0.408\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      16/50      2.18G      1.548     0.8939      1.131         10        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1304       3033      0.836       0.71      0.801      0.421\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      17/50       2.2G      1.558     0.8891      1.125         44        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1304       3033      0.855      0.731      0.813      0.433\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      18/50      2.21G      1.554     0.8781      1.123         27        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1304       3033      0.856      0.716       0.81      0.426\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      19/50       2.2G      1.538     0.8811      1.119         24        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1304       3033      0.811      0.707      0.784      0.407\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      20/50       2.2G      1.533     0.8549      1.114         11        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1304       3033      0.833      0.634      0.734      0.396\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      21/50      2.23G      1.509     0.8371      1.103         34        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1304       3033      0.881      0.702      0.812      0.419\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      22/50      2.29G      1.513      0.833      1.106         45        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1304       3033      0.865      0.728      0.826      0.447\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      23/50      2.18G      1.491     0.8131       1.09         24        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1304       3033      0.883      0.738      0.838      0.456\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      24/50       2.2G      1.477      0.806      1.093         13        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1304       3033      0.869      0.749      0.838      0.445\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      25/50      2.16G      1.478     0.7936      1.088         19        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1304       3033       0.89      0.744      0.843      0.445\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      26/50      2.19G      1.453     0.7845      1.084         12        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1304       3033      0.856      0.703      0.798      0.428\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      27/50      2.18G      1.456     0.7742      1.082         39        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1304       3033      0.865      0.731      0.829      0.453\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      28/50       2.2G      1.449      0.775      1.079         12        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1304       3033      0.858      0.761      0.839      0.458\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      29/50      2.21G      1.426      0.754      1.069         19        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1304       3033      0.865      0.728      0.833      0.463\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      30/50       2.2G      1.419      0.742      1.057         25        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1304       3033      0.886      0.734       0.84      0.449\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      31/50      2.18G      1.418     0.7508      1.063         33        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1304       3033      0.859      0.745      0.835      0.456\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      32/50      2.18G      1.399     0.7311      1.052         29        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1304       3033      0.904      0.763      0.865      0.472\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      33/50       2.2G      1.399     0.7319      1.056          8        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1304       3033      0.886      0.771       0.86      0.483\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      34/50      2.18G      1.391     0.7243       1.05         16        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1304       3033      0.881      0.742      0.849      0.477\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      35/50      2.23G        1.4     0.7181      1.053         29        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1304       3033      0.889      0.775      0.864      0.484\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      36/50      2.18G      1.372     0.7088      1.047         20        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1304       3033      0.897      0.789      0.879      0.496\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      37/50      2.18G      1.365     0.6991      1.042         24        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1304       3033       0.89      0.765      0.863      0.495\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      38/50      2.18G      1.372     0.6977      1.039         44        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1304       3033      0.905      0.778      0.876      0.491\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      39/50      2.16G      1.342     0.6789      1.032         25        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1304       3033      0.893      0.793      0.878        0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      40/50      2.23G      1.332     0.6774      1.032          4        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1304       3033      0.902      0.778      0.875      0.501\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      41/50      2.18G       1.35     0.6554      1.046         23        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1304       3033      0.884      0.792      0.878      0.503\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      42/50      2.18G      1.336     0.6451      1.042         38        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1304       3033      0.902      0.801      0.892      0.508\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      43/50      2.18G      1.316     0.6291      1.036         21        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1304       3033      0.902      0.789      0.883      0.516\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      44/50       2.2G      1.316     0.6207      1.032         10        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1304       3033      0.888      0.806      0.889      0.516\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      45/50      2.18G      1.299     0.6126      1.026         21        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1304       3033      0.893      0.795      0.885      0.519\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      46/50      2.18G      1.283     0.6039      1.024         15        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1304       3033        0.9      0.796      0.888      0.519\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      47/50      2.18G      1.277     0.5995      1.017         20        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1304       3033      0.897      0.791      0.883      0.517\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      48/50      2.17G      1.273     0.5964      1.018         22        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1304       3033      0.897      0.794      0.887      0.519\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      49/50      2.18G      1.268     0.5862      1.014         24        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1304       3033      0.892      0.799      0.888      0.523\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      50/50      2.16G      1.253      0.582      1.005         19        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1304       3033      0.907      0.791      0.888      0.524\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "50 epochs completed in 0.591 hours.\n",
      "Optimizer stripped from /home/dionisius/bdma/tue/data_challenge_3/deepfish-detection/runs/detect/adaptive/weights/last.pt, 6.2MB\n",
      "Optimizer stripped from /home/dionisius/bdma/tue/data_challenge_3/deepfish-detection/runs/detect/adaptive/weights/best.pt, 6.2MB\n",
      "\n",
      "Validating /home/dionisius/bdma/tue/data_challenge_3/deepfish-detection/runs/detect/adaptive/weights/best.pt...\n",
      "Ultralytics YOLOv8.2.89 üöÄ Python-3.11.2 torch-2.4.1+cu121 CUDA:0 (NVIDIA GeForce RTX 4060 Laptop GPU, 7943MiB)\n",
      "Model summary (fused): 168 layers, 3,005,843 parameters, 0 gradients, 8.1 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1304       3033      0.909      0.792      0.888      0.524\n",
      "Speed: 0.3ms preprocess, 2.0ms inference, 0.0ms loss, 0.3ms postprocess per image\n",
      "Results saved to \u001b[1m/home/dionisius/bdma/tue/data_challenge_3/deepfish-detection/runs/detect/adaptive\u001b[0m\n",
      "CPU times: user 36min 6s, sys: 1min 17s, total: 37min 23s\n",
      "Wall time: 35min 44s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_model(pretrained_model=\"yolov8n.pt\", name=\"adaptive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7621634d-d134-4986-8842-f340bc7b33a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mv datasets/images/train datasets/images_preprocessed/adaptive"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4a825ca-451e-4d63-9c6e-a5ac81788fad",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Combined datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "80712e8c-cc22-4e87-ba3a-59da683b8df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mv datasets/images_preprocessed/combined datasets/images/train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d9e056d7-83f5-4658-8437-aa53e35f3283",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.3.14 available üòÉ Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.2.89 üöÄ Python-3.11.2 torch-2.4.1+cu121 CUDA:0 (NVIDIA GeForce RTX 4060 Laptop GPU, 7943MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8n.pt, data=data.yaml, epochs=50, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=combined, exist_ok=True, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=/home/dionisius/bdma/tue/data_challenge_3/deepfish-detection/runs/detect/combined\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
      " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
      " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 22        [15, 18, 21]  1    751507  ultralytics.nn.modules.head.Detect           [1, [64, 128, 256]]           \n",
      "Model summary: 225 layers, 3,011,043 parameters, 3,011,027 gradients, 8.2 GFLOPs\n",
      "\n",
      "Transferred 319/355 items from pretrained weights\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /home/dionisius/bdma/tue/data_challenge_3/deepfish-detection/dat\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /home/dionisius/bdma/tue/data_challenge_3/deepfish-detection/datasets/labels/train.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/dionisius/bdma/tue/data_challenge_3/deepfish-detection/datas\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING ‚ö†Ô∏è /home/dionisius/bdma/tue/data_challenge_3/deepfish-detection/datasets/images/val/9894_gerres_f000034_jpg.rf.077f365f7e09097b1627e75c4d237a57.jpg: 1 duplicate labels removed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to /home/dionisius/bdma/tue/data_challenge_3/deepfish-detection/runs/detect/combined/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1m/home/dionisius/bdma/tue/data_challenge_3/deepfish-detection/runs/detect/combined\u001b[0m\n",
      "Starting training for 50 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       1/50      2.25G      1.914      2.445      1.296         37        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1304       3033      0.756      0.611      0.685      0.342\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       2/50      2.17G      1.798      1.434       1.21         63        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1304       3033      0.787      0.533      0.612      0.304\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       3/50      2.16G      1.831      1.331      1.226         50        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1304       3033      0.711      0.566      0.628      0.308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       4/50      2.16G      1.827      1.286      1.236         60        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1304       3033      0.827      0.692      0.783      0.397\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       5/50      2.18G      1.749      1.149      1.196         34        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1304       3033      0.837      0.721      0.806      0.419\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       6/50      2.19G      1.695      1.069      1.168         39        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1304       3033      0.847      0.744      0.828      0.437\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       7/50      2.16G      1.646      1.009      1.146         58        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1304       3033      0.868      0.786      0.862      0.472\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       8/50      2.19G      1.625     0.9775      1.136         89        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1304       3033       0.87      0.792       0.87      0.474\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       9/50      2.16G      1.595     0.9462      1.125         40        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1304       3033      0.888      0.796      0.877      0.491\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      10/50      2.16G      1.573      0.917      1.113         58        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1304       3033      0.884      0.813      0.882       0.49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      11/50      2.19G      1.551     0.8903      1.103         70        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1304       3033      0.903      0.825      0.897      0.508\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      12/50      2.16G      1.535     0.8705      1.096         39        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1304       3033      0.915      0.808      0.899      0.515\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      13/50      2.16G      1.518     0.8539      1.087         39        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1304       3033        0.9      0.833      0.904      0.513\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      14/50      2.18G      1.509     0.8397      1.082         33        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1304       3033      0.901      0.842      0.908      0.516\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      15/50      2.24G      1.492     0.8276      1.075         55        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1304       3033       0.92      0.844      0.915       0.53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      16/50      2.16G      1.476     0.8126      1.068         87        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1304       3033        0.9      0.858      0.916      0.529\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      17/50      2.18G      1.464     0.8013      1.061         53        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1304       3033      0.923      0.858      0.921      0.533\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      18/50      2.16G      1.449     0.7878       1.06         55        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1304       3033      0.912      0.852      0.919      0.539\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      19/50      2.16G      1.431      0.772      1.054         84        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1304       3033      0.917      0.855      0.925      0.541\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      20/50      2.19G       1.43     0.7645      1.049         33        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1304       3033      0.921      0.869      0.927      0.546\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      21/50      2.16G      1.425     0.7593      1.048         43        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1304       3033      0.935      0.865      0.934      0.553\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      22/50      2.17G      1.414     0.7459      1.045         75        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1304       3033      0.932      0.865      0.931      0.549\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      23/50      2.16G      1.394     0.7379      1.038         46        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1304       3033      0.928      0.872      0.933      0.552\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      24/50      2.16G      1.387     0.7279      1.032         54        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1304       3033      0.921      0.883      0.935      0.554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      25/50      2.16G      1.384      0.723      1.032         68        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1304       3033      0.932      0.883      0.939      0.562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      26/50      2.16G      1.373      0.716      1.027         34        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1304       3033      0.935      0.887      0.942       0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      27/50      2.16G      1.359     0.7068      1.025        101        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1304       3033      0.928      0.892      0.943      0.564\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      28/50      2.16G      1.358     0.7055      1.023         39        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1304       3033      0.934      0.888      0.944      0.564\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      29/50      2.16G      1.347      0.694      1.017         35        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1304       3033      0.935       0.88      0.942       0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      30/50      2.18G      1.337     0.6863      1.015         27        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1304       3033      0.929      0.893      0.947      0.569\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      31/50      2.19G      1.334     0.6835      1.015         54        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1304       3033      0.929      0.891      0.944       0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      32/50      2.19G      1.322      0.674      1.008         48        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1304       3033      0.917      0.899      0.943      0.574\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      33/50      2.16G      1.311     0.6657      1.004         47        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1304       3033      0.925      0.896      0.944      0.573\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      34/50      2.21G      1.307     0.6624      1.006         66        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1304       3033      0.926      0.899      0.946      0.577\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      35/50      2.18G      1.299     0.6524     0.9999         39        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1304       3033      0.931      0.906      0.949      0.579\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      36/50      2.18G      1.285     0.6434      0.993         34        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1304       3033      0.937      0.894      0.952      0.581\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      37/50      2.28G      1.278       0.64     0.9965         39        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1304       3033       0.94      0.894      0.952       0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      38/50      2.16G      1.275     0.6361     0.9909         56        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1304       3033      0.941      0.891      0.951      0.581\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      39/50      2.19G      1.267     0.6298     0.9881         69        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1304       3033      0.929      0.901      0.952      0.582\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      40/50      2.16G      1.255       0.62     0.9856         62        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1304       3033      0.935      0.903      0.954      0.585\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      41/50      2.18G      1.247     0.5912     0.9921         51        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1304       3033      0.937      0.906      0.954      0.586\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      42/50      2.16G       1.23     0.5778     0.9837         40        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1304       3033      0.932      0.911      0.955      0.588\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      43/50      2.18G      1.223     0.5717     0.9839         35        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1304       3033      0.932      0.914      0.955      0.589\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      44/50      2.16G      1.208     0.5614     0.9781         30        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1304       3033      0.934      0.911      0.955      0.591\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      45/50      2.19G      1.194     0.5546      0.972         29        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1304       3033      0.934      0.915      0.957      0.592\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      46/50      2.16G      1.187     0.5471     0.9691         39        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1304       3033      0.933      0.914      0.957      0.592\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      47/50      2.16G      1.172     0.5407     0.9656         48        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1304       3033      0.929      0.917      0.957      0.592\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      48/50      2.16G      1.168     0.5348     0.9644         25        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1304       3033      0.928      0.918      0.957      0.593\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      49/50      2.16G      1.159     0.5289     0.9611         26        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1304       3033      0.929      0.916      0.958      0.593\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      50/50      2.18G      1.143     0.5231     0.9545         24        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1304       3033       0.93      0.918      0.957      0.594\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "50 epochs completed in 2.153 hours.\n",
      "Optimizer stripped from /home/dionisius/bdma/tue/data_challenge_3/deepfish-detection/runs/detect/combined/weights/last.pt, 6.2MB\n",
      "Optimizer stripped from /home/dionisius/bdma/tue/data_challenge_3/deepfish-detection/runs/detect/combined/weights/best.pt, 6.2MB\n",
      "\n",
      "Validating /home/dionisius/bdma/tue/data_challenge_3/deepfish-detection/runs/detect/combined/weights/best.pt...\n",
      "Ultralytics YOLOv8.2.89 üöÄ Python-3.11.2 torch-2.4.1+cu121 CUDA:0 (NVIDIA GeForce RTX 4060 Laptop GPU, 7943MiB)\n",
      "Model summary (fused): 168 layers, 3,005,843 parameters, 0 gradients, 8.1 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1304       3033       0.93      0.917      0.958      0.594\n",
      "Speed: 0.2ms preprocess, 1.9ms inference, 0.0ms loss, 0.4ms postprocess per image\n",
      "Results saved to \u001b[1m/home/dionisius/bdma/tue/data_challenge_3/deepfish-detection/runs/detect/combined\u001b[0m\n",
      "CPU times: user 2h 10min 51s, sys: 3min 58s, total: 2h 14min 49s\n",
      "Wall time: 2h 11min 33s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_model(pretrained_model=\"yolov8n.pt\", name=\"combined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "742d22a8-f716-4415-bdd8-a20dde15dd9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mv datasets/images/train datasets/images_preprocessed/combined"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "126ad558-0de3-498d-9c4b-b2dfb9692ebc",
   "metadata": {},
   "source": [
    "## Different YOLO Sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "216eae82-6bbe-409e-b878-38c853407cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mv datasets/images_preprocessed/combined datasets/images/train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a430281f-694a-4af6-98d6-31b1dd326af7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.3.15 available üòÉ Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.2.89 üöÄ Python-3.11.2 torch-2.4.1+cu121 CUDA:0 (NVIDIA GeForce RTX 4060 Laptop GPU, 7943MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8s.pt, data=data.yaml, epochs=50, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=yolo_small, exist_ok=True, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=/home/dionisius/bdma/tue/data_challenge_3/deepfish-detection/runs/detect/yolo_small\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
      "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n",
      "  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  5                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n",
      "  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
      "  8                  -1  1   1838080  ultralytics.nn.modules.block.C2f             [512, 512, 1, True]           \n",
      "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 16                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 19                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1   1969152  ultralytics.nn.modules.block.C2f             [768, 512, 1]                 \n",
      " 22        [15, 18, 21]  1   2116435  ultralytics.nn.modules.head.Detect           [1, [128, 256, 512]]          \n",
      "Model summary: 225 layers, 11,135,987 parameters, 11,135,971 gradients, 28.6 GFLOPs\n",
      "\n",
      "Transferred 349/355 items from pretrained weights\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /home/dionisius/bdma/tue/data_challenge_3/deepfish-detection/datasets/labels/train.cache... 18272 images, 5564 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 18272/18272 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/dionisius/bdma/tue/data_challenge_3/deepfish-detection/datasets/labels/val.cache... 1304 images, 402 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1304/1304 [00:00<?, ?it/s]\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING ‚ö†Ô∏è /home/dionisius/bdma/tue/data_challenge_3/deepfish-detection/datasets/images/val/9894_gerres_f000034_jpg.rf.077f365f7e09097b1627e75c4d237a57.jpg: 1 duplicate labels removed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to /home/dionisius/bdma/tue/data_challenge_3/deepfish-detection/runs/detect/yolo_small/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1m/home/dionisius/bdma/tue/data_challenge_3/deepfish-detection/runs/detect/yolo_small\u001b[0m\n",
      "Starting training for 50 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       1/50      3.87G      1.858      1.842      1.302         37        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1142/1142 [05:08<00:00,  3.70it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 41/41 [00:08<00:00,  4.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1304       3033      0.822      0.618      0.704      0.351\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       2/50       3.8G      1.685      1.113       1.17         63        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1142/1142 [05:05<00:00,  3.74it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 41/41 [00:08<00:00,  4.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1304       3033      0.866      0.738      0.826      0.439\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       3/50       3.8G      1.728      1.143      1.186         50        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1142/1142 [05:04<00:00,  3.75it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 41/41 [00:08<00:00,  4.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1304       3033      0.835       0.68      0.778      0.389\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       4/50      3.79G      1.745      1.149      1.202         60        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1142/1142 [05:04<00:00,  3.75it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 41/41 [00:08<00:00,  4.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1304       3033      0.813      0.736      0.815      0.422\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       5/50       3.8G      1.673      1.034      1.166         34        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1142/1142 [05:04<00:00,  3.75it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 41/41 [00:08<00:00,  4.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1304       3033      0.863      0.778       0.86      0.463\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       6/50      3.82G      1.613     0.9631      1.136         39        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1142/1142 [05:04<00:00,  3.75it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 41/41 [00:08<00:00,  4.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1304       3033      0.893      0.805      0.884      0.484\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       7/50      3.79G      1.562     0.9082      1.117         58        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1142/1142 [05:04<00:00,  3.75it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 41/41 [00:08<00:00,  4.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1304       3033      0.879      0.809      0.877      0.488\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       8/50      3.82G      1.537     0.8755      1.102         89        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1142/1142 [05:04<00:00,  3.75it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 41/41 [00:08<00:00,  4.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1304       3033      0.903      0.819      0.898       0.51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       9/50      3.79G       1.51     0.8455      1.094         40        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1142/1142 [05:04<00:00,  3.75it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 41/41 [00:08<00:00,  4.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1304       3033      0.912      0.837       0.91      0.518\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      10/50      3.79G       1.48     0.8167       1.08         58        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1142/1142 [05:04<00:00,  3.75it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 41/41 [00:08<00:00,  4.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1304       3033      0.899      0.848      0.912      0.518\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      11/50      3.82G      1.456     0.7953      1.068         70        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1142/1142 [05:04<00:00,  3.75it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 41/41 [00:08<00:00,  4.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1304       3033      0.906      0.852       0.92      0.537\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      12/50      3.79G      1.441      0.777      1.061         39        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1142/1142 [05:04<00:00,  3.75it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 41/41 [00:08<00:00,  4.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1304       3033      0.915       0.86      0.929      0.543\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      13/50      3.79G      1.421     0.7601      1.052         39        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1142/1142 [05:05<00:00,  3.74it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 41/41 [00:08<00:00,  4.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1304       3033      0.903      0.857      0.923      0.536\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      14/50      3.79G      1.409     0.7452      1.045         33        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1142/1142 [05:04<00:00,  3.75it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 41/41 [00:08<00:00,  4.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1304       3033      0.919      0.866       0.93      0.545\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      15/50      3.79G      1.388     0.7265      1.037         55        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1142/1142 [05:04<00:00,  3.75it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 41/41 [00:08<00:00,  4.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1304       3033      0.924      0.867      0.932      0.554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      16/50      3.79G      1.377     0.7202      1.035         87        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1142/1142 [05:04<00:00,  3.75it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 41/41 [00:08<00:00,  4.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1304       3033      0.925      0.877      0.937      0.559\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      17/50       3.8G      1.361      0.706      1.026         53        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1142/1142 [05:05<00:00,  3.74it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 41/41 [00:08<00:00,  4.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1304       3033      0.925      0.889      0.942      0.566\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      18/50       3.8G      1.344     0.6954      1.022         55        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1142/1142 [05:05<00:00,  3.74it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 41/41 [00:08<00:00,  4.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1304       3033      0.924      0.889      0.943       0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      19/50      3.79G      1.324     0.6793      1.017         84        \n",
      "                 Class     Images  Instances      Box(P          R      mA"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1304       3033      0.917      0.907      0.947       0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      20/50      3.81G       1.32     0.6742      1.013         33        \n",
      "                 Class     Images  Instances      Box(P          R      mA"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1304       3033      0.925      0.895      0.946      0.572\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      21/50      3.79G      1.315     0.6689      1.009         43        \n",
      "                 Class     Images  Instances      Box(P          R      mA"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1304       3033      0.935      0.891      0.949      0.577\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      22/50       3.8G      1.302     0.6551      1.005         75        \n",
      "                 Class     Images  Instances      Box(P          R      mA"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1304       3033      0.932      0.902      0.952      0.583\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      23/50      3.79G      1.287     0.6465      1.001         46        \n",
      "                 Class     Images  Instances      Box(P          R      mA"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1304       3033      0.939      0.906      0.955      0.586\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      24/50      3.78G      1.273     0.6382     0.9964         54        \n",
      "                 Class     Images  Instances      Box(P          R      mA"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1304       3033      0.939      0.899      0.953      0.586\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      25/50      3.79G      1.267     0.6346     0.9925         68        \n",
      "                 Class     Images  Instances      Box(P          R      mA"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1304       3033      0.939      0.906      0.953       0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      26/50      3.79G      1.257     0.6236     0.9883         34        \n",
      "                 Class     Images  Instances      Box(P          R      mA"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1304       3033      0.937      0.907      0.957      0.588\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      27/50      3.79G       1.24     0.6139     0.9852        101        \n",
      "                 Class     Images  Instances      Box(P          R      mA"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1304       3033      0.933      0.906      0.955      0.591\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      28/50      3.79G      1.236     0.6136     0.9826         39        \n",
      "                 Class     Images  Instances      Box(P          R      mA"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1304       3033      0.937      0.914      0.959      0.592\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      29/50      3.79G      1.228     0.6031     0.9799         35        \n",
      "                 Class     Images  Instances      Box(P          R      mA"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1304       3033      0.936      0.916      0.958      0.594\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      30/50       3.8G      1.214      0.594     0.9754         27        \n",
      "                 Class     Images  Instances      Box(P          R      mA"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1304       3033      0.932       0.92      0.963      0.595\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      31/50      3.82G      1.206     0.5914     0.9731         54        \n",
      "                 Class     Images  Instances      Box(P          R      mA"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1304       3033      0.935      0.916      0.959      0.599\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      32/50       3.8G      1.195     0.5816     0.9676         48        \n",
      "                 Class     Images  Instances      Box(P          R      mA"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1304       3033      0.941      0.912      0.962      0.601\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      33/50       3.8G      1.183     0.5737     0.9657         47        \n",
      "                 Class     Images  Instances      Box(P          R      mA"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1304       3033      0.935      0.922       0.96      0.599\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      34/50      3.79G      1.172     0.5704     0.9646         66        \n",
      "                 Class     Images  Instances      Box(P          R      mA"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1304       3033      0.933      0.926       0.96      0.602\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      35/50       3.8G      1.164     0.5607     0.9592         39        \n",
      "                 Class     Images  Instances      Box(P          R      mA"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1304       3033      0.937      0.923      0.962      0.603\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      36/50      3.74G      1.151     0.5504      0.953         34        \n",
      "                 Class     Images  Instances      Box(P          R      mA"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1304       3033       0.94      0.926      0.963      0.606\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      37/50       3.8G      1.137     0.5475     0.9529         39        \n",
      "                 Class     Images  Instances      Box(P          R      mA"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1304       3033      0.939      0.924      0.963      0.607\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      38/50       3.8G      1.141     0.5452     0.9502         56        \n",
      "                 Class     Images  Instances      Box(P          R      mA"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1304       3033      0.938      0.925      0.963      0.608\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      39/50      3.82G      1.121     0.5366      0.945         69        \n",
      "                 Class     Images  Instances      Box(P          R      mA"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1304       3033      0.936       0.93      0.963      0.609\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      40/50      3.79G      1.114      0.528     0.9434         62        \n",
      "                 Class     Images  Instances      Box(P          R      mA"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1304       3033      0.937      0.928      0.963      0.608\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      41/50      3.75G      1.109     0.5041     0.9479         51        \n",
      "                 Class     Images  Instances      Box(P          R      mA"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1304       3033      0.942      0.927      0.965       0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      42/50       3.8G      1.088     0.4932     0.9409         40        \n",
      "                 Class     Images  Instances      Box(P          R      mA"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1304       3033      0.943      0.927      0.965      0.611\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      43/50      3.75G      1.079     0.4869     0.9406         35        \n",
      "                 Class     Images  Instances      Box(P          R      mA"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1304       3033      0.941      0.925      0.964      0.611\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      44/50       3.8G       1.06     0.4781     0.9334         30        \n",
      "                 Class     Images  Instances      Box(P          R      mA"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1304       3033      0.941      0.925      0.964      0.611\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      45/50      3.82G      1.041      0.469     0.9266         29        \n",
      "                 Class     Images  Instances      Box(P          R      mA"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1304       3033      0.942      0.926      0.965      0.613\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      46/50      3.79G      1.034     0.4628     0.9231         39        \n",
      "                 Class     Images  Instances      Box(P          R      mA"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1304       3033      0.943      0.925      0.965      0.613\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      47/50      3.79G      1.018     0.4573     0.9203         48        \n",
      "                 Class     Images  Instances      Box(P          R      mA"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1304       3033       0.94      0.928      0.966      0.613\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      48/50      3.79G      1.008     0.4499     0.9185         25        \n",
      "                 Class     Images  Instances      Box(P          R      mA"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1304       3033       0.94      0.925      0.965      0.612\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      49/50      3.79G     0.9977     0.4456      0.914         26        \n",
      "                 Class     Images  Instances      Box(P          R      mA"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1304       3033       0.94      0.926      0.966      0.612\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      50/50      3.75G     0.9871     0.4407     0.9091         24        \n",
      "                 Class     Images  Instances      Box(P          R      mA"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1304       3033       0.94      0.925      0.965      0.612\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "50 epochs completed in 4.359 hours.\n",
      "Optimizer stripped from /home/dionisius/bdma/tue/data_challenge_3/deepfish-detection/runs/detect/yolo_small/weights/last.pt, 22.5MB\n",
      "Optimizer stripped from /home/dionisius/bdma/tue/data_challenge_3/deepfish-detection/runs/detect/yolo_small/weights/best.pt, 22.5MB\n",
      "\n",
      "Validating /home/dionisius/bdma/tue/data_challenge_3/deepfish-detection/runs/detect/yolo_small/weights/best.pt...\n",
      "Ultralytics YOLOv8.2.89 üöÄ Python-3.11.2 torch-2.4.1+cu121 CUDA:0 (NVIDIA GeForce RTX 4060 Laptop GPU, 7943MiB)\n",
      "Model summary (fused): 168 layers, 11,125,971 parameters, 0 gradients, 28.4 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mA\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1304       3033       0.94      0.927      0.966      0.613\n",
      "Speed: 0.3ms preprocess, 5.1ms inference, 0.0ms loss, 0.3ms postprocess per image\n",
      "Results saved to \u001b[1m/home/dionisius/bdma/tue/data_challenge_3/deepfish-detection/runs/detect/yolo_small\u001b[0m\n",
      "CPU times: user 4h 19min 42s, sys: 7min 18s, total: 4h 27min\n",
      "Wall time: 4h 21min 50s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_model(pretrained_model=\"yolov8s.pt\", name=\"yolo_small\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8f8cf32e-19b1-4406-b168-e33a6a094a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mv datasets/images/train datasets/images_preprocessed/combined"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24435f15-f0b3-46d7-bf26-611fb1d76aa8",
   "metadata": {},
   "source": [
    "# Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "596d6150-ea90-4cb2-8ac3-1c2ed67827b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.2.89 üöÄ Python-3.11.2 torch-2.4.1+cu121 CUDA:0 (NVIDIA GeForce RTX 4060 Laptop GPU, 7943MiB)\n",
      "Model summary (fused): 168 layers, 3,005,843 parameters, 0 gradients, 8.1 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/dionisius/bdma/tue/data_challenge_3/deepfish-detection/datasets/labels/val.cache... 1304 images, 402 backgrounds, 0 corru\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING ‚ö†Ô∏è /home/dionisius/bdma/tue/data_challenge_3/deepfish-detection/datasets/images/val/9894_gerres_f000034_jpg.rf.077f365f7e09097b1627e75c4d237a57.jpg: 1 duplicate labels removed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 82/82 [00:06<00:00, 12.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1304       3033       0.93      0.869      0.934      0.565\n",
      "Speed: 0.4ms preprocess, 3.2ms inference, 0.0ms loss, 0.6ms postprocess per image\n",
      "Results saved to \u001b[1m/home/dionisius/bdma/tue/data_challenge_3/deepfish-detection/runs/detect/val\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "model = YOLO('runs/detect/original/weights/best.pt')\n",
    "results = model.val(data='data.yaml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cc68c293-a502-4b24-b469-a86f9d1cefe1",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'stop' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mstop\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'stop' is not defined"
     ]
    }
   ],
   "source": [
    "stop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5408f71b-90e0-4ba6-8204-ed25c11fc8c1",
   "metadata": {},
   "source": [
    "# Object counting\n",
    "After training, the weights will be stored. I uploaded the weights of my best model after 70 epochs of training in `model_trained_deepfish/best.pt`. The input video is `test_video/fish.mp4` and the output of object counting is in `output_video/fish_output.mp4`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0bd6808f-c07a-4efe-bd92-163e0356873a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Polygon Counter Initiated.\n",
      "\n",
      "0: 640x640 (no detections), 3.6ms\n",
      "Speed: 1.2ms preprocess, 3.6ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 3.6ms\n",
      "Speed: 1.3ms preprocess, 3.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 3.9ms\n",
      "Speed: 3.7ms preprocess, 3.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 5.4ms\n",
      "Speed: 2.6ms preprocess, 5.4ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 8.4ms\n",
      "Speed: 3.8ms preprocess, 8.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.5ms\n",
      "Speed: 4.5ms preprocess, 10.5ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 5.0ms\n",
      "Speed: 1.6ms preprocess, 5.0ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 3.7ms\n",
      "Speed: 2.1ms preprocess, 3.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.1ms\n",
      "Speed: 3.9ms preprocess, 10.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 4.4ms\n",
      "Speed: 5.7ms preprocess, 4.4ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 3.6ms\n",
      "Speed: 1.4ms preprocess, 3.6ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Video frame is empty or video processing has been successfully completed.\n",
      "Polygon Counter Initiated.\n",
      "\n",
      "0: 640x640 (no detections), 3.6ms\n",
      "Speed: 1.3ms preprocess, 3.6ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 4.4ms\n",
      "Speed: 1.6ms preprocess, 4.4ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 3.6ms\n",
      "Speed: 1.5ms preprocess, 3.6ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 5.2ms\n",
      "Speed: 1.4ms preprocess, 5.2ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 4.1ms\n",
      "Speed: 1.4ms preprocess, 4.1ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 3.6ms\n",
      "Speed: 1.4ms preprocess, 3.6ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 3.6ms\n",
      "Speed: 1.7ms preprocess, 3.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 3.6ms\n",
      "Speed: 1.4ms preprocess, 3.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 4.0ms\n",
      "Speed: 2.0ms preprocess, 4.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 3.6ms\n",
      "Speed: 1.4ms preprocess, 3.6ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 3.6ms\n",
      "Speed: 1.4ms preprocess, 3.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 3.6ms\n",
      "Speed: 1.3ms preprocess, 3.6ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 3.6ms\n",
      "Speed: 1.4ms preprocess, 3.6ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Video frame is empty or video processing has been successfully completed.\n",
      "Polygon Counter Initiated.\n",
      "\n",
      "0: 640x640 2 Fishs, 3.5ms\n",
      "Speed: 1.2ms preprocess, 3.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 3 Fishs, 3.6ms\n",
      "Speed: 1.3ms preprocess, 3.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Video frame is empty or video processing has been successfully completed.\n",
      "Polygon Counter Initiated.\n",
      "\n",
      "0: 640x640 1 Fish, 3.5ms\n",
      "Speed: 1.2ms preprocess, 3.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 Fishs, 4.0ms\n",
      "Speed: 1.5ms preprocess, 4.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 Fishs, 3.6ms\n",
      "Speed: 1.4ms preprocess, 3.6ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 Fishs, 3.6ms\n",
      "Speed: 1.3ms preprocess, 3.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 Fishs, 5.3ms\n",
      "Speed: 2.7ms preprocess, 5.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 Fishs, 3.6ms\n",
      "Speed: 1.4ms preprocess, 3.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 Fishs, 3.6ms\n",
      "Speed: 1.3ms preprocess, 3.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 Fishs, 7.4ms\n",
      "Speed: 2.8ms preprocess, 7.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Fish, 3.6ms\n",
      "Speed: 1.3ms preprocess, 3.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Fish, 3.6ms\n",
      "Speed: 2.5ms preprocess, 3.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 Fishs, 3.6ms\n",
      "Speed: 1.6ms preprocess, 3.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 Fishs, 3.8ms\n",
      "Speed: 1.4ms preprocess, 3.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 Fishs, 3.6ms\n",
      "Speed: 1.4ms preprocess, 3.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 Fishs, 3.6ms\n",
      "Speed: 1.4ms preprocess, 3.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 3 Fishs, 3.6ms\n",
      "Speed: 1.3ms preprocess, 3.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Fish, 3.6ms\n",
      "Speed: 1.4ms preprocess, 3.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Fish, 3.6ms\n",
      "Speed: 1.4ms preprocess, 3.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Fish, 3.6ms\n",
      "Speed: 1.3ms preprocess, 3.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Video frame is empty or video processing has been successfully completed.\n",
      "Polygon Counter Initiated.\n",
      "\n",
      "0: 640x640 1 Fish, 3.6ms\n",
      "Speed: 1.3ms preprocess, 3.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Fish, 3.6ms\n",
      "Speed: 1.4ms preprocess, 3.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Video frame is empty or video processing has been successfully completed.\n",
      "Polygon Counter Initiated.\n",
      "\n",
      "0: 640x640 (no detections), 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 4.7ms\n",
      "Speed: 1.5ms preprocess, 4.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.4ms\n",
      "Speed: 3.6ms preprocess, 10.4ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 3.6ms\n",
      "Speed: 1.6ms preprocess, 3.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 3.8ms\n",
      "Speed: 2.0ms preprocess, 3.8ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 7.0ms\n",
      "Speed: 1.6ms preprocess, 7.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 3.6ms\n",
      "Speed: 1.9ms preprocess, 3.6ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 3.6ms\n",
      "Speed: 1.3ms preprocess, 3.6ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 3.6ms\n",
      "Speed: 1.4ms preprocess, 3.6ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Video frame is empty or video processing has been successfully completed.\n",
      "Polygon Counter Initiated.\n",
      "\n",
      "0: 640x640 1 Fish, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Fish, 3.6ms\n",
      "Speed: 1.4ms preprocess, 3.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Fish, 3.6ms\n",
      "Speed: 1.3ms preprocess, 3.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Fish, 3.6ms\n",
      "Speed: 1.3ms preprocess, 3.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Fish, 3.6ms\n",
      "Speed: 1.8ms preprocess, 3.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Fish, 3.6ms\n",
      "Speed: 2.1ms preprocess, 3.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Fish, 3.6ms\n",
      "Speed: 1.4ms preprocess, 3.6ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Fish, 3.6ms\n",
      "Speed: 1.5ms preprocess, 3.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Fish, 3.6ms\n",
      "Speed: 1.4ms preprocess, 3.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Fish, 3.6ms\n",
      "Speed: 1.3ms preprocess, 3.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Fish, 3.6ms\n",
      "Speed: 1.3ms preprocess, 3.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Fish, 3.6ms\n",
      "Speed: 1.3ms preprocess, 3.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Fish, 3.6ms\n",
      "Speed: 1.3ms preprocess, 3.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Fish, 3.6ms\n",
      "Speed: 1.3ms preprocess, 3.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Fish, 3.8ms\n",
      "Speed: 1.3ms preprocess, 3.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Fish, 3.8ms\n",
      "Speed: 1.4ms preprocess, 3.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Fish, 3.8ms\n",
      "Speed: 2.5ms preprocess, 3.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Fish, 3.8ms\n",
      "Speed: 1.4ms preprocess, 3.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Fish, 3.8ms\n",
      "Speed: 1.4ms preprocess, 3.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Fish, 3.8ms\n",
      "Speed: 1.4ms preprocess, 3.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Fish, 3.8ms\n",
      "Speed: 1.4ms preprocess, 3.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Fish, 3.8ms\n",
      "Speed: 1.4ms preprocess, 3.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Fish, 3.8ms\n",
      "Speed: 1.4ms preprocess, 3.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Video frame is empty or video processing has been successfully completed.\n",
      "Polygon Counter Initiated.\n",
      "\n",
      "0: 640x640 1 Fish, 3.8ms\n",
      "Speed: 1.3ms preprocess, 3.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Fish, 3.8ms\n",
      "Speed: 1.4ms preprocess, 3.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Fish, 3.9ms\n",
      "Speed: 2.1ms preprocess, 3.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Fish, 3.8ms\n",
      "Speed: 1.4ms preprocess, 3.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 Fishs, 3.8ms\n",
      "Speed: 1.3ms preprocess, 3.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Video frame is empty or video processing has been successfully completed.\n",
      "Polygon Counter Initiated.\n",
      "\n",
      "0: 640x640 1 Fish, 3.8ms\n",
      "Speed: 1.3ms preprocess, 3.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Fish, 3.8ms\n",
      "Speed: 1.4ms preprocess, 3.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Fish, 3.8ms\n",
      "Speed: 1.3ms preprocess, 3.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Fish, 3.8ms\n",
      "Speed: 1.4ms preprocess, 3.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Fish, 4.5ms\n",
      "Speed: 4.5ms preprocess, 4.5ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Fish, 3.8ms\n",
      "Speed: 1.3ms preprocess, 3.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Fish, 3.8ms\n",
      "Speed: 1.4ms preprocess, 3.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Fish, 3.9ms\n",
      "Speed: 1.4ms preprocess, 3.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Fish, 3.9ms\n",
      "Speed: 1.5ms preprocess, 3.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Video frame is empty or video processing has been successfully completed.\n",
      "Polygon Counter Initiated.\n",
      "\n",
      "0: 640x640 2 Fishs, 3.9ms\n",
      "Speed: 1.4ms preprocess, 3.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 Fishs, 4.9ms\n",
      "Speed: 2.4ms preprocess, 4.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Video frame is empty or video processing has been successfully completed.\n",
      "Polygon Counter Initiated.\n",
      "\n",
      "0: 640x640 2 Fishs, 3.8ms\n",
      "Speed: 1.3ms preprocess, 3.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Video frame is empty or video processing has been successfully completed.\n",
      "Polygon Counter Initiated.\n",
      "\n",
      "0: 640x640 6 Fishs, 3.8ms\n",
      "Speed: 1.3ms preprocess, 3.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 5 Fishs, 5.3ms\n",
      "Speed: 2.6ms preprocess, 5.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 5 Fishs, 4.3ms\n",
      "Speed: 6.6ms preprocess, 4.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 8 Fishs, 3.9ms\n",
      "Speed: 1.4ms preprocess, 3.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Fish, 3.9ms\n",
      "Speed: 1.4ms preprocess, 3.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 5 Fishs, 4.2ms\n",
      "Speed: 2.6ms preprocess, 4.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Video frame is empty or video processing has been successfully completed.\n",
      "Polygon Counter Initiated.\n",
      "\n",
      "0: 640x640 2 Fishs, 3.8ms\n",
      "Speed: 1.3ms preprocess, 3.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 Fishs, 8.9ms\n",
      "Speed: 7.5ms preprocess, 8.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Fish, 3.9ms\n",
      "Speed: 2.3ms preprocess, 3.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 Fishs, 5.2ms\n",
      "Speed: 3.4ms preprocess, 5.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Fish, 4.2ms\n",
      "Speed: 2.7ms preprocess, 4.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Fish, 3.9ms\n",
      "Speed: 2.8ms preprocess, 3.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Fish, 3.6ms\n",
      "Speed: 2.8ms preprocess, 3.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Fish, 3.6ms\n",
      "Speed: 1.5ms preprocess, 3.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Fish, 3.6ms\n",
      "Speed: 1.3ms preprocess, 3.6ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Video frame is empty or video processing has been successfully completed.\n",
      "Polygon Counter Initiated.\n",
      "\n",
      "0: 640x640 4 Fishs, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 Fishs, 3.6ms\n",
      "Speed: 1.4ms preprocess, 3.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 4 Fishs, 3.6ms\n",
      "Speed: 3.1ms preprocess, 3.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Fish, 3.6ms\n",
      "Speed: 1.4ms preprocess, 3.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 Fishs, 3.6ms\n",
      "Speed: 1.4ms preprocess, 3.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 Fishs, 8.4ms\n",
      "Speed: 2.8ms preprocess, 8.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 Fishs, 3.6ms\n",
      "Speed: 1.4ms preprocess, 3.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 Fishs, 3.6ms\n",
      "Speed: 1.3ms preprocess, 3.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 Fishs, 4.3ms\n",
      "Speed: 2.6ms preprocess, 4.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Fish, 3.6ms\n",
      "Speed: 1.3ms preprocess, 3.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Fish, 3.6ms\n",
      "Speed: 1.3ms preprocess, 3.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Video frame is empty or video processing has been successfully completed.\n",
      "Polygon Counter Initiated.\n",
      "\n",
      "0: 640x640 1 Fish, 3.6ms\n",
      "Speed: 1.3ms preprocess, 3.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Fish, 4.1ms\n",
      "Speed: 1.5ms preprocess, 4.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 Fishs, 3.6ms\n",
      "Speed: 1.5ms preprocess, 3.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 Fishs, 3.6ms\n",
      "Speed: 1.4ms preprocess, 3.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Fish, 3.6ms\n",
      "Speed: 1.4ms preprocess, 3.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Fish, 3.6ms\n",
      "Speed: 1.3ms preprocess, 3.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 Fishs, 3.6ms\n",
      "Speed: 1.3ms preprocess, 3.6ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 Fishs, 3.6ms\n",
      "Speed: 1.4ms preprocess, 3.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Video frame is empty or video processing has been successfully completed.\n",
      "Polygon Counter Initiated.\n",
      "\n",
      "0: 640x640 3 Fishs, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 3 Fishs, 3.6ms\n",
      "Speed: 1.4ms preprocess, 3.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 3 Fishs, 3.6ms\n",
      "Speed: 1.3ms preprocess, 3.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 Fishs, 3.6ms\n",
      "Speed: 1.4ms preprocess, 3.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 Fishs, 3.6ms\n",
      "Speed: 1.3ms preprocess, 3.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 Fishs, 3.6ms\n",
      "Speed: 1.4ms preprocess, 3.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 Fishs, 3.6ms\n",
      "Speed: 1.3ms preprocess, 3.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Fish, 3.6ms\n",
      "Speed: 1.4ms preprocess, 3.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Fish, 3.6ms\n",
      "Speed: 1.4ms preprocess, 3.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Fish, 3.6ms\n",
      "Speed: 1.3ms preprocess, 3.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Fish, 3.6ms\n",
      "Speed: 1.5ms preprocess, 3.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Video frame is empty or video processing has been successfully completed.\n",
      "Polygon Counter Initiated.\n",
      "\n",
      "0: 640x640 (no detections), 3.6ms\n",
      "Speed: 1.3ms preprocess, 3.6ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 3.6ms\n",
      "Speed: 1.4ms preprocess, 3.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 3.6ms\n",
      "Speed: 1.3ms preprocess, 3.6ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 3.6ms\n",
      "Speed: 1.4ms preprocess, 3.6ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 3.6ms\n",
      "Speed: 1.3ms preprocess, 3.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 4.0ms\n",
      "Speed: 2.6ms preprocess, 4.0ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 3.6ms\n",
      "Speed: 1.4ms preprocess, 3.6ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 3.6ms\n",
      "Speed: 1.5ms preprocess, 3.6ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 3.6ms\n",
      "Speed: 1.3ms preprocess, 3.6ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 3.6ms\n",
      "Speed: 1.4ms preprocess, 3.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 3.6ms\n",
      "Speed: 1.5ms preprocess, 3.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 3.6ms\n",
      "Speed: 1.4ms preprocess, 3.6ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Video frame is empty or video processing has been successfully completed.\n",
      "Polygon Counter Initiated.\n",
      "\n",
      "0: 640x640 2 Fishs, 3.6ms\n",
      "Speed: 1.5ms preprocess, 3.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 4 Fishs, 3.8ms\n",
      "Speed: 1.7ms preprocess, 3.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 3 Fishs, 3.8ms\n",
      "Speed: 1.4ms preprocess, 3.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 4 Fishs, 8.7ms\n",
      "Speed: 3.0ms preprocess, 8.7ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 Fishs, 4.3ms\n",
      "Speed: 1.5ms preprocess, 4.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 Fishs, 3.8ms\n",
      "Speed: 1.3ms preprocess, 3.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Video frame is empty or video processing has been successfully completed.\n",
      "Polygon Counter Initiated.\n",
      "\n",
      "0: 640x640 1 Fish, 3.8ms\n",
      "Speed: 1.2ms preprocess, 3.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Fish, 3.9ms\n",
      "Speed: 1.4ms preprocess, 3.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Video frame is empty or video processing has been successfully completed.\n",
      "Polygon Counter Initiated.\n",
      "\n",
      "0: 640x640 7 Fishs, 3.8ms\n",
      "Speed: 1.3ms preprocess, 3.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 9 Fishs, 3.9ms\n",
      "Speed: 1.3ms preprocess, 3.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 Fishs, 3.9ms\n",
      "Speed: 1.4ms preprocess, 3.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 3 Fishs, 3.8ms\n",
      "Speed: 1.4ms preprocess, 3.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 3 Fishs, 3.9ms\n",
      "Speed: 1.4ms preprocess, 3.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Fish, 3.8ms\n",
      "Speed: 1.3ms preprocess, 3.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 Fishs, 3.9ms\n",
      "Speed: 1.8ms preprocess, 3.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 Fishs, 4.4ms\n",
      "Speed: 1.7ms preprocess, 4.4ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 4 Fishs, 3.9ms\n",
      "Speed: 1.4ms preprocess, 3.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 6 Fishs, 3.9ms\n",
      "Speed: 1.4ms preprocess, 3.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 3 Fishs, 3.9ms\n",
      "Speed: 1.4ms preprocess, 3.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 3 Fishs, 3.8ms\n",
      "Speed: 1.3ms preprocess, 3.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 3 Fishs, 3.9ms\n",
      "Speed: 1.4ms preprocess, 3.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 3 Fishs, 3.9ms\n",
      "Speed: 1.4ms preprocess, 3.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 4 Fishs, 3.9ms\n",
      "Speed: 1.4ms preprocess, 3.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 3 Fishs, 7.4ms\n",
      "Speed: 1.5ms preprocess, 7.4ms inference, 2.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 5 Fishs, 3.9ms\n",
      "Speed: 1.5ms preprocess, 3.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 3 Fishs, 3.9ms\n",
      "Speed: 1.4ms preprocess, 3.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 4 Fishs, 3.9ms\n",
      "Speed: 1.5ms preprocess, 3.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Fish, 3.9ms\n",
      "Speed: 1.4ms preprocess, 3.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 5 Fishs, 3.9ms\n",
      "Speed: 1.4ms preprocess, 3.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 Fishs, 3.8ms\n",
      "Speed: 1.4ms preprocess, 3.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 Fishs, 3.9ms\n",
      "Speed: 1.4ms preprocess, 3.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Fish, 3.9ms\n",
      "Speed: 1.6ms preprocess, 3.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 Fishs, 3.9ms\n",
      "Speed: 1.4ms preprocess, 3.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 3 Fishs, 3.9ms\n",
      "Speed: 1.4ms preprocess, 3.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 Fishs, 3.9ms\n",
      "Speed: 1.4ms preprocess, 3.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Fish, 3.9ms\n",
      "Speed: 1.3ms preprocess, 3.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 4 Fishs, 3.9ms\n",
      "Speed: 1.4ms preprocess, 3.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 3 Fishs, 3.9ms\n",
      "Speed: 1.4ms preprocess, 3.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 Fishs, 3.9ms\n",
      "Speed: 1.4ms preprocess, 3.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 4 Fishs, 4.4ms\n",
      "Speed: 3.2ms preprocess, 4.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 8 Fishs, 3.9ms\n",
      "Speed: 1.4ms preprocess, 3.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Fish, 3.9ms\n",
      "Speed: 1.4ms preprocess, 3.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 3 Fishs, 3.7ms\n",
      "Speed: 1.5ms preprocess, 3.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Fish, 3.6ms\n",
      "Speed: 1.4ms preprocess, 3.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Fish, 3.6ms\n",
      "Speed: 1.4ms preprocess, 3.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 3 Fishs, 3.6ms\n",
      "Speed: 1.4ms preprocess, 3.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 Fishs, 3.6ms\n",
      "Speed: 1.4ms preprocess, 3.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Video frame is empty or video processing has been successfully completed.\n",
      "Polygon Counter Initiated.\n",
      "\n",
      "0: 640x640 1 Fish, 3.6ms\n",
      "Speed: 1.3ms preprocess, 3.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Fish, 3.6ms\n",
      "Speed: 1.4ms preprocess, 3.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Fish, 3.6ms\n",
      "Speed: 1.4ms preprocess, 3.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Fish, 3.6ms\n",
      "Speed: 1.4ms preprocess, 3.6ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Fish, 3.6ms\n",
      "Speed: 1.4ms preprocess, 3.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Fish, 3.6ms\n",
      "Speed: 1.4ms preprocess, 3.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Fish, 3.6ms\n",
      "Speed: 1.4ms preprocess, 3.6ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Fish, 3.6ms\n",
      "Speed: 1.3ms preprocess, 3.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Video frame is empty or video processing has been successfully completed.\n",
      "Polygon Counter Initiated.\n",
      "\n",
      "0: 640x640 1 Fish, 3.6ms\n",
      "Speed: 1.3ms preprocess, 3.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Fish, 3.6ms\n",
      "Speed: 1.3ms preprocess, 3.6ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 Fishs, 4.2ms\n",
      "Speed: 2.7ms preprocess, 4.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Fish, 3.6ms\n",
      "Speed: 1.3ms preprocess, 3.6ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Video frame is empty or video processing has been successfully completed.\n",
      "Polygon Counter Initiated.\n",
      "\n",
      "0: 640x640 1 Fish, 3.6ms\n",
      "Speed: 1.3ms preprocess, 3.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Fish, 3.6ms\n",
      "Speed: 1.4ms preprocess, 3.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Fish, 5.7ms\n",
      "Speed: 2.7ms preprocess, 5.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Fish, 3.6ms\n",
      "Speed: 1.4ms preprocess, 3.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Fish, 3.6ms\n",
      "Speed: 1.4ms preprocess, 3.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Fish, 3.6ms\n",
      "Speed: 1.3ms preprocess, 3.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Fish, 3.6ms\n",
      "Speed: 1.4ms preprocess, 3.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Video frame is empty or video processing has been successfully completed.\n",
      "Polygon Counter Initiated.\n",
      "\n",
      "0: 640x640 (no detections), 3.6ms\n",
      "Speed: 1.3ms preprocess, 3.6ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 3.6ms\n",
      "Speed: 1.4ms preprocess, 3.6ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 3.6ms\n",
      "Speed: 1.4ms preprocess, 3.6ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 3.6ms\n",
      "Speed: 1.4ms preprocess, 3.6ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 4.6ms\n",
      "Speed: 2.8ms preprocess, 4.6ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Video frame is empty or video processing has been successfully completed.\n",
      "Polygon Counter Initiated.\n",
      "\n",
      "0: 640x640 2 Fishs, 3.6ms\n",
      "Speed: 1.3ms preprocess, 3.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Fish, 3.6ms\n",
      "Speed: 1.8ms preprocess, 3.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Fish, 3.6ms\n",
      "Speed: 1.7ms preprocess, 3.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Video frame is empty or video processing has been successfully completed.\n",
      "Polygon Counter Initiated.\n",
      "\n",
      "0: 640x640 1 Fish, 3.6ms\n",
      "Speed: 1.3ms preprocess, 3.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Fish, 3.6ms\n",
      "Speed: 1.4ms preprocess, 3.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Video frame is empty or video processing has been successfully completed.\n",
      "Polygon Counter Initiated.\n",
      "\n",
      "0: 640x640 5 Fishs, 3.6ms\n",
      "Speed: 1.3ms preprocess, 3.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 5 Fishs, 3.6ms\n",
      "Speed: 1.4ms preprocess, 3.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 7 Fishs, 3.6ms\n",
      "Speed: 1.3ms preprocess, 3.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Video frame is empty or video processing has been successfully completed.\n",
      "Polygon Counter Initiated.\n",
      "\n",
      "0: 640x640 1 Fish, 3.6ms\n",
      "Speed: 1.3ms preprocess, 3.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Fish, 3.6ms\n",
      "Speed: 1.4ms preprocess, 3.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Fish, 3.6ms\n",
      "Speed: 1.4ms preprocess, 3.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Fish, 3.6ms\n",
      "Speed: 1.4ms preprocess, 3.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Video frame is empty or video processing has been successfully completed.\n",
      "Polygon Counter Initiated.\n",
      "\n",
      "0: 640x640 (no detections), 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 3.6ms\n",
      "Speed: 1.4ms preprocess, 3.6ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 3.6ms\n",
      "Speed: 1.4ms preprocess, 3.6ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 3.6ms\n",
      "Speed: 1.4ms preprocess, 3.6ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 3.6ms\n",
      "Speed: 1.3ms preprocess, 3.6ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 3.6ms\n",
      "Speed: 1.4ms preprocess, 3.6ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 3.6ms\n",
      "Speed: 1.5ms preprocess, 3.6ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 3.6ms\n",
      "Speed: 1.4ms preprocess, 3.6ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Video frame is empty or video processing has been successfully completed.\n",
      "Polygon Counter Initiated.\n",
      "\n",
      "0: 640x640 (no detections), 3.6ms\n",
      "Speed: 1.4ms preprocess, 3.6ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 3.6ms\n",
      "Speed: 1.5ms preprocess, 3.6ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 4.6ms\n",
      "Speed: 3.1ms preprocess, 4.6ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 3.6ms\n",
      "Speed: 1.3ms preprocess, 3.6ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 3.6ms\n",
      "Speed: 1.3ms preprocess, 3.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 3.6ms\n",
      "Speed: 1.4ms preprocess, 3.6ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 3.6ms\n",
      "Speed: 1.4ms preprocess, 3.6ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Video frame is empty or video processing has been successfully completed.\n",
      "Polygon Counter Initiated.\n",
      "\n",
      "0: 640x640 (no detections), 3.6ms\n",
      "Speed: 1.3ms preprocess, 3.6ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 3.6ms\n",
      "Speed: 1.4ms preprocess, 3.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 3.6ms\n",
      "Speed: 1.4ms preprocess, 3.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 3.6ms\n",
      "Speed: 1.3ms preprocess, 3.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Video frame is empty or video processing has been successfully completed.\n",
      "Polygon Counter Initiated.\n",
      "\n",
      "0: 640x640 (no detections), 3.6ms\n",
      "Speed: 1.3ms preprocess, 3.6ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 3.6ms\n",
      "Speed: 1.4ms preprocess, 3.6ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 3.6ms\n",
      "Speed: 1.3ms preprocess, 3.6ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 3.6ms\n",
      "Speed: 1.3ms preprocess, 3.6ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 3.6ms\n",
      "Speed: 1.3ms preprocess, 3.6ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Video frame is empty or video processing has been successfully completed.\n",
      "Polygon Counter Initiated.\n",
      "\n",
      "0: 640x640 1 Fish, 3.6ms\n",
      "Speed: 1.4ms preprocess, 3.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Fish, 6.1ms\n",
      "Speed: 5.5ms preprocess, 6.1ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Fish, 3.6ms\n",
      "Speed: 1.5ms preprocess, 3.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Fish, 3.6ms\n",
      "Speed: 1.3ms preprocess, 3.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Fish, 3.6ms\n",
      "Speed: 1.4ms preprocess, 3.6ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Video frame is empty or video processing has been successfully completed.\n",
      "Polygon Counter Initiated.\n",
      "\n",
      "0: 640x640 (no detections), 3.6ms\n",
      "Speed: 1.3ms preprocess, 3.6ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 8.0ms\n",
      "Speed: 2.5ms preprocess, 8.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 3.6ms\n",
      "Speed: 1.4ms preprocess, 3.6ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 3.6ms\n",
      "Speed: 1.4ms preprocess, 3.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 3.6ms\n",
      "Speed: 1.3ms preprocess, 3.6ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 3.6ms\n",
      "Speed: 1.3ms preprocess, 3.6ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 3.6ms\n",
      "Speed: 1.4ms preprocess, 3.6ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 3.6ms\n",
      "Speed: 1.3ms preprocess, 3.6ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 3.6ms\n",
      "Speed: 1.3ms preprocess, 3.6ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 6.4ms\n",
      "Speed: 2.5ms preprocess, 6.4ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 3.6ms\n",
      "Speed: 1.4ms preprocess, 3.6ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 3.6ms\n",
      "Speed: 1.4ms preprocess, 3.6ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 3.6ms\n",
      "Speed: 1.3ms preprocess, 3.6ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 3.6ms\n",
      "Speed: 1.4ms preprocess, 3.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 3.6ms\n",
      "Speed: 1.3ms preprocess, 3.6ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 3.6ms\n",
      "Speed: 1.4ms preprocess, 3.6ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 3.6ms\n",
      "Speed: 1.4ms preprocess, 3.6ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 3.6ms\n",
      "Speed: 1.4ms preprocess, 3.6ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 3.6ms\n",
      "Speed: 1.4ms preprocess, 3.6ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 3.6ms\n",
      "Speed: 1.3ms preprocess, 3.6ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 3.6ms\n",
      "Speed: 1.4ms preprocess, 3.6ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 3.6ms\n",
      "Speed: 1.4ms preprocess, 3.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Video frame is empty or video processing has been successfully completed.\n",
      "Polygon Counter Initiated.\n",
      "\n",
      "0: 640x640 4 Fishs, 3.6ms\n",
      "Speed: 1.3ms preprocess, 3.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 10 Fishs, 3.7ms\n",
      "Speed: 1.6ms preprocess, 3.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 4 Fishs, 3.7ms\n",
      "Speed: 1.4ms preprocess, 3.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 9 Fishs, 3.7ms\n",
      "Speed: 1.4ms preprocess, 3.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 Fishs, 3.7ms\n",
      "Speed: 1.3ms preprocess, 3.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Fish, 4.0ms\n",
      "Speed: 2.8ms preprocess, 4.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 4 Fishs, 3.7ms\n",
      "Speed: 1.3ms preprocess, 3.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 5 Fishs, 3.7ms\n",
      "Speed: 1.3ms preprocess, 3.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 5 Fishs, 3.7ms\n",
      "Speed: 1.3ms preprocess, 3.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 5 Fishs, 3.7ms\n",
      "Speed: 1.3ms preprocess, 3.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 11 Fishs, 3.7ms\n",
      "Speed: 1.3ms preprocess, 3.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 5 Fishs, 3.7ms\n",
      "Speed: 1.4ms preprocess, 3.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 Fishs, 3.7ms\n",
      "Speed: 2.5ms preprocess, 3.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 4 Fishs, 3.7ms\n",
      "Speed: 1.4ms preprocess, 3.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 3 Fishs, 3.7ms\n",
      "Speed: 1.3ms preprocess, 3.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Fish, 3.7ms\n",
      "Speed: 1.3ms preprocess, 3.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 11 Fishs, 3.7ms\n",
      "Speed: 1.3ms preprocess, 3.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Fish, 3.7ms\n",
      "Speed: 1.3ms preprocess, 3.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 Fishs, 3.7ms\n",
      "Speed: 1.3ms preprocess, 3.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 Fishs, 3.7ms\n",
      "Speed: 1.3ms preprocess, 3.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 6 Fishs, 3.7ms\n",
      "Speed: 1.4ms preprocess, 3.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 Fishs, 3.7ms\n",
      "Speed: 1.4ms preprocess, 3.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 Fishs, 3.7ms\n",
      "Speed: 1.3ms preprocess, 3.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Fish, 3.7ms\n",
      "Speed: 1.4ms preprocess, 3.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 Fishs, 3.7ms\n",
      "Speed: 1.3ms preprocess, 3.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 7 Fishs, 4.0ms\n",
      "Speed: 2.6ms preprocess, 4.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 4 Fishs, 3.7ms\n",
      "Speed: 1.3ms preprocess, 3.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Fish, 3.7ms\n",
      "Speed: 1.3ms preprocess, 3.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 8 Fishs, 3.7ms\n",
      "Speed: 1.3ms preprocess, 3.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 15 Fishs, 3.7ms\n",
      "Speed: 1.3ms preprocess, 3.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Fish, 3.7ms\n",
      "Speed: 1.4ms preprocess, 3.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Fish, 7.8ms\n",
      "Speed: 2.5ms preprocess, 7.8ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 8 Fishs, 3.8ms\n",
      "Speed: 1.4ms preprocess, 3.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 8 Fishs, 3.7ms\n",
      "Speed: 1.5ms preprocess, 3.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 7 Fishs, 3.7ms\n",
      "Speed: 1.3ms preprocess, 3.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 14 Fishs, 3.7ms\n",
      "Speed: 1.3ms preprocess, 3.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 Fishs, 3.8ms\n",
      "Speed: 1.3ms preprocess, 3.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Fish, 3.7ms\n",
      "Speed: 1.3ms preprocess, 3.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 7 Fishs, 3.7ms\n",
      "Speed: 1.3ms preprocess, 3.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 4 Fishs, 3.7ms\n",
      "Speed: 1.3ms preprocess, 3.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 5 Fishs, 3.7ms\n",
      "Speed: 1.3ms preprocess, 3.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 3 Fishs, 3.8ms\n",
      "Speed: 1.4ms preprocess, 3.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 Fishs, 3.8ms\n",
      "Speed: 1.4ms preprocess, 3.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Fish, 3.8ms\n",
      "Speed: 1.5ms preprocess, 3.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 Fishs, 3.8ms\n",
      "Speed: 1.3ms preprocess, 3.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Fish, 3.8ms\n",
      "Speed: 1.3ms preprocess, 3.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Video frame is empty or video processing has been successfully completed.\n",
      "Polygon Counter Initiated.\n",
      "\n",
      "0: 640x640 (no detections), 3.7ms\n",
      "Speed: 1.3ms preprocess, 3.7ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 3.8ms\n",
      "Speed: 1.4ms preprocess, 3.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 3.8ms\n",
      "Speed: 1.3ms preprocess, 3.8ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 3.8ms\n",
      "Speed: 1.4ms preprocess, 3.8ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Video frame is empty or video processing has been successfully completed.\n",
      "Polygon Counter Initiated.\n",
      "\n",
      "0: 640x640 (no detections), 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 3.6ms\n",
      "Speed: 1.4ms preprocess, 3.6ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 3.6ms\n",
      "Speed: 1.3ms preprocess, 3.6ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 3.6ms\n",
      "Speed: 1.3ms preprocess, 3.6ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 8.0ms\n",
      "Speed: 2.8ms preprocess, 8.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 4.0ms\n",
      "Speed: 2.8ms preprocess, 4.0ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 3.6ms\n",
      "Speed: 1.4ms preprocess, 3.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 3.6ms\n",
      "Speed: 1.3ms preprocess, 3.6ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 3.6ms\n",
      "Speed: 1.6ms preprocess, 3.6ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 3.6ms\n",
      "Speed: 1.4ms preprocess, 3.6ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 3.6ms\n",
      "Speed: 1.3ms preprocess, 3.6ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 3.6ms\n",
      "Speed: 1.3ms preprocess, 3.6ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 3.6ms\n",
      "Speed: 1.3ms preprocess, 3.6ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 5.7ms\n",
      "Speed: 2.6ms preprocess, 5.7ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 3.6ms\n",
      "Speed: 1.3ms preprocess, 3.6ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 3.6ms\n",
      "Speed: 1.3ms preprocess, 3.6ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 3.7ms\n",
      "Speed: 1.3ms preprocess, 3.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 3.7ms\n",
      "Speed: 1.3ms preprocess, 3.7ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 3.8ms\n",
      "Speed: 1.4ms preprocess, 3.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 3.7ms\n",
      "Speed: 1.3ms preprocess, 3.7ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 3.7ms\n",
      "Speed: 1.3ms preprocess, 3.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Video frame is empty or video processing has been successfully completed.\n",
      "Polygon Counter Initiated.\n",
      "\n",
      "0: 640x640 1 Fish, 3.7ms\n",
      "Speed: 1.2ms preprocess, 3.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 3.8ms\n",
      "Speed: 1.4ms preprocess, 3.8ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 3.8ms\n",
      "Speed: 1.4ms preprocess, 3.8ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 3.8ms\n",
      "Speed: 1.3ms preprocess, 3.8ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 8.3ms\n",
      "Speed: 2.7ms preprocess, 8.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 3.8ms\n",
      "Speed: 1.3ms preprocess, 3.8ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 3.8ms\n",
      "Speed: 1.4ms preprocess, 3.8ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Video frame is empty or video processing has been successfully completed.\n",
      "Polygon Counter Initiated.\n",
      "\n",
      "0: 640x640 (no detections), 3.8ms\n",
      "Speed: 1.3ms preprocess, 3.8ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 3.8ms\n",
      "Speed: 1.3ms preprocess, 3.8ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 3.8ms\n",
      "Speed: 1.4ms preprocess, 3.8ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 3.8ms\n",
      "Speed: 1.3ms preprocess, 3.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 3.8ms\n",
      "Speed: 1.3ms preprocess, 3.8ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 3.8ms\n",
      "Speed: 1.3ms preprocess, 3.8ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 3.8ms\n",
      "Speed: 1.3ms preprocess, 3.8ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 3.8ms\n",
      "Speed: 1.5ms preprocess, 3.8ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 3.8ms\n",
      "Speed: 1.3ms preprocess, 3.8ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 6.8ms\n",
      "Speed: 2.7ms preprocess, 6.8ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 3.8ms\n",
      "Speed: 1.3ms preprocess, 3.8ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 3.8ms\n",
      "Speed: 1.3ms preprocess, 3.8ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 3.8ms\n",
      "Speed: 1.4ms preprocess, 3.8ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Video frame is empty or video processing has been successfully completed.\n",
      "Polygon Counter Initiated.\n",
      "\n",
      "0: 640x640 2 Fishs, 3.7ms\n",
      "Speed: 1.3ms preprocess, 3.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Fish, 3.8ms\n",
      "Speed: 1.3ms preprocess, 3.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Fish, 3.8ms\n",
      "Speed: 1.4ms preprocess, 3.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Fish, 3.8ms\n",
      "Speed: 1.3ms preprocess, 3.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 3 Fishs, 3.8ms\n",
      "Speed: 1.3ms preprocess, 3.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 4 Fishs, 3.8ms\n",
      "Speed: 1.3ms preprocess, 3.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 5 Fishs, 7.9ms\n",
      "Speed: 2.6ms preprocess, 7.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 Fishs, 3.8ms\n",
      "Speed: 1.4ms preprocess, 3.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 3 Fishs, 3.8ms\n",
      "Speed: 1.3ms preprocess, 3.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 Fishs, 4.5ms\n",
      "Speed: 2.8ms preprocess, 4.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Fish, 5.1ms\n",
      "Speed: 2.6ms preprocess, 5.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 9 Fishs, 3.8ms\n",
      "Speed: 1.4ms preprocess, 3.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 4 Fishs, 3.8ms\n",
      "Speed: 1.3ms preprocess, 3.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Video frame is empty or video processing has been successfully completed.\n",
      "Polygon Counter Initiated.\n",
      "\n",
      "0: 640x640 (no detections), 3.8ms\n",
      "Speed: 1.2ms preprocess, 3.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 3.8ms\n",
      "Speed: 1.3ms preprocess, 3.8ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 3.8ms\n",
      "Speed: 1.3ms preprocess, 3.8ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 3.8ms\n",
      "Speed: 1.4ms preprocess, 3.8ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 3.8ms\n",
      "Speed: 1.4ms preprocess, 3.8ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Video frame is empty or video processing has been successfully completed.\n",
      "Polygon Counter Initiated.\n",
      "\n",
      "0: 640x640 1 Fish, 3.8ms\n",
      "Speed: 1.3ms preprocess, 3.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Video frame is empty or video processing has been successfully completed.\n",
      "Polygon Counter Initiated.\n",
      "\n",
      "0: 640x640 1 Fish, 3.8ms\n",
      "Speed: 1.3ms preprocess, 3.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Fish, 3.8ms\n",
      "Speed: 1.5ms preprocess, 3.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Fish, 3.8ms\n",
      "Speed: 1.3ms preprocess, 3.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Fish, 3.8ms\n",
      "Speed: 1.3ms preprocess, 3.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Fish, 3.8ms\n",
      "Speed: 1.3ms preprocess, 3.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Fish, 3.8ms\n",
      "Speed: 1.3ms preprocess, 3.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Video frame is empty or video processing has been successfully completed.\n",
      "Polygon Counter Initiated.\n",
      "\n",
      "0: 640x640 1 Fish, 3.8ms\n",
      "Speed: 1.3ms preprocess, 3.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Fish, 3.8ms\n",
      "Speed: 1.3ms preprocess, 3.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Fish, 3.9ms\n",
      "Speed: 1.4ms preprocess, 3.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Fish, 3.8ms\n",
      "Speed: 1.3ms preprocess, 3.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Fish, 3.8ms\n",
      "Speed: 1.8ms preprocess, 3.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Fish, 3.9ms\n",
      "Speed: 1.4ms preprocess, 3.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Fish, 3.8ms\n",
      "Speed: 1.3ms preprocess, 3.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Fish, 3.9ms\n",
      "Speed: 2.3ms preprocess, 3.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Video frame is empty or video processing has been successfully completed.\n",
      "Polygon Counter Initiated.\n",
      "\n",
      "0: 640x640 (no detections), 3.8ms\n",
      "Speed: 1.3ms preprocess, 3.8ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 5.5ms\n",
      "Speed: 1.7ms preprocess, 5.5ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 3.9ms\n",
      "Speed: 1.7ms preprocess, 3.9ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 3.9ms\n",
      "Speed: 1.4ms preprocess, 3.9ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 3.8ms\n",
      "Speed: 1.3ms preprocess, 3.8ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 3.9ms\n",
      "Speed: 1.3ms preprocess, 3.9ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 7.4ms\n",
      "Speed: 2.7ms preprocess, 7.4ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 3.9ms\n",
      "Speed: 1.4ms preprocess, 3.9ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 3.9ms\n",
      "Speed: 2.1ms preprocess, 3.9ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Video frame is empty or video processing has been successfully completed.\n",
      "Polygon Counter Initiated.\n",
      "\n",
      "0: 640x640 1 Fish, 3.9ms\n",
      "Speed: 1.3ms preprocess, 3.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Fish, 3.9ms\n",
      "Speed: 1.9ms preprocess, 3.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Fish, 7.9ms\n",
      "Speed: 3.0ms preprocess, 7.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Fish, 3.9ms\n",
      "Speed: 1.5ms preprocess, 3.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 Fishs, 4.1ms\n",
      "Speed: 1.3ms preprocess, 4.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 Fishs, 3.8ms\n",
      "Speed: 1.3ms preprocess, 3.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 Fishs, 3.8ms\n",
      "Speed: 1.3ms preprocess, 3.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 Fishs, 3.8ms\n",
      "Speed: 1.3ms preprocess, 3.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Fish, 3.8ms\n",
      "Speed: 1.3ms preprocess, 3.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Video frame is empty or video processing has been successfully completed.\n",
      "Polygon Counter Initiated.\n",
      "\n",
      "0: 640x640 2 Fishs, 3.8ms\n",
      "Speed: 1.3ms preprocess, 3.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Video frame is empty or video processing has been successfully completed.\n",
      "Polygon Counter Initiated.\n",
      "\n",
      "0: 640x640 2 Fishs, 3.8ms\n",
      "Speed: 1.3ms preprocess, 3.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Fish, 3.9ms\n",
      "Speed: 2.8ms preprocess, 3.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 Fishs, 3.9ms\n",
      "Speed: 1.3ms preprocess, 3.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Video frame is empty or video processing has been successfully completed.\n",
      "Polygon Counter Initiated.\n",
      "\n",
      "0: 640x640 1 Fish, 3.8ms\n",
      "Speed: 1.3ms preprocess, 3.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Fish, 3.8ms\n",
      "Speed: 1.4ms preprocess, 3.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Fish, 3.8ms\n",
      "Speed: 1.4ms preprocess, 3.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Video frame is empty or video processing has been successfully completed.\n",
      "Polygon Counter Initiated.\n",
      "\n",
      "0: 640x640 1 Fish, 3.8ms\n",
      "Speed: 1.3ms preprocess, 3.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Fish, 3.8ms\n",
      "Speed: 1.4ms preprocess, 3.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Video frame is empty or video processing has been successfully completed.\n",
      "Polygon Counter Initiated.\n",
      "\n",
      "0: 640x640 1 Fish, 3.8ms\n",
      "Speed: 1.3ms preprocess, 3.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Fish, 3.8ms\n",
      "Speed: 1.3ms preprocess, 3.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Video frame is empty or video processing has been successfully completed.\n",
      "Polygon Counter Initiated.\n",
      "\n",
      "0: 640x640 3 Fishs, 3.6ms\n",
      "Speed: 1.3ms preprocess, 3.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 3 Fishs, 3.6ms\n",
      "Speed: 1.4ms preprocess, 3.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 3 Fishs, 5.0ms\n",
      "Speed: 2.7ms preprocess, 5.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Fish, 3.6ms\n",
      "Speed: 1.3ms preprocess, 3.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Fish, 3.6ms\n",
      "Speed: 2.6ms preprocess, 3.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 4 Fishs, 3.6ms\n",
      "Speed: 1.3ms preprocess, 3.6ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 6 Fishs, 3.6ms\n",
      "Speed: 1.4ms preprocess, 3.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Fish, 3.6ms\n",
      "Speed: 1.3ms preprocess, 3.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Fish, 3.6ms\n",
      "Speed: 1.6ms preprocess, 3.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Video frame is empty or video processing has been successfully completed.\n",
      "Polygon Counter Initiated.\n",
      "\n",
      "0: 640x640 1 Fish, 3.5ms\n",
      "Speed: 1.2ms preprocess, 3.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Fish, 5.1ms\n",
      "Speed: 2.6ms preprocess, 5.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 Fishs, 3.6ms\n",
      "Speed: 1.4ms preprocess, 3.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 Fishs, 6.4ms\n",
      "Speed: 2.6ms preprocess, 6.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 Fishs, 3.6ms\n",
      "Speed: 1.3ms preprocess, 3.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Video frame is empty or video processing has been successfully completed.\n",
      "Polygon Counter Initiated.\n",
      "\n",
      "0: 640x640 4 Fishs, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Fish, 3.6ms\n",
      "Speed: 1.4ms preprocess, 3.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 5 Fishs, 3.6ms\n",
      "Speed: 1.4ms preprocess, 3.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 27 Fishs, 3.6ms\n",
      "Speed: 1.4ms preprocess, 3.6ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 3 Fishs, 3.6ms\n",
      "Speed: 2.3ms preprocess, 3.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 3 Fishs, 3.6ms\n",
      "Speed: 1.3ms preprocess, 3.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 5 Fishs, 3.6ms\n",
      "Speed: 1.3ms preprocess, 3.6ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 4 Fishs, 3.6ms\n",
      "Speed: 1.5ms preprocess, 3.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 Fishs, 3.6ms\n",
      "Speed: 1.4ms preprocess, 3.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 Fishs, 3.6ms\n",
      "Speed: 1.4ms preprocess, 3.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Fish, 3.6ms\n",
      "Speed: 1.4ms preprocess, 3.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 5 Fishs, 3.6ms\n",
      "Speed: 1.4ms preprocess, 3.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Fish, 4.0ms\n",
      "Speed: 2.8ms preprocess, 4.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 16 Fishs, 3.6ms\n",
      "Speed: 1.3ms preprocess, 3.6ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 3 Fishs, 6.5ms\n",
      "Speed: 2.6ms preprocess, 6.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 4 Fishs, 3.6ms\n",
      "Speed: 1.4ms preprocess, 3.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Fish, 3.6ms\n",
      "Speed: 1.4ms preprocess, 3.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 3 Fishs, 3.6ms\n",
      "Speed: 1.4ms preprocess, 3.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 8 Fishs, 3.6ms\n",
      "Speed: 1.5ms preprocess, 3.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Fish, 3.6ms\n",
      "Speed: 1.4ms preprocess, 3.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 4 Fishs, 3.6ms\n",
      "Speed: 1.4ms preprocess, 3.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Fish, 3.6ms\n",
      "Speed: 1.4ms preprocess, 3.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 4 Fishs, 3.6ms\n",
      "Speed: 1.3ms preprocess, 3.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Fish, 3.6ms\n",
      "Speed: 1.3ms preprocess, 3.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Fish, 3.6ms\n",
      "Speed: 1.3ms preprocess, 3.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 Fishs, 3.6ms\n",
      "Speed: 1.4ms preprocess, 3.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 Fishs, 3.6ms\n",
      "Speed: 1.4ms preprocess, 3.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 3 Fishs, 3.6ms\n",
      "Speed: 1.4ms preprocess, 3.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 4 Fishs, 3.6ms\n",
      "Speed: 1.5ms preprocess, 3.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 3 Fishs, 3.7ms\n",
      "Speed: 1.3ms preprocess, 3.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 4 Fishs, 3.6ms\n",
      "Speed: 1.4ms preprocess, 3.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Video frame is empty or video processing has been successfully completed.\n",
      "Polygon Counter Initiated.\n",
      "\n",
      "0: 640x640 2 Fishs, 3.6ms\n",
      "Speed: 1.3ms preprocess, 3.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Fish, 3.6ms\n",
      "Speed: 1.3ms preprocess, 3.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 3 Fishs, 3.6ms\n",
      "Speed: 1.3ms preprocess, 3.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 3 Fishs, 3.6ms\n",
      "Speed: 1.3ms preprocess, 3.6ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 3 Fishs, 5.5ms\n",
      "Speed: 2.8ms preprocess, 5.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 3 Fishs, 3.6ms\n",
      "Speed: 1.3ms preprocess, 3.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 3 Fishs, 3.6ms\n",
      "Speed: 1.3ms preprocess, 3.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 3 Fishs, 3.6ms\n",
      "Speed: 2.1ms preprocess, 3.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 3 Fishs, 3.6ms\n",
      "Speed: 1.3ms preprocess, 3.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 3 Fishs, 3.6ms\n",
      "Speed: 1.3ms preprocess, 3.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 Fishs, 3.6ms\n",
      "Speed: 1.3ms preprocess, 3.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Fish, 3.6ms\n",
      "Speed: 1.3ms preprocess, 3.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 Fishs, 3.6ms\n",
      "Speed: 1.3ms preprocess, 3.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Fish, 3.6ms\n",
      "Speed: 1.4ms preprocess, 3.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Fish, 3.6ms\n",
      "Speed: 1.3ms preprocess, 3.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Fish, 3.6ms\n",
      "Speed: 1.3ms preprocess, 3.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Fish, 3.6ms\n",
      "Speed: 1.3ms preprocess, 3.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Video frame is empty or video processing has been successfully completed.\n",
      "Polygon Counter Initiated.\n",
      "\n",
      "0: 640x640 2 Fishs, 3.8ms\n",
      "Speed: 1.3ms preprocess, 3.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 Fishs, 3.9ms\n",
      "Speed: 1.4ms preprocess, 3.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Fish, 4.7ms\n",
      "Speed: 1.3ms preprocess, 4.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Fish, 3.8ms\n",
      "Speed: 1.3ms preprocess, 3.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Fish, 3.9ms\n",
      "Speed: 1.5ms preprocess, 3.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Fish, 3.8ms\n",
      "Speed: 1.3ms preprocess, 3.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 Fishs, 3.9ms\n",
      "Speed: 1.5ms preprocess, 3.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 Fishs, 3.9ms\n",
      "Speed: 1.4ms preprocess, 3.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Fish, 3.8ms\n",
      "Speed: 1.3ms preprocess, 3.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Fish, 3.9ms\n",
      "Speed: 1.5ms preprocess, 3.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Fish, 3.9ms\n",
      "Speed: 1.4ms preprocess, 3.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Video frame is empty or video processing has been successfully completed.\n",
      "Polygon Counter Initiated.\n",
      "\n",
      "0: 640x640 (no detections), 3.8ms\n",
      "Speed: 1.3ms preprocess, 3.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 4.2ms\n",
      "Speed: 2.7ms preprocess, 4.2ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Fish, 3.9ms\n",
      "Speed: 1.4ms preprocess, 3.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 3.8ms\n",
      "Speed: 1.3ms preprocess, 3.8ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 3.8ms\n",
      "Speed: 1.3ms preprocess, 3.8ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 3.8ms\n",
      "Speed: 1.3ms preprocess, 3.8ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 3.8ms\n",
      "Speed: 1.8ms preprocess, 3.8ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Fish, 3.9ms\n",
      "Speed: 1.4ms preprocess, 3.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 3.9ms\n",
      "Speed: 1.4ms preprocess, 3.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Video frame is empty or video processing has been successfully completed.\n",
      "Polygon Counter Initiated.\n",
      "\n",
      "0: 640x640 1 Fish, 3.8ms\n",
      "Speed: 1.2ms preprocess, 3.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Fish, 6.0ms\n",
      "Speed: 1.7ms preprocess, 6.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Fish, 3.9ms\n",
      "Speed: 1.4ms preprocess, 3.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Fish, 3.8ms\n",
      "Speed: 1.3ms preprocess, 3.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Fish, 3.9ms\n",
      "Speed: 1.4ms preprocess, 3.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Fish, 3.8ms\n",
      "Speed: 1.3ms preprocess, 3.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Fish, 3.9ms\n",
      "Speed: 1.4ms preprocess, 3.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Fish, 3.8ms\n",
      "Speed: 1.3ms preprocess, 3.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Fish, 3.8ms\n",
      "Speed: 1.3ms preprocess, 3.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Fish, 3.9ms\n",
      "Speed: 1.3ms preprocess, 3.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Fish, 3.9ms\n",
      "Speed: 1.3ms preprocess, 3.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Video frame is empty or video processing has been successfully completed.\n",
      "Polygon Counter Initiated.\n",
      "\n",
      "0: 640x640 (no detections), 3.8ms\n",
      "Speed: 1.3ms preprocess, 3.8ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 6.9ms\n",
      "Speed: 2.7ms preprocess, 6.9ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 3.8ms\n",
      "Speed: 1.4ms preprocess, 3.8ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 3.8ms\n",
      "Speed: 1.3ms preprocess, 3.8ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 3.9ms\n",
      "Speed: 1.4ms preprocess, 3.9ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 3.8ms\n",
      "Speed: 1.3ms preprocess, 3.8ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 3.8ms\n",
      "Speed: 1.3ms preprocess, 3.8ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 3.9ms\n",
      "Speed: 1.4ms preprocess, 3.9ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 3.8ms\n",
      "Speed: 1.3ms preprocess, 3.8ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 3.8ms\n",
      "Speed: 1.3ms preprocess, 3.8ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 3.8ms\n",
      "Speed: 1.2ms preprocess, 3.8ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 3.9ms\n",
      "Speed: 1.3ms preprocess, 3.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 3.8ms\n",
      "Speed: 1.3ms preprocess, 3.8ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 3.9ms\n",
      "Speed: 1.5ms preprocess, 3.9ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 3.8ms\n",
      "Speed: 1.3ms preprocess, 3.8ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 3.8ms\n",
      "Speed: 1.3ms preprocess, 3.8ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 3.8ms\n",
      "Speed: 1.4ms preprocess, 3.8ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 3.8ms\n",
      "Speed: 1.8ms preprocess, 3.8ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 3.8ms\n",
      "Speed: 1.5ms preprocess, 3.8ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Video frame is empty or video processing has been successfully completed.\n",
      "Polygon Counter Initiated.\n",
      "\n",
      "0: 640x640 1 Fish, 3.7ms\n",
      "Speed: 1.2ms preprocess, 3.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Fish, 4.6ms\n",
      "Speed: 2.8ms preprocess, 4.6ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Fish, 3.8ms\n",
      "Speed: 1.4ms preprocess, 3.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Fish, 3.8ms\n",
      "Speed: 1.4ms preprocess, 3.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Fish, 3.8ms\n",
      "Speed: 1.3ms preprocess, 3.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Video frame is empty or video processing has been successfully completed.\n",
      "Polygon Counter Initiated.\n",
      "\n",
      "0: 640x640 4 Fishs, 3.7ms\n",
      "Speed: 1.2ms preprocess, 3.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Fish, 3.8ms\n",
      "Speed: 1.3ms preprocess, 3.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 6 Fishs, 3.8ms\n",
      "Speed: 1.3ms preprocess, 3.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Fish, 3.8ms\n",
      "Speed: 1.3ms preprocess, 3.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 6 Fishs, 3.8ms\n",
      "Speed: 1.4ms preprocess, 3.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 4 Fishs, 3.8ms\n",
      "Speed: 1.4ms preprocess, 3.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 6 Fishs, 3.8ms\n",
      "Speed: 1.3ms preprocess, 3.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 3 Fishs, 3.8ms\n",
      "Speed: 1.4ms preprocess, 3.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 4 Fishs, 3.8ms\n",
      "Speed: 1.3ms preprocess, 3.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 4 Fishs, 3.8ms\n",
      "Speed: 1.5ms preprocess, 3.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 4 Fishs, 3.8ms\n",
      "Speed: 1.3ms preprocess, 3.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 4 Fishs, 3.8ms\n",
      "Speed: 1.3ms preprocess, 3.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 3 Fishs, 3.8ms\n",
      "Speed: 1.3ms preprocess, 3.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Video frame is empty or video processing has been successfully completed.\n",
      "Polygon Counter Initiated.\n",
      "\n",
      "0: 640x640 (no detections), 3.8ms\n",
      "Speed: 1.2ms preprocess, 3.8ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Fish, 3.8ms\n",
      "Speed: 1.3ms preprocess, 3.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 3.8ms\n",
      "Speed: 1.3ms preprocess, 3.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 4.8ms\n",
      "Speed: 2.7ms preprocess, 4.8ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Video frame is empty or video processing has been successfully completed.\n",
      "Polygon Counter Initiated.\n",
      "\n",
      "0: 640x640 1 Fish, 3.8ms\n",
      "Speed: 1.3ms preprocess, 3.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Fish, 3.8ms\n",
      "Speed: 2.4ms preprocess, 3.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Fish, 4.3ms\n",
      "Speed: 2.7ms preprocess, 4.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Fish, 3.8ms\n",
      "Speed: 1.3ms preprocess, 3.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Video frame is empty or video processing has been successfully completed.\n",
      "Polygon Counter Initiated.\n",
      "\n",
      "0: 640x640 1 Fish, 3.8ms\n",
      "Speed: 1.3ms preprocess, 3.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Fish, 3.8ms\n",
      "Speed: 1.3ms preprocess, 3.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 3 Fishs, 3.8ms\n",
      "Speed: 1.4ms preprocess, 3.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 3 Fishs, 3.8ms\n",
      "Speed: 1.4ms preprocess, 3.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 3 Fishs, 3.9ms\n",
      "Speed: 1.4ms preprocess, 3.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Fish, 3.8ms\n",
      "Speed: 1.4ms preprocess, 3.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 Fishs, 3.8ms\n",
      "Speed: 1.3ms preprocess, 3.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Fish, 3.8ms\n",
      "Speed: 1.4ms preprocess, 3.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Fish, 3.9ms\n",
      "Speed: 1.4ms preprocess, 3.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 Fishs, 3.8ms\n",
      "Speed: 1.5ms preprocess, 3.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 Fishs, 3.9ms\n",
      "Speed: 1.4ms preprocess, 3.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Fish, 3.8ms\n",
      "Speed: 1.3ms preprocess, 3.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 Fishs, 3.8ms\n",
      "Speed: 1.3ms preprocess, 3.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 Fishs, 3.8ms\n",
      "Speed: 1.4ms preprocess, 3.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 Fishs, 3.9ms\n",
      "Speed: 1.4ms preprocess, 3.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 Fishs, 3.8ms\n",
      "Speed: 1.4ms preprocess, 3.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 Fishs, 3.8ms\n",
      "Speed: 1.3ms preprocess, 3.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 Fishs, 3.8ms\n",
      "Speed: 1.3ms preprocess, 3.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 Fishs, 3.8ms\n",
      "Speed: 1.3ms preprocess, 3.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 Fishs, 3.8ms\n",
      "Speed: 1.4ms preprocess, 3.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 Fishs, 3.8ms\n",
      "Speed: 1.3ms preprocess, 3.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 Fishs, 3.9ms\n",
      "Speed: 1.4ms preprocess, 3.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Video frame is empty or video processing has been successfully completed.\n",
      "Polygon Counter Initiated.\n",
      "\n",
      "0: 640x640 1 Fish, 3.8ms\n",
      "Speed: 1.3ms preprocess, 3.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Fish, 3.8ms\n",
      "Speed: 1.3ms preprocess, 3.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Fish, 3.8ms\n",
      "Speed: 1.4ms preprocess, 3.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Fish, 3.8ms\n",
      "Speed: 1.4ms preprocess, 3.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Fish, 3.9ms\n",
      "Speed: 1.3ms preprocess, 3.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Fish, 3.8ms\n",
      "Speed: 1.3ms preprocess, 3.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Fish, 3.8ms\n",
      "Speed: 1.4ms preprocess, 3.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Fish, 3.8ms\n",
      "Speed: 1.3ms preprocess, 3.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Fish, 3.8ms\n",
      "Speed: 1.3ms preprocess, 3.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Fish, 3.8ms\n",
      "Speed: 1.4ms preprocess, 3.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Fish, 3.8ms\n",
      "Speed: 1.4ms preprocess, 3.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Fish, 3.8ms\n",
      "Speed: 1.4ms preprocess, 3.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Fish, 3.8ms\n",
      "Speed: 1.3ms preprocess, 3.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Fish, 3.8ms\n",
      "Speed: 1.4ms preprocess, 3.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Video frame is empty or video processing has been successfully completed.\n",
      "Polygon Counter Initiated.\n",
      "\n",
      "0: 640x640 (no detections), 3.8ms\n",
      "Speed: 1.3ms preprocess, 3.8ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 6.5ms\n",
      "Speed: 2.9ms preprocess, 6.5ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 3.8ms\n",
      "Speed: 1.4ms preprocess, 3.8ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Fish, 3.8ms\n",
      "Speed: 1.3ms preprocess, 3.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 3.8ms\n",
      "Speed: 1.3ms preprocess, 3.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 3.8ms\n",
      "Speed: 1.4ms preprocess, 3.8ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 3.8ms\n",
      "Speed: 1.4ms preprocess, 3.8ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 3.8ms\n",
      "Speed: 1.4ms preprocess, 3.8ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 3.8ms\n",
      "Speed: 1.4ms preprocess, 3.8ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 3.8ms\n",
      "Speed: 1.3ms preprocess, 3.8ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 3.8ms\n",
      "Speed: 1.4ms preprocess, 3.8ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 3.8ms\n",
      "Speed: 1.4ms preprocess, 3.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 3.8ms\n",
      "Speed: 1.5ms preprocess, 3.8ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 3.8ms\n",
      "Speed: 1.3ms preprocess, 3.8ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 5.9ms\n",
      "Speed: 2.7ms preprocess, 5.9ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 3.8ms\n",
      "Speed: 1.4ms preprocess, 3.8ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 Fishs, 3.8ms\n",
      "Speed: 1.4ms preprocess, 3.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 3.8ms\n",
      "Speed: 1.4ms preprocess, 3.8ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 3.8ms\n",
      "Speed: 1.4ms preprocess, 3.8ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Fish, 3.8ms\n",
      "Speed: 1.4ms preprocess, 3.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 3.8ms\n",
      "Speed: 1.4ms preprocess, 3.8ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 3.9ms\n",
      "Speed: 1.5ms preprocess, 3.9ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Video frame is empty or video processing has been successfully completed.\n",
      "Polygon Counter Initiated.\n",
      "\n",
      "0: 640x640 (no detections), 3.6ms\n",
      "Speed: 1.3ms preprocess, 3.6ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 3.7ms\n",
      "Speed: 1.4ms preprocess, 3.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 3.7ms\n",
      "Speed: 1.3ms preprocess, 3.7ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 3.7ms\n",
      "Speed: 1.4ms preprocess, 3.7ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 4.0ms\n",
      "Speed: 2.5ms preprocess, 4.0ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 5.7ms\n",
      "Speed: 2.6ms preprocess, 5.7ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 3.7ms\n",
      "Speed: 1.3ms preprocess, 3.7ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 3.7ms\n",
      "Speed: 1.3ms preprocess, 3.7ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 3.7ms\n",
      "Speed: 1.4ms preprocess, 3.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 3.7ms\n",
      "Speed: 1.4ms preprocess, 3.7ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Video frame is empty or video processing has been successfully completed.\n"
     ]
    }
   ],
   "source": [
    "def get_fish_count(modelname, videoname):\n",
    "    # model = YOLO(\"model_trained_deepfish/256_epochs/weights/best.pt\")\n",
    "    # model = YOLO(\"runs/detect/train12/weights/best.pt\")\n",
    "    model = YOLO(modelname)\n",
    "    \n",
    "    # cap = cv2.VideoCapture(\"test_video/fish.mp4\")\n",
    "    # cap = cv2.VideoCapture(\"./datasets/videos/train/7398_F2.mp4\")\n",
    "    cap = cv2.VideoCapture(videoname)\n",
    "    assert cap.isOpened(), \"Error reading video file\"\n",
    "    \n",
    "    w, h, fps = (int(cap.get(x)) for x in (cv2.CAP_PROP_FRAME_WIDTH, cv2.CAP_PROP_FRAME_HEIGHT, cv2.CAP_PROP_FPS))\n",
    "    \n",
    "    # Define region points\n",
    "    region_points = [(0, 0), (w, 0), (w, h), (0, h)]\n",
    "    \n",
    "    # Video writer\n",
    "    video_writer = cv2.VideoWriter(\"output_video/fish_output.mp4\", cv2.VideoWriter_fourcc(*\"mp4v\"), fps, (w, h))\n",
    "    \n",
    "    # Init Object Counter\n",
    "    counter = solutions.ObjectCounter(\n",
    "        view_img=True,\n",
    "        reg_pts=region_points,\n",
    "        names=model.names,\n",
    "        draw_tracks=True,\n",
    "        line_thickness=1,\n",
    "    )\n",
    "    \n",
    "    while cap.isOpened():\n",
    "        success, im0 = cap.read()\n",
    "        if not success:\n",
    "            print(\"Video frame is empty or video processing has been successfully completed.\")\n",
    "            break\n",
    "        tracks = model.track(im0, persist=True, show=False)\n",
    "    \n",
    "        # print(counter.class_wise_count)\n",
    "        im0 = counter.start_counting(im0, tracks)\n",
    "        video_writer.write(im0)\n",
    "        # time.sleep(SLEEP * 3)\n",
    "    \n",
    "    # print(\"Total fish count:\", len(counter.track_history.keys()))\n",
    "    \n",
    "    cap.release()\n",
    "    video_writer.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "    return len(counter.track_history.keys())\n",
    "\n",
    "counts = {}\n",
    "for video in os.listdir('datasets/videos/test/'):\n",
    "    # print(video)\n",
    "    counts[video] = get_fish_count(modelname=\"runs/detect/original/weights/best.pt\", videoname=f\"./datasets/videos/test/{video}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "dd607a1d-a085-4c79-8d66-5a9ef1266651",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7117_Caranx_sexfasciatus_juvenile.mp4 23\n",
      "7117_no_fish_2.mp4 0\n",
      "7268_F1.mp4 52\n",
      "7393_F1.mp4 4\n",
      "7393_NF2.mp4 0\n",
      "7398_F1.mp4 8\n",
      "7398_F2.mp4 2\n",
      "7398_F3.mp4 1\n",
      "7398_F4.mp4 1\n",
      "7398_F5.mp4 2\n",
      "7398_F6.mp4 1\n",
      "7398_NF2.mp4 0\n",
      "7426_F1.mp4 3\n",
      "7426_F2.mp4 8\n",
      "7426_F3.mp4 1\n",
      "7426_NF1.mp4 0\n",
      "7434_F1.mp4 28\n",
      "7434_F2.mp4 2\n",
      "7434_NF2.mp4 0\n",
      "7434_NF3.mp4 0\n",
      "7463_F1.mp4 7\n",
      "7463_F2.mp4 5\n",
      "7463_F3.mp4 2\n",
      "7463_F4.mp4 11\n",
      "7463_F5.mp4 2\n",
      "7463_F6.mp4 5\n",
      "7463_F7.mp4 2\n",
      "7463_NF1.mp4 0\n",
      "7463_NF3.mp4 0\n",
      "7482_F1.mp4 4\n",
      "7482_F2.mp4 8\n",
      "7482_NF1.mp4 0\n",
      "7490_F1.mp4 3\n",
      "7490_F2.mp4 2\n",
      "7490_F3.mp4 1\n",
      "7490_F7.mp4 2\n",
      "7490_NF2.mp4 0\n",
      "7585_F1.mp4 6\n",
      "7585_NF2.mp4 0\n",
      "7623_F1.mp4 2\n",
      "7623_F2.mp4 6\n",
      "7623_NF1.mp4 0\n",
      "9852_Acanthopagrus_palmaris.mp4 2\n",
      "9852_Lutjanus_russellii_EJP.mp4 1\n",
      "9852_no_fish_2.mp4 0\n",
      "9862_Acanthopagrus_palmaris.mp4 2\n",
      "9862_no_fish.mp4 0\n",
      "9866_acanthopagrus_and_caranx.mp4 7\n",
      "9866_acanthopagrus_palmaris.mp4 4\n",
      "9866_no_fish.mp4 0\n",
      "9870_Gerres.mp4 2\n",
      "9870_no_fish.mp4 0\n",
      "9892_Acanthopagrus_palmaris_2.mp4 1\n",
      "9892_Caranx.mp4 1\n",
      "9892_acanthopagrus_palmaris.mp4 2\n",
      "9892_no_fish_2.mp4 0\n",
      "9894_Amniataba_caudivittatus.mp4 2\n",
      "9894_gerres.mp4 2\n",
      "9894_gerres_2.mp4 2\n",
      "9894_no_fish_2.mp4 0\n",
      "9898_Acanthopagrus_palmaris.mp4 1\n",
      "9898_no_fish.mp4 0\n",
      "9907_acanthopagrus_palmaris.mp4 5\n",
      "9907_no_fish_2.mp4 0\n",
      "9908_Acanthopagrus_palmaris.mp4 2\n",
      "9908_Epinephelus.mp4 1\n",
      "9908_no_fish_2.mp4 0\n"
     ]
    }
   ],
   "source": [
    "for k, v in sorted(counts.items()):\n",
    "    print(k, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "30975e47-284e-41cd-b02c-50ff64cfb470",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Polygon Counter Initiated.\n",
      "\n",
      "0: 640x640 7 Fishs, 3.6ms\n",
      "Speed: 1.3ms preprocess, 3.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Fish, 9.7ms\n",
      "Speed: 5.0ms preprocess, 9.7ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 5 Fishs, 3.6ms\n",
      "Speed: 1.7ms preprocess, 3.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Fish, 7.9ms\n",
      "Speed: 6.4ms preprocess, 7.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 6 Fishs, 5.8ms\n",
      "Speed: 3.1ms preprocess, 5.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 5 Fishs, 9.0ms\n",
      "Speed: 3.8ms preprocess, 9.0ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 6 Fishs, 9.3ms\n",
      "Speed: 6.9ms preprocess, 9.3ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 5 Fishs, 6.4ms\n",
      "Speed: 3.3ms preprocess, 6.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Fish, 6.8ms\n",
      "Speed: 4.4ms preprocess, 6.8ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Fish, 6.6ms\n",
      "Speed: 2.8ms preprocess, 6.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 Fishs, 8.0ms\n",
      "Speed: 4.1ms preprocess, 8.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 6 Fishs, 8.1ms\n",
      "Speed: 4.6ms preprocess, 8.1ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 12 Fishs, 8.0ms\n",
      "Speed: 5.0ms preprocess, 8.0ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 16 Fishs, 5.6ms\n",
      "Speed: 2.7ms preprocess, 5.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 4 Fishs, 8.1ms\n",
      "Speed: 4.1ms preprocess, 8.1ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 5 Fishs, 5.7ms\n",
      "Speed: 3.0ms preprocess, 5.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 Fishs, 7.7ms\n",
      "Speed: 3.5ms preprocess, 7.7ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 3 Fishs, 8.5ms\n",
      "Speed: 5.1ms preprocess, 8.5ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 10 Fishs, 7.4ms\n",
      "Speed: 3.1ms preprocess, 7.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 3 Fishs, 9.8ms\n",
      "Speed: 5.1ms preprocess, 9.8ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 5 Fishs, 7.6ms\n",
      "Speed: 4.7ms preprocess, 7.6ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Fish, 9.2ms\n",
      "Speed: 5.0ms preprocess, 9.2ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 4 Fishs, 6.8ms\n",
      "Speed: 4.9ms preprocess, 6.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Fish, 6.4ms\n",
      "Speed: 4.4ms preprocess, 6.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Fish, 3.6ms\n",
      "Speed: 2.6ms preprocess, 3.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 Fishs, 8.6ms\n",
      "Speed: 4.1ms preprocess, 8.6ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 Fishs, 7.7ms\n",
      "Speed: 4.3ms preprocess, 7.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 3 Fishs, 3.6ms\n",
      "Speed: 1.4ms preprocess, 3.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 3 Fishs, 7.2ms\n",
      "Speed: 4.2ms preprocess, 7.2ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 Fishs, 7.4ms\n",
      "Speed: 5.0ms preprocess, 7.4ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 3 Fishs, 9.3ms\n",
      "Speed: 4.2ms preprocess, 9.3ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Video frame is empty or video processing has been successfully completed.\n"
     ]
    }
   ],
   "source": [
    "# model = YOLO(\"model_trained_deepfish/256_epochs/weights/best.pt\")\n",
    "# model = YOLO(\"runs/detect/train12/weights/best.pt\")\n",
    "model = YOLO(\"runs/detect/combined/weights/best.pt\")\n",
    "\n",
    "# cap = cv2.VideoCapture(\"test_video/fish.mp4\")\n",
    "# cap = cv2.VideoCapture(\"./datasets/videos/train/7398_F2.mp4\")\n",
    "cap = cv2.VideoCapture(\"./datasets/videos/test/7117_Caranx_sexfasciatus_juvenile.mp4\")\n",
    "assert cap.isOpened(), \"Error reading video file\"\n",
    "\n",
    "w, h, fps = (int(cap.get(x)) for x in (cv2.CAP_PROP_FRAME_WIDTH, cv2.CAP_PROP_FRAME_HEIGHT, cv2.CAP_PROP_FPS))\n",
    "\n",
    "# Define region points\n",
    "region_points = [(0, 0), (w, 0), (w, h), (0, h)]\n",
    "\n",
    "# Video writer\n",
    "video_writer = cv2.VideoWriter(\"output_video/fish_output.mp4\", cv2.VideoWriter_fourcc(*\"mp4v\"), fps, (w, h))\n",
    "\n",
    "# Init Object Counter\n",
    "counter = solutions.ObjectCounter(\n",
    "    view_img=True,\n",
    "    reg_pts=region_points,\n",
    "    names=model.names,\n",
    "    draw_tracks=True,\n",
    "    line_thickness=1,\n",
    ")\n",
    "\n",
    "while cap.isOpened():\n",
    "    success, im0 = cap.read()\n",
    "    if not success:\n",
    "        print(\"Video frame is empty or video processing has been successfully completed.\")\n",
    "        break\n",
    "    tracks = model.track(im0, persist=True, show=False)\n",
    "\n",
    "    # print(counter.class_wise_count)\n",
    "    im0 = counter.start_counting(im0, tracks)\n",
    "    video_writer.write(im0)\n",
    "    time.sleep(SLEEP * 3)\n",
    "\n",
    "# print(\"Total fish count:\", len(counter.track_history.keys()))\n",
    "\n",
    "\n",
    "cap.release()\n",
    "video_writer.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9b0cc508-bb85-4933-a55e-4e8d917ebb48",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "511324a2-e219-4ffa-9741-d3257056a968",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-image in ./venv/lib/python3.11/site-packages (0.24.0)\n",
      "Requirement already satisfied: numpy>=1.23 in ./venv/lib/python3.11/site-packages (from scikit-image) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.9 in ./venv/lib/python3.11/site-packages (from scikit-image) (1.14.1)\n",
      "Requirement already satisfied: networkx>=2.8 in ./venv/lib/python3.11/site-packages (from scikit-image) (3.3)\n",
      "Requirement already satisfied: pillow>=9.1 in ./venv/lib/python3.11/site-packages (from scikit-image) (10.4.0)\n",
      "Requirement already satisfied: imageio>=2.33 in ./venv/lib/python3.11/site-packages (from scikit-image) (2.35.1)\n",
      "Requirement already satisfied: tifffile>=2022.8.12 in ./venv/lib/python3.11/site-packages (from scikit-image) (2024.9.20)\n",
      "Requirement already satisfied: packaging>=21 in ./venv/lib/python3.11/site-packages (from scikit-image) (24.1)\n",
      "Requirement already satisfied: lazy-loader>=0.4 in ./venv/lib/python3.11/site-packages (from scikit-image) (0.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "210d0807-c6da-428e-ab2d-8ca2d226c75d",
   "metadata": {},
   "source": [
    "## From images to video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "96583377-f2c3-4aae-9b85-a8a1a73ab742",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['7117', 'Caranx', 'sexfasciatus', 'juvenile', 'f000004', 'jpg.rf.df30d192d5422d3224e10afe0f077c15.jpg']\n",
      "7117_Caranx_sexfasciatus_juvenile f000004jpg.rf.df30d192d5422d3224e10afe0f077c15.jpg\n",
      "./datasets/videos/test/7117_Caranx_sexfasciatus_juvenile.mp4\n",
      "Starting a new video for 7117_Caranx_sexfasciatus_juvenile\n",
      "['7117', 'Caranx', 'sexfasciatus', 'juvenile', 'f000097', 'jpg.rf.f917fa957dcdbfcd4c0483265a2b21e0.jpg']\n",
      "7117_Caranx_sexfasciatus_juvenile f000097jpg.rf.f917fa957dcdbfcd4c0483265a2b21e0.jpg\n",
      "./datasets/videos/test/7117_Caranx_sexfasciatus_juvenile.mp4\n",
      "['7117', 'Caranx', 'sexfasciatus', 'juvenile', 'f000099', 'jpg.rf.b714fa15a57102ec0b2e0344754d8bcd.jpg']\n",
      "7117_Caranx_sexfasciatus_juvenile f000099jpg.rf.b714fa15a57102ec0b2e0344754d8bcd.jpg\n",
      "./datasets/videos/test/7117_Caranx_sexfasciatus_juvenile.mp4\n",
      "['7117', 'Caranx', 'sexfasciatus', 'juvenile', 'f000122', 'jpg.rf.0af1925a49b5750555e1ec4ef1ddb81b.jpg']\n",
      "7117_Caranx_sexfasciatus_juvenile f000122jpg.rf.0af1925a49b5750555e1ec4ef1ddb81b.jpg\n",
      "./datasets/videos/test/7117_Caranx_sexfasciatus_juvenile.mp4\n",
      "['7117', 'Caranx', 'sexfasciatus', 'juvenile', 'f000123', 'jpg.rf.e81561f0078317d0a1a04f90a70aec63.jpg']\n",
      "7117_Caranx_sexfasciatus_juvenile f000123jpg.rf.e81561f0078317d0a1a04f90a70aec63.jpg\n",
      "./datasets/videos/test/7117_Caranx_sexfasciatus_juvenile.mp4\n",
      "['7117', 'Caranx', 'sexfasciatus', 'juvenile', 'f000135', 'jpg.rf.61eca6876c0d4707e1ebc20d3df9edbf.jpg']\n",
      "7117_Caranx_sexfasciatus_juvenile f000135jpg.rf.61eca6876c0d4707e1ebc20d3df9edbf.jpg\n",
      "./datasets/videos/test/7117_Caranx_sexfasciatus_juvenile.mp4\n",
      "['7117', 'Caranx', 'sexfasciatus', 'juvenile', 'f000136', 'jpg.rf.6e2ad724bb7935f0f6ea35d269221555.jpg']\n",
      "7117_Caranx_sexfasciatus_juvenile f000136jpg.rf.6e2ad724bb7935f0f6ea35d269221555.jpg\n",
      "./datasets/videos/test/7117_Caranx_sexfasciatus_juvenile.mp4\n",
      "['7117', 'Caranx', 'sexfasciatus', 'juvenile', 'f000148', 'jpg.rf.2234167ec2ed898b3805e586cc48a0df.jpg']\n",
      "7117_Caranx_sexfasciatus_juvenile f000148jpg.rf.2234167ec2ed898b3805e586cc48a0df.jpg\n",
      "./datasets/videos/test/7117_Caranx_sexfasciatus_juvenile.mp4\n",
      "['7117', 'Caranx', 'sexfasciatus', 'juvenile', 'f000203', 'jpg.rf.f024b3dfe4e4134db3063275006a9fac.jpg']\n",
      "7117_Caranx_sexfasciatus_juvenile f000203jpg.rf.f024b3dfe4e4134db3063275006a9fac.jpg\n",
      "./datasets/videos/test/7117_Caranx_sexfasciatus_juvenile.mp4\n",
      "['7117', 'Caranx', 'sexfasciatus', 'juvenile', 'f000218', 'jpg.rf.0edaaf362e5a4d42a77fd04d72c7773d.jpg']\n",
      "7117_Caranx_sexfasciatus_juvenile f000218jpg.rf.0edaaf362e5a4d42a77fd04d72c7773d.jpg\n",
      "./datasets/videos/test/7117_Caranx_sexfasciatus_juvenile.mp4\n",
      "['7117', 'Caranx', 'sexfasciatus', 'juvenile', 'f000233', 'jpg.rf.afb0d2c8b72bbf065d5bf9cde2fac3a8.jpg']\n",
      "7117_Caranx_sexfasciatus_juvenile f000233jpg.rf.afb0d2c8b72bbf065d5bf9cde2fac3a8.jpg\n",
      "./datasets/videos/test/7117_Caranx_sexfasciatus_juvenile.mp4\n",
      "['7117', 'Caranx', 'sexfasciatus', 'juvenile', 'f000264', 'jpg.rf.b1cf307d800194e4efaecb110da54a1d.jpg']\n",
      "7117_Caranx_sexfasciatus_juvenile f000264jpg.rf.b1cf307d800194e4efaecb110da54a1d.jpg\n",
      "./datasets/videos/test/7117_Caranx_sexfasciatus_juvenile.mp4\n",
      "['7117', 'Caranx', 'sexfasciatus', 'juvenile', 'f000271', 'jpg.rf.455cf4479789283c988de66399bfd1a2.jpg']\n",
      "7117_Caranx_sexfasciatus_juvenile f000271jpg.rf.455cf4479789283c988de66399bfd1a2.jpg\n",
      "./datasets/videos/test/7117_Caranx_sexfasciatus_juvenile.mp4\n",
      "['7117', 'Caranx', 'sexfasciatus', 'juvenile', 'f000356', 'jpg.rf.8af3bb3a6f2c6db8a49760e47b711ed8.jpg']\n",
      "7117_Caranx_sexfasciatus_juvenile f000356jpg.rf.8af3bb3a6f2c6db8a49760e47b711ed8.jpg\n",
      "./datasets/videos/test/7117_Caranx_sexfasciatus_juvenile.mp4\n",
      "['7117', 'Caranx', 'sexfasciatus', 'juvenile', 'f000360', 'jpg.rf.1004b2c30275542b24f2a07e6752a268.jpg']\n",
      "7117_Caranx_sexfasciatus_juvenile f000360jpg.rf.1004b2c30275542b24f2a07e6752a268.jpg\n",
      "./datasets/videos/test/7117_Caranx_sexfasciatus_juvenile.mp4\n",
      "['7117', 'Caranx', 'sexfasciatus', 'juvenile', 'f000361', 'jpg.rf.a22091eefeb5f53a02377ba17bf22c0b.jpg']\n",
      "7117_Caranx_sexfasciatus_juvenile f000361jpg.rf.a22091eefeb5f53a02377ba17bf22c0b.jpg\n",
      "./datasets/videos/test/7117_Caranx_sexfasciatus_juvenile.mp4\n",
      "['7117', 'Caranx', 'sexfasciatus', 'juvenile', 'f000985', 'jpg.rf.5b249f3b4a193fbc5002fd20bf0e5413.jpg']\n",
      "7117_Caranx_sexfasciatus_juvenile f000985jpg.rf.5b249f3b4a193fbc5002fd20bf0e5413.jpg\n",
      "./datasets/videos/test/7117_Caranx_sexfasciatus_juvenile.mp4\n",
      "['7117', 'Caranx', 'sexfasciatus', 'juvenile', 'f000993', 'jpg.rf.5211660a59d12ec0fddac90bd7ebe873.jpg']\n",
      "7117_Caranx_sexfasciatus_juvenile f000993jpg.rf.5211660a59d12ec0fddac90bd7ebe873.jpg\n",
      "./datasets/videos/test/7117_Caranx_sexfasciatus_juvenile.mp4\n",
      "['7117', 'Caranx', 'sexfasciatus', 'juvenile', 'f001009', 'jpg.rf.430d5d3cb3136492b82b967644ad6843.jpg']\n",
      "7117_Caranx_sexfasciatus_juvenile f001009jpg.rf.430d5d3cb3136492b82b967644ad6843.jpg\n",
      "./datasets/videos/test/7117_Caranx_sexfasciatus_juvenile.mp4\n",
      "['7117', 'Caranx', 'sexfasciatus', 'juvenile', 'f001011', 'jpg.rf.aa6c2f945556ad437fb8ce1155c64cb0.jpg']\n",
      "7117_Caranx_sexfasciatus_juvenile f001011jpg.rf.aa6c2f945556ad437fb8ce1155c64cb0.jpg\n",
      "./datasets/videos/test/7117_Caranx_sexfasciatus_juvenile.mp4\n",
      "['7117', 'Caranx', 'sexfasciatus', 'juvenile', 'f001070', 'jpg.rf.33d1c25f5340058beda95b38028f821e.jpg']\n",
      "7117_Caranx_sexfasciatus_juvenile f001070jpg.rf.33d1c25f5340058beda95b38028f821e.jpg\n",
      "./datasets/videos/test/7117_Caranx_sexfasciatus_juvenile.mp4\n",
      "['7117', 'Caranx', 'sexfasciatus', 'juvenile', 'f001071', 'jpg.rf.45d0a28359632678e7a698c56a0ca836.jpg']\n",
      "7117_Caranx_sexfasciatus_juvenile f001071jpg.rf.45d0a28359632678e7a698c56a0ca836.jpg\n",
      "./datasets/videos/test/7117_Caranx_sexfasciatus_juvenile.mp4\n",
      "['7117', 'Caranx', 'sexfasciatus', 'juvenile', 'f001091', 'jpg.rf.9d9ccebc335473888f615f0bbedd5ad9.jpg']\n",
      "7117_Caranx_sexfasciatus_juvenile f001091jpg.rf.9d9ccebc335473888f615f0bbedd5ad9.jpg\n",
      "./datasets/videos/test/7117_Caranx_sexfasciatus_juvenile.mp4\n",
      "['7117', 'Caranx', 'sexfasciatus', 'juvenile', 'f001182', 'jpg.rf.751b5f36d1ff98d921205888bd234923.jpg']\n",
      "7117_Caranx_sexfasciatus_juvenile f001182jpg.rf.751b5f36d1ff98d921205888bd234923.jpg\n",
      "./datasets/videos/test/7117_Caranx_sexfasciatus_juvenile.mp4\n",
      "['7117', 'Caranx', 'sexfasciatus', 'juvenile', 'f001191', 'jpg.rf.2c72a0b90c2c57b241ef7861207bf05a.jpg']\n",
      "7117_Caranx_sexfasciatus_juvenile f001191jpg.rf.2c72a0b90c2c57b241ef7861207bf05a.jpg\n",
      "./datasets/videos/test/7117_Caranx_sexfasciatus_juvenile.mp4\n",
      "['7117', 'Caranx', 'sexfasciatus', 'juvenile', 'f001197', 'jpg.rf.3f0125ca52fdd6fda1887329c6cf8d12.jpg']\n",
      "7117_Caranx_sexfasciatus_juvenile f001197jpg.rf.3f0125ca52fdd6fda1887329c6cf8d12.jpg\n",
      "./datasets/videos/test/7117_Caranx_sexfasciatus_juvenile.mp4\n",
      "['7117', 'Caranx', 'sexfasciatus', 'juvenile', 'f001207', 'jpg.rf.919c02e526bfe0f74aa9db1f6cb79a28.jpg']\n",
      "7117_Caranx_sexfasciatus_juvenile f001207jpg.rf.919c02e526bfe0f74aa9db1f6cb79a28.jpg\n",
      "./datasets/videos/test/7117_Caranx_sexfasciatus_juvenile.mp4\n",
      "['7117', 'Caranx', 'sexfasciatus', 'juvenile', 'f001316', 'jpg.rf.0a1b47ca92a925885fbf6f93ea6428ca.jpg']\n",
      "7117_Caranx_sexfasciatus_juvenile f001316jpg.rf.0a1b47ca92a925885fbf6f93ea6428ca.jpg\n",
      "./datasets/videos/test/7117_Caranx_sexfasciatus_juvenile.mp4\n",
      "['7117', 'Caranx', 'sexfasciatus', 'juvenile', 'f001398', 'jpg.rf.186211da2fffe9d33fe8c51241b793e1.jpg']\n",
      "7117_Caranx_sexfasciatus_juvenile f001398jpg.rf.186211da2fffe9d33fe8c51241b793e1.jpg\n",
      "./datasets/videos/test/7117_Caranx_sexfasciatus_juvenile.mp4\n",
      "['7117', 'Caranx', 'sexfasciatus', 'juvenile', 'f001410', 'jpg.rf.2f7f30b91471cf33eceabed996e36cc6.jpg']\n",
      "7117_Caranx_sexfasciatus_juvenile f001410jpg.rf.2f7f30b91471cf33eceabed996e36cc6.jpg\n",
      "./datasets/videos/test/7117_Caranx_sexfasciatus_juvenile.mp4\n",
      "['7117', 'Caranx', 'sexfasciatus', 'juvenile', 'f001460', 'jpg.rf.89ad260bd7a4654a00731e127b1ca022.jpg']\n",
      "7117_Caranx_sexfasciatus_juvenile f001460jpg.rf.89ad260bd7a4654a00731e127b1ca022.jpg\n",
      "./datasets/videos/test/7117_Caranx_sexfasciatus_juvenile.mp4\n",
      "['7117', 'no', 'fish', '2', 'f000006', 'jpg.rf.c7238a88cb0dfc6695a38563758468de.jpg']\n",
      "7117_no_fish_2 f000006jpg.rf.c7238a88cb0dfc6695a38563758468de.jpg\n",
      "./datasets/videos/test/7117_no_fish_2.mp4\n",
      "Starting a new video for 7117_no_fish_2\n",
      "['7117', 'no', 'fish', '2', 'f000016', 'jpg.rf.22bea30b5766e061007b4b5fa10689c7.jpg']\n",
      "7117_no_fish_2 f000016jpg.rf.22bea30b5766e061007b4b5fa10689c7.jpg\n",
      "./datasets/videos/test/7117_no_fish_2.mp4\n",
      "['7117', 'no', 'fish', '2', 'f000040', 'jpg.rf.f87c8a6acfcf4d1951170faa879a682b.jpg']\n",
      "7117_no_fish_2 f000040jpg.rf.f87c8a6acfcf4d1951170faa879a682b.jpg\n",
      "./datasets/videos/test/7117_no_fish_2.mp4\n",
      "['7117', 'no', 'fish', '2', 'f000041', 'jpg.rf.889277bb1023d0dd2d184381ad250d9f.jpg']\n",
      "7117_no_fish_2 f000041jpg.rf.889277bb1023d0dd2d184381ad250d9f.jpg\n",
      "./datasets/videos/test/7117_no_fish_2.mp4\n",
      "['7117', 'no', 'fish', '2', 'f000043', 'jpg.rf.57ce0e8f4e6f9ef3e7cb080ccfa9118f.jpg']\n",
      "7117_no_fish_2 f000043jpg.rf.57ce0e8f4e6f9ef3e7cb080ccfa9118f.jpg\n",
      "./datasets/videos/test/7117_no_fish_2.mp4\n",
      "['7117', 'no', 'fish', '2', 'f000053', 'jpg.rf.d922bf71924f85e70e09ed8503575b91.jpg']\n",
      "7117_no_fish_2 f000053jpg.rf.d922bf71924f85e70e09ed8503575b91.jpg\n",
      "./datasets/videos/test/7117_no_fish_2.mp4\n",
      "['7117', 'no', 'fish', '2', 'f000060', 'jpg.rf.ec801d385ddf0848350b56c0ed35029c.jpg']\n",
      "7117_no_fish_2 f000060jpg.rf.ec801d385ddf0848350b56c0ed35029c.jpg\n",
      "./datasets/videos/test/7117_no_fish_2.mp4\n",
      "['7117', 'no', 'fish', '2', 'f000079', 'jpg.rf.473ead07b001736ebba03b73bc0a0f21.jpg']\n",
      "7117_no_fish_2 f000079jpg.rf.473ead07b001736ebba03b73bc0a0f21.jpg\n",
      "./datasets/videos/test/7117_no_fish_2.mp4\n",
      "['7117', 'no', 'fish', '2', 'f000084', 'jpg.rf.2f4b1e27e15be68ff5c407304425ccf8.jpg']\n",
      "7117_no_fish_2 f000084jpg.rf.2f4b1e27e15be68ff5c407304425ccf8.jpg\n",
      "./datasets/videos/test/7117_no_fish_2.mp4\n",
      "['7268', 'F1', 'f000246', 'jpg.rf.d5ed0476c5d4f94e5625fce7d909236d.jpg']\n",
      "7268_F1 f000246jpg.rf.d5ed0476c5d4f94e5625fce7d909236d.jpg\n",
      "./datasets/videos/test/7268_F1.mp4\n",
      "Starting a new video for 7268_F1\n",
      "['7268', 'F1', 'f000265', 'jpg.rf.2a7f33fa5d24f46a69aa9530dcc7230b.jpg']\n",
      "7268_F1 f000265jpg.rf.2a7f33fa5d24f46a69aa9530dcc7230b.jpg\n",
      "./datasets/videos/test/7268_F1.mp4\n",
      "['7268', 'F1', 'f000266', 'jpg.rf.1062317b0586418309ae8924a66e2924.jpg']\n",
      "7268_F1 f000266jpg.rf.1062317b0586418309ae8924a66e2924.jpg\n",
      "./datasets/videos/test/7268_F1.mp4\n",
      "['7268', 'F1', 'f000280', 'jpg.rf.5e8dbe823ccbd3eb4e3011b7391f5464.jpg']\n",
      "7268_F1 f000280jpg.rf.5e8dbe823ccbd3eb4e3011b7391f5464.jpg\n",
      "./datasets/videos/test/7268_F1.mp4\n",
      "['7268', 'F1', 'f000283', 'jpg.rf.17483c97c921033511d3bef475a6ebb1.jpg']\n",
      "7268_F1 f000283jpg.rf.17483c97c921033511d3bef475a6ebb1.jpg\n",
      "./datasets/videos/test/7268_F1.mp4\n",
      "['7268', 'F1', 'f000290', 'jpg.rf.1dedefcbd825442836f0dee35ed0797d.jpg']\n",
      "7268_F1 f000290jpg.rf.1dedefcbd825442836f0dee35ed0797d.jpg\n",
      "./datasets/videos/test/7268_F1.mp4\n",
      "['7268', 'F1', 'f000292', 'jpg.rf.5b13f46cdb7563ba237a1d006c4d9c69.jpg']\n",
      "7268_F1 f000292jpg.rf.5b13f46cdb7563ba237a1d006c4d9c69.jpg\n",
      "./datasets/videos/test/7268_F1.mp4\n",
      "['7268', 'F1', 'f000294', 'jpg.rf.30d68d61c4d4dfea02b915b31d8382ad.jpg']\n",
      "7268_F1 f000294jpg.rf.30d68d61c4d4dfea02b915b31d8382ad.jpg\n",
      "./datasets/videos/test/7268_F1.mp4\n",
      "['7268', 'F1', 'f000297', 'jpg.rf.7e420f51e4420a21241620964abd48e2.jpg']\n",
      "7268_F1 f000297jpg.rf.7e420f51e4420a21241620964abd48e2.jpg\n",
      "./datasets/videos/test/7268_F1.mp4\n",
      "['7268', 'F1', 'f000301', 'jpg.rf.de9e00afda3d3f8a673439ae8fedde39.jpg']\n",
      "7268_F1 f000301jpg.rf.de9e00afda3d3f8a673439ae8fedde39.jpg\n",
      "./datasets/videos/test/7268_F1.mp4\n",
      "['7268', 'F1', 'f000328', 'jpg.rf.4b618344456e71ca54992e45d938b879.jpg']\n",
      "7268_F1 f000328jpg.rf.4b618344456e71ca54992e45d938b879.jpg\n",
      "./datasets/videos/test/7268_F1.mp4\n",
      "['7268', 'F1', 'f000329', 'jpg.rf.936d6d0390f9ca6e83af64961a7dfd68.jpg']\n",
      "7268_F1 f000329jpg.rf.936d6d0390f9ca6e83af64961a7dfd68.jpg\n",
      "./datasets/videos/test/7268_F1.mp4\n",
      "['7268', 'F1', 'f000336', 'jpg.rf.9a7078a3c7ec71a92cefc9259a08fcbc.jpg']\n",
      "7268_F1 f000336jpg.rf.9a7078a3c7ec71a92cefc9259a08fcbc.jpg\n",
      "./datasets/videos/test/7268_F1.mp4\n",
      "['7268', 'F1', 'f000338', 'jpg.rf.8a2e63d69cd33b4b5d2e852592f2c501.jpg']\n",
      "7268_F1 f000338jpg.rf.8a2e63d69cd33b4b5d2e852592f2c501.jpg\n",
      "./datasets/videos/test/7268_F1.mp4\n",
      "['7268', 'F1', 'f000342', 'jpg.rf.be3e7cb55b4659eb484fa3fd63d8b8f3.jpg']\n",
      "7268_F1 f000342jpg.rf.be3e7cb55b4659eb484fa3fd63d8b8f3.jpg\n",
      "./datasets/videos/test/7268_F1.mp4\n",
      "['7268', 'F1', 'f000354', 'jpg.rf.9ac3d296be08fde7fde2ce98f855b223.jpg']\n",
      "7268_F1 f000354jpg.rf.9ac3d296be08fde7fde2ce98f855b223.jpg\n",
      "./datasets/videos/test/7268_F1.mp4\n",
      "['7268', 'F1', 'f000361', 'jpg.rf.406a72e7975c7acab6df5be1a55ff2ed.jpg']\n",
      "7268_F1 f000361jpg.rf.406a72e7975c7acab6df5be1a55ff2ed.jpg\n",
      "./datasets/videos/test/7268_F1.mp4\n",
      "['7268', 'F1', 'f000392', 'jpg.rf.022d6787180d0716f062836302a1266e.jpg']\n",
      "7268_F1 f000392jpg.rf.022d6787180d0716f062836302a1266e.jpg\n",
      "./datasets/videos/test/7268_F1.mp4\n",
      "['7268', 'F1', 'f000395', 'jpg.rf.646f4422a6f1ad2c2a4d952825dd66e5.jpg']\n",
      "7268_F1 f000395jpg.rf.646f4422a6f1ad2c2a4d952825dd66e5.jpg\n",
      "./datasets/videos/test/7268_F1.mp4\n",
      "['7268', 'F1', 'f000400', 'jpg.rf.436cea7411145c08cd122a5d344d1d0e.jpg']\n",
      "7268_F1 f000400jpg.rf.436cea7411145c08cd122a5d344d1d0e.jpg\n",
      "./datasets/videos/test/7268_F1.mp4\n",
      "['7268', 'F1', 'f000402', 'jpg.rf.38ae916585ba7206976b2cf13ea9b70c.jpg']\n",
      "7268_F1 f000402jpg.rf.38ae916585ba7206976b2cf13ea9b70c.jpg\n",
      "./datasets/videos/test/7268_F1.mp4\n",
      "['7268', 'F1', 'f000406', 'jpg.rf.638f4745c33dc155dc493d1fbce1f5fa.jpg']\n",
      "7268_F1 f000406jpg.rf.638f4745c33dc155dc493d1fbce1f5fa.jpg\n",
      "./datasets/videos/test/7268_F1.mp4\n",
      "['7268', 'F1', 'f000412', 'jpg.rf.32c5b045763a055d883672ecfc01e5b2.jpg']\n",
      "7268_F1 f000412jpg.rf.32c5b045763a055d883672ecfc01e5b2.jpg\n",
      "./datasets/videos/test/7268_F1.mp4\n",
      "['7268', 'F1', 'f000455', 'jpg.rf.508d9fef29ce4c524026e831770331cd.jpg']\n",
      "7268_F1 f000455jpg.rf.508d9fef29ce4c524026e831770331cd.jpg\n",
      "./datasets/videos/test/7268_F1.mp4\n",
      "['7268', 'F1', 'f000468', 'jpg.rf.9b5a47ce916cb7471a5bd88e1ae411fa.jpg']\n",
      "7268_F1 f000468jpg.rf.9b5a47ce916cb7471a5bd88e1ae411fa.jpg\n",
      "./datasets/videos/test/7268_F1.mp4\n",
      "['7268', 'F1', 'f000469', 'jpg.rf.a294f571aa70263dfe21b7c284158a72.jpg']\n",
      "7268_F1 f000469jpg.rf.a294f571aa70263dfe21b7c284158a72.jpg\n",
      "./datasets/videos/test/7268_F1.mp4\n",
      "['7268', 'F1', 'f000486', 'jpg.rf.0cbc5721667cd603f249f6fc2c7f4906.jpg']\n",
      "7268_F1 f000486jpg.rf.0cbc5721667cd603f249f6fc2c7f4906.jpg\n",
      "./datasets/videos/test/7268_F1.mp4\n",
      "['7268', 'F1', 'f000521', 'jpg.rf.13f493c2ce314e876c92fefecb905858.jpg']\n",
      "7268_F1 f000521jpg.rf.13f493c2ce314e876c92fefecb905858.jpg\n",
      "./datasets/videos/test/7268_F1.mp4\n",
      "['7268', 'F1', 'f000522', 'jpg.rf.f089ebeda4a2604200272333f9e399ab.jpg']\n",
      "7268_F1 f000522jpg.rf.f089ebeda4a2604200272333f9e399ab.jpg\n",
      "./datasets/videos/test/7268_F1.mp4\n",
      "['7268', 'F1', 'f000543', 'jpg.rf.bc6368c59c0c9c15f1a35e46eccb2159.jpg']\n",
      "7268_F1 f000543jpg.rf.bc6368c59c0c9c15f1a35e46eccb2159.jpg\n",
      "./datasets/videos/test/7268_F1.mp4\n",
      "['7268', 'F1', 'f000577', 'jpg.rf.19e8cf0f1f405e8a6412e191aa2ac812.jpg']\n",
      "7268_F1 f000577jpg.rf.19e8cf0f1f405e8a6412e191aa2ac812.jpg\n",
      "./datasets/videos/test/7268_F1.mp4\n",
      "['7268', 'F1', 'f000581', 'jpg.rf.b3131b832de53b7016fe7ebbbbe73b78.jpg']\n",
      "7268_F1 f000581jpg.rf.b3131b832de53b7016fe7ebbbbe73b78.jpg\n",
      "./datasets/videos/test/7268_F1.mp4\n",
      "['7268', 'F1', 'f000589', 'jpg.rf.f058a318160cda5d0393ab774f9f71a9.jpg']\n",
      "7268_F1 f000589jpg.rf.f058a318160cda5d0393ab774f9f71a9.jpg\n",
      "./datasets/videos/test/7268_F1.mp4\n",
      "['7268', 'F1', 'f000595', 'jpg.rf.940f76651cec8f3979403136fb7de482.jpg']\n",
      "7268_F1 f000595jpg.rf.940f76651cec8f3979403136fb7de482.jpg\n",
      "./datasets/videos/test/7268_F1.mp4\n",
      "['7268', 'F1', 'f000596', 'jpg.rf.4a9b6606ad987cf20459fc2d5bd3b769.jpg']\n",
      "7268_F1 f000596jpg.rf.4a9b6606ad987cf20459fc2d5bd3b769.jpg\n",
      "./datasets/videos/test/7268_F1.mp4\n",
      "['7268', 'F1', 'f000603', 'jpg.rf.12b7fc330b52ca211122e93d68c659d6.jpg']\n",
      "7268_F1 f000603jpg.rf.12b7fc330b52ca211122e93d68c659d6.jpg\n",
      "./datasets/videos/test/7268_F1.mp4\n",
      "['7268', 'F1', 'f000606', 'jpg.rf.05c4f3261e9b52c5d67f14e5bd444c5e.jpg']\n",
      "7268_F1 f000606jpg.rf.05c4f3261e9b52c5d67f14e5bd444c5e.jpg\n",
      "./datasets/videos/test/7268_F1.mp4\n",
      "['7268', 'F1', 'f000615', 'jpg.rf.c07669c57bd32eb8300740ad80f6ce66.jpg']\n",
      "7268_F1 f000615jpg.rf.c07669c57bd32eb8300740ad80f6ce66.jpg\n",
      "./datasets/videos/test/7268_F1.mp4\n",
      "['7268', 'F1', 'f000642', 'jpg.rf.922c3a1d78807105912f9ac0eb057820.jpg']\n",
      "7268_F1 f000642jpg.rf.922c3a1d78807105912f9ac0eb057820.jpg\n",
      "./datasets/videos/test/7268_F1.mp4\n",
      "['7268', 'F1', 'f000644', 'jpg.rf.e4e4b4c76cfbc9278b26130056880a16.jpg']\n",
      "7268_F1 f000644jpg.rf.e4e4b4c76cfbc9278b26130056880a16.jpg\n",
      "./datasets/videos/test/7268_F1.mp4\n",
      "['7268', 'F1', 'f000646', 'jpg.rf.7e3740b46448475ffe887866eae8b76b.jpg']\n",
      "7268_F1 f000646jpg.rf.7e3740b46448475ffe887866eae8b76b.jpg\n",
      "./datasets/videos/test/7268_F1.mp4\n",
      "['7268', 'F1', 'f000648', 'jpg.rf.3cadef2bd4ebb7c2d2108e8ac2a038d5.jpg']\n",
      "7268_F1 f000648jpg.rf.3cadef2bd4ebb7c2d2108e8ac2a038d5.jpg\n",
      "./datasets/videos/test/7268_F1.mp4\n",
      "['7268', 'F1', 'f000658', 'jpg.rf.7538adbb99560e65bc93173ef8eca2fe.jpg']\n",
      "7268_F1 f000658jpg.rf.7538adbb99560e65bc93173ef8eca2fe.jpg\n",
      "./datasets/videos/test/7268_F1.mp4\n",
      "['7268', 'F1', 'f000664', 'jpg.rf.fbe568714728331e00006da37064ae52.jpg']\n",
      "7268_F1 f000664jpg.rf.fbe568714728331e00006da37064ae52.jpg\n",
      "./datasets/videos/test/7268_F1.mp4\n",
      "['7268', 'F1', 'f000669', 'jpg.rf.fcd9b7fc53ee437e1f3eb17220f2c267.jpg']\n",
      "7268_F1 f000669jpg.rf.fcd9b7fc53ee437e1f3eb17220f2c267.jpg\n",
      "./datasets/videos/test/7268_F1.mp4\n",
      "['7268', 'F1', 'f000673', 'jpg.rf.7155bf010f1b9bf9a9688697b566fe7d.jpg']\n",
      "7268_F1 f000673jpg.rf.7155bf010f1b9bf9a9688697b566fe7d.jpg\n",
      "./datasets/videos/test/7268_F1.mp4\n",
      "['7393', 'F1', 'f000021', 'jpg.rf.af1d3e351c328d0dd370e5acfd0a8990.jpg']\n",
      "7393_F1 f000021jpg.rf.af1d3e351c328d0dd370e5acfd0a8990.jpg\n",
      "./datasets/videos/test/7393_F1.mp4\n",
      "Starting a new video for 7393_F1\n",
      "['7393', 'F1', 'f000022', 'jpg.rf.8d79483d87a4fc04495083ede1922a44.jpg']\n",
      "7393_F1 f000022jpg.rf.8d79483d87a4fc04495083ede1922a44.jpg\n",
      "./datasets/videos/test/7393_F1.mp4\n",
      "['7393', 'F1', 'f000024', 'jpg.rf.4982a36afe28e0df2cc6262bf86e655d.jpg']\n",
      "7393_F1 f000024jpg.rf.4982a36afe28e0df2cc6262bf86e655d.jpg\n",
      "./datasets/videos/test/7393_F1.mp4\n",
      "['7393', 'F1', 'f000037', 'jpg.rf.35b7577b38b13a79ab8fdb6ed841d120.jpg']\n",
      "7393_F1 f000037jpg.rf.35b7577b38b13a79ab8fdb6ed841d120.jpg\n",
      "./datasets/videos/test/7393_F1.mp4\n",
      "['7393', 'F1', 'f000049', 'jpg.rf.6eb8d3349d21ef9857b03f5b56872aeb.jpg']\n",
      "7393_F1 f000049jpg.rf.6eb8d3349d21ef9857b03f5b56872aeb.jpg\n",
      "./datasets/videos/test/7393_F1.mp4\n",
      "['7393', 'F1', 'f000125', 'jpg.rf.a9caa6572162c9634f33d5f270fdd486.jpg']\n",
      "7393_F1 f000125jpg.rf.a9caa6572162c9634f33d5f270fdd486.jpg\n",
      "./datasets/videos/test/7393_F1.mp4\n",
      "['7393', 'F1', 'f000135', 'jpg.rf.134c0efaa3f0a5a6e8690930f0dd4e90.jpg']\n",
      "7393_F1 f000135jpg.rf.134c0efaa3f0a5a6e8690930f0dd4e90.jpg\n",
      "./datasets/videos/test/7393_F1.mp4\n",
      "['7393', 'F1', 'f000182', 'jpg.rf.f3b55e75c76b8bca63447d7b49e0242c.jpg']\n",
      "7393_F1 f000182jpg.rf.f3b55e75c76b8bca63447d7b49e0242c.jpg\n",
      "./datasets/videos/test/7393_F1.mp4\n",
      "['7393', 'F1', 'f000185', 'jpg.rf.f77c15895adce3d948d971683ad33ad8.jpg']\n",
      "7393_F1 f000185jpg.rf.f77c15895adce3d948d971683ad33ad8.jpg\n",
      "./datasets/videos/test/7393_F1.mp4\n",
      "['7393', 'F1', 'f000237', 'jpg.rf.cc69b68ad409cfdc6d5c9ff52857138d.jpg']\n",
      "7393_F1 f000237jpg.rf.cc69b68ad409cfdc6d5c9ff52857138d.jpg\n",
      "./datasets/videos/test/7393_F1.mp4\n",
      "['7393', 'F1', 'f000240', 'jpg.rf.da6719b2301193d6299669b92a6a68a9.jpg']\n",
      "7393_F1 f000240jpg.rf.da6719b2301193d6299669b92a6a68a9.jpg\n",
      "./datasets/videos/test/7393_F1.mp4\n",
      "['7393', 'F1', 'f000359', 'jpg.rf.a74f56753cec183b4b8f6eb62d926037.jpg']\n",
      "7393_F1 f000359jpg.rf.a74f56753cec183b4b8f6eb62d926037.jpg\n",
      "./datasets/videos/test/7393_F1.mp4\n",
      "['7393', 'F1', 'f000361', 'jpg.rf.ccfe7b630a85b18efef2dbba5e2630b8.jpg']\n",
      "7393_F1 f000361jpg.rf.ccfe7b630a85b18efef2dbba5e2630b8.jpg\n",
      "./datasets/videos/test/7393_F1.mp4\n",
      "['7393', 'F1', 'f000362', 'jpg.rf.ba84645bc8e764be61e3cbf432ede92d.jpg']\n",
      "7393_F1 f000362jpg.rf.ba84645bc8e764be61e3cbf432ede92d.jpg\n",
      "./datasets/videos/test/7393_F1.mp4\n",
      "['7393', 'NF2', 'f000008', 'jpg.rf.8d5466886d3a35c6136404d94bc7ff8a.jpg']\n",
      "7393_NF2 f000008jpg.rf.8d5466886d3a35c6136404d94bc7ff8a.jpg\n",
      "./datasets/videos/test/7393_NF2.mp4\n",
      "Starting a new video for 7393_NF2\n",
      "['7393', 'NF2', 'f000010', 'jpg.rf.317afa574cff9f9345410cd5c6706c73.jpg']\n",
      "7393_NF2 f000010jpg.rf.317afa574cff9f9345410cd5c6706c73.jpg\n",
      "./datasets/videos/test/7393_NF2.mp4\n",
      "['7393', 'NF2', 'f000019', 'jpg.rf.93771922d116365ae033b4ac65e72bb9.jpg']\n",
      "7393_NF2 f000019jpg.rf.93771922d116365ae033b4ac65e72bb9.jpg\n",
      "./datasets/videos/test/7393_NF2.mp4\n",
      "['7393', 'NF2', 'f000023', 'jpg.rf.ec4743dab4c4eaa92066ee4641a02360.jpg']\n",
      "7393_NF2 f000023jpg.rf.ec4743dab4c4eaa92066ee4641a02360.jpg\n",
      "./datasets/videos/test/7393_NF2.mp4\n",
      "['7393', 'NF2', 'f001509', 'jpg.rf.000abdbd4350152dd4b410f365118edd.jpg']\n",
      "7393_NF2 f001509jpg.rf.000abdbd4350152dd4b410f365118edd.jpg\n",
      "./datasets/videos/test/7393_NF2.mp4\n",
      "['7393', 'NF2', 'f001511', 'jpg.rf.453bb272b6ee793d4e08c6003ae2ab32.jpg']\n",
      "7393_NF2 f001511jpg.rf.453bb272b6ee793d4e08c6003ae2ab32.jpg\n",
      "./datasets/videos/test/7393_NF2.mp4\n",
      "['7393', 'NF2', 'f001519', 'jpg.rf.71f643b6058791327ee520304fad5ec7.jpg']\n",
      "7393_NF2 f001519jpg.rf.71f643b6058791327ee520304fad5ec7.jpg\n",
      "./datasets/videos/test/7393_NF2.mp4\n",
      "['7393', 'NF2', 'f001528', 'jpg.rf.cbe34f481ba2a809e8613093bd995449.jpg']\n",
      "7393_NF2 f001528jpg.rf.cbe34f481ba2a809e8613093bd995449.jpg\n",
      "./datasets/videos/test/7393_NF2.mp4\n",
      "['7393', 'NF2', 'f001533', 'jpg.rf.c14d5596e4ce97eca171b07a51a497ff.jpg']\n",
      "7393_NF2 f001533jpg.rf.c14d5596e4ce97eca171b07a51a497ff.jpg\n",
      "./datasets/videos/test/7393_NF2.mp4\n",
      "['7393', 'NF2', 'f001544', 'jpg.rf.307c0a7728bd9b612b194a5f900c48ee.jpg']\n",
      "7393_NF2 f001544jpg.rf.307c0a7728bd9b612b194a5f900c48ee.jpg\n",
      "./datasets/videos/test/7393_NF2.mp4\n",
      "['7398', 'F1', 'f000029', 'jpg.rf.29fa602c7fdb28aea3895d456606fcf0.jpg']\n",
      "7398_F1 f000029jpg.rf.29fa602c7fdb28aea3895d456606fcf0.jpg\n",
      "./datasets/videos/test/7398_F1.mp4\n",
      "Starting a new video for 7398_F1\n",
      "['7398', 'F1', 'f000033', 'jpg.rf.fc7963e46abcf79091aab72c07f0b09c.jpg']\n",
      "7398_F1 f000033jpg.rf.fc7963e46abcf79091aab72c07f0b09c.jpg\n",
      "./datasets/videos/test/7398_F1.mp4\n",
      "['7398', 'F1', 'f000056', 'jpg.rf.39f9fca3fb5ea263bb5e37f4f1b5813a.jpg']\n",
      "7398_F1 f000056jpg.rf.39f9fca3fb5ea263bb5e37f4f1b5813a.jpg\n",
      "./datasets/videos/test/7398_F1.mp4\n",
      "['7398', 'F1', 'f000062', 'jpg.rf.f0860cf4c96a917262daa7f5c01b8d4d.jpg']\n",
      "7398_F1 f000062jpg.rf.f0860cf4c96a917262daa7f5c01b8d4d.jpg\n",
      "./datasets/videos/test/7398_F1.mp4\n",
      "['7398', 'F1', 'f000079', 'jpg.rf.adf24fcfb076a476191bbc1e70ecbac3.jpg']\n",
      "7398_F1 f000079jpg.rf.adf24fcfb076a476191bbc1e70ecbac3.jpg\n",
      "./datasets/videos/test/7398_F1.mp4\n",
      "['7398', 'F1', 'f000080', 'jpg.rf.9defb827d50f917beabacdbac98b16be.jpg']\n",
      "7398_F1 f000080jpg.rf.9defb827d50f917beabacdbac98b16be.jpg\n",
      "./datasets/videos/test/7398_F1.mp4\n",
      "['7398', 'F1', 'f000094', 'jpg.rf.503f040684b418ab86a96297a0fc6cb6.jpg']\n",
      "7398_F1 f000094jpg.rf.503f040684b418ab86a96297a0fc6cb6.jpg\n",
      "./datasets/videos/test/7398_F1.mp4\n",
      "['7398', 'F1', 'f000106', 'jpg.rf.b75f52c7ca9f105d3cdc574ad198f63a.jpg']\n",
      "7398_F1 f000106jpg.rf.b75f52c7ca9f105d3cdc574ad198f63a.jpg\n",
      "./datasets/videos/test/7398_F1.mp4\n",
      "['7398', 'F1', 'f000151', 'jpg.rf.5aeca9f508adb3932e9b7d638ea0bec2.jpg']\n",
      "7398_F1 f000151jpg.rf.5aeca9f508adb3932e9b7d638ea0bec2.jpg\n",
      "./datasets/videos/test/7398_F1.mp4\n",
      "['7398', 'F1', 'f000156', 'jpg.rf.13e518721219d3f3099fce777222fa76.jpg']\n",
      "7398_F1 f000156jpg.rf.13e518721219d3f3099fce777222fa76.jpg\n",
      "./datasets/videos/test/7398_F1.mp4\n",
      "['7398', 'F1', 'f000161', 'jpg.rf.095cc6b73faa4a04a056ef5e0256c308.jpg']\n",
      "7398_F1 f000161jpg.rf.095cc6b73faa4a04a056ef5e0256c308.jpg\n",
      "./datasets/videos/test/7398_F1.mp4\n",
      "['7398', 'F2', 'f000004', 'jpg.rf.bbfba631af0799ed9c01f2ca108ddedf.jpg']\n",
      "7398_F2 f000004jpg.rf.bbfba631af0799ed9c01f2ca108ddedf.jpg\n",
      "./datasets/videos/test/7398_F2.mp4\n",
      "Starting a new video for 7398_F2\n",
      "['7398', 'F2', 'f000027', 'jpg.rf.e68ec1de17c724cacf1d898ca077344c.jpg']\n",
      "7398_F2 f000027jpg.rf.e68ec1de17c724cacf1d898ca077344c.jpg\n",
      "./datasets/videos/test/7398_F2.mp4\n",
      "['7398', 'F2', 'f000033', 'jpg.rf.5882aa8c2bbc27ebf26d905bedc712d4.jpg']\n",
      "7398_F2 f000033jpg.rf.5882aa8c2bbc27ebf26d905bedc712d4.jpg\n",
      "./datasets/videos/test/7398_F2.mp4\n",
      "['7398', 'F3', 'f000012', 'jpg.rf.74998761ac6a5c7a654aee8514458ba2.jpg']\n",
      "7398_F3 f000012jpg.rf.74998761ac6a5c7a654aee8514458ba2.jpg\n",
      "./datasets/videos/test/7398_F3.mp4\n",
      "Starting a new video for 7398_F3\n",
      "['7398', 'F3', 'f000027', 'jpg.rf.f3f15e049d61d2e32cefeef384e89e33.jpg']\n",
      "7398_F3 f000027jpg.rf.f3f15e049d61d2e32cefeef384e89e33.jpg\n",
      "./datasets/videos/test/7398_F3.mp4\n",
      "['7398', 'F4', 'f000250', 'jpg.rf.d12f273608cd4cb85526eed3c3121cdc.jpg']\n",
      "7398_F4 f000250jpg.rf.d12f273608cd4cb85526eed3c3121cdc.jpg\n",
      "./datasets/videos/test/7398_F4.mp4\n",
      "Starting a new video for 7398_F4\n",
      "['7398', 'F4', 'f000694', 'jpg.rf.8a31541621cdd299e6dea51ed27ca8db.jpg']\n",
      "7398_F4 f000694jpg.rf.8a31541621cdd299e6dea51ed27ca8db.jpg\n",
      "./datasets/videos/test/7398_F4.mp4\n",
      "['7398', 'F5', 'f000252', 'jpg.rf.90c72c8b34593aa8f5104a0a4bfa5b12.jpg']\n",
      "7398_F5 f000252jpg.rf.90c72c8b34593aa8f5104a0a4bfa5b12.jpg\n",
      "./datasets/videos/test/7398_F5.mp4\n",
      "Starting a new video for 7398_F5\n",
      "['7398', 'F6', 'f000195', 'jpg.rf.f19fb1d9b1bc75539c0d030ed3d83f68.jpg']\n",
      "7398_F6 f000195jpg.rf.f19fb1d9b1bc75539c0d030ed3d83f68.jpg\n",
      "./datasets/videos/test/7398_F6.mp4\n",
      "Starting a new video for 7398_F6\n",
      "['7398', 'NF2', 'f000096', 'jpg.rf.26451092f6e7c2bf78bb63b84c091460.jpg']\n",
      "7398_NF2 f000096jpg.rf.26451092f6e7c2bf78bb63b84c091460.jpg\n",
      "./datasets/videos/test/7398_NF2.mp4\n",
      "Starting a new video for 7398_NF2\n",
      "['7398', 'NF2', 'f000097', 'jpg.rf.a34ec42dca05149c368b6a81fdb10940.jpg']\n",
      "7398_NF2 f000097jpg.rf.a34ec42dca05149c368b6a81fdb10940.jpg\n",
      "./datasets/videos/test/7398_NF2.mp4\n",
      "['7398', 'NF2', 'f000101', 'jpg.rf.f30cb5339fcf3717c23db3e75726ac31.jpg']\n",
      "7398_NF2 f000101jpg.rf.f30cb5339fcf3717c23db3e75726ac31.jpg\n",
      "./datasets/videos/test/7398_NF2.mp4\n",
      "['7398', 'NF2', 'f000107', 'jpg.rf.4375203e1eba1ea634f9245519b73b38.jpg']\n",
      "7398_NF2 f000107jpg.rf.4375203e1eba1ea634f9245519b73b38.jpg\n",
      "./datasets/videos/test/7398_NF2.mp4\n",
      "['7398', 'NF2', 'f000123', 'jpg.rf.e7aaf9126e51e88294723b5bda7c0d73.jpg']\n",
      "7398_NF2 f000123jpg.rf.e7aaf9126e51e88294723b5bda7c0d73.jpg\n",
      "./datasets/videos/test/7398_NF2.mp4\n",
      "['7398', 'NF2', 'f000124', 'jpg.rf.9ab384040b159eb74ff4c9b374fa07c8.jpg']\n",
      "7398_NF2 f000124jpg.rf.9ab384040b159eb74ff4c9b374fa07c8.jpg\n",
      "./datasets/videos/test/7398_NF2.mp4\n",
      "['7398', 'NF2', 'f000125', 'jpg.rf.92f53ec73cd717e3b428d51dc71460e4.jpg']\n",
      "7398_NF2 f000125jpg.rf.92f53ec73cd717e3b428d51dc71460e4.jpg\n",
      "./datasets/videos/test/7398_NF2.mp4\n",
      "['7398', 'NF2', 'f000140', 'jpg.rf.6a13ed8f498da9aa4191c0c4eca9dca6.jpg']\n",
      "7398_NF2 f000140jpg.rf.6a13ed8f498da9aa4191c0c4eca9dca6.jpg\n",
      "./datasets/videos/test/7398_NF2.mp4\n",
      "['7398', 'NF2', 'f000144', 'jpg.rf.ebd332d2dc23af0d2513e3a043196083.jpg']\n",
      "7398_NF2 f000144jpg.rf.ebd332d2dc23af0d2513e3a043196083.jpg\n",
      "./datasets/videos/test/7398_NF2.mp4\n",
      "['7398', 'NF2', 'f000154', 'jpg.rf.162fffc0c7feb48511379628228eaf57.jpg']\n",
      "7398_NF2 f000154jpg.rf.162fffc0c7feb48511379628228eaf57.jpg\n",
      "./datasets/videos/test/7398_NF2.mp4\n",
      "['7398', 'NF2', 'f000155', 'jpg.rf.ee4c828d0b64e6dd06e2d59c3d1fb666.jpg']\n",
      "7398_NF2 f000155jpg.rf.ee4c828d0b64e6dd06e2d59c3d1fb666.jpg\n",
      "./datasets/videos/test/7398_NF2.mp4\n",
      "['7398', 'NF2', 'f000157', 'jpg.rf.a21ee92eea3ecb87efb14dd483b6331c.jpg']\n",
      "7398_NF2 f000157jpg.rf.a21ee92eea3ecb87efb14dd483b6331c.jpg\n",
      "./datasets/videos/test/7398_NF2.mp4\n",
      "['7398', 'NF2', 'f000158', 'jpg.rf.676dcd27bf1a829100b77a4609274184.jpg']\n",
      "7398_NF2 f000158jpg.rf.676dcd27bf1a829100b77a4609274184.jpg\n",
      "./datasets/videos/test/7398_NF2.mp4\n",
      "['7398', 'NF2', 'f000162', 'jpg.rf.5f41d20d01abfcd239810c653e5cd713.jpg']\n",
      "7398_NF2 f000162jpg.rf.5f41d20d01abfcd239810c653e5cd713.jpg\n",
      "./datasets/videos/test/7398_NF2.mp4\n",
      "['7398', 'NF2', 'f000169', 'jpg.rf.acd8bcd171d3711a65d46be8427cb685.jpg']\n",
      "7398_NF2 f000169jpg.rf.acd8bcd171d3711a65d46be8427cb685.jpg\n",
      "./datasets/videos/test/7398_NF2.mp4\n",
      "['7398', 'NF2', 'f000173', 'jpg.rf.3d5f7ecce39f300ce014d27c20da7226.jpg']\n",
      "7398_NF2 f000173jpg.rf.3d5f7ecce39f300ce014d27c20da7226.jpg\n",
      "./datasets/videos/test/7398_NF2.mp4\n",
      "['7398', 'NF2', 'f000181', 'jpg.rf.06beabe2773409a1ba4b5305832a3051.jpg']\n",
      "7398_NF2 f000181jpg.rf.06beabe2773409a1ba4b5305832a3051.jpg\n",
      "./datasets/videos/test/7398_NF2.mp4\n",
      "['7398', 'NF2', 'f000202', 'jpg.rf.5a329afd1dc547f0217a3d10e29f7755.jpg']\n",
      "7398_NF2 f000202jpg.rf.5a329afd1dc547f0217a3d10e29f7755.jpg\n",
      "./datasets/videos/test/7398_NF2.mp4\n",
      "['7398', 'NF2', 'f000207', 'jpg.rf.a9ec433a31bbd80e3ade93151a972069.jpg']\n",
      "7398_NF2 f000207jpg.rf.a9ec433a31bbd80e3ade93151a972069.jpg\n",
      "./datasets/videos/test/7398_NF2.mp4\n",
      "['7398', 'NF2', 'f000208', 'jpg.rf.290ecef442f90a18bcd2b5f8f1f6fcbf.jpg']\n",
      "7398_NF2 f000208jpg.rf.290ecef442f90a18bcd2b5f8f1f6fcbf.jpg\n",
      "./datasets/videos/test/7398_NF2.mp4\n",
      "['7398', 'NF2', 'f000216', 'jpg.rf.24c50a5c4e2e4af4969d049e909d5f2e.jpg']\n",
      "7398_NF2 f000216jpg.rf.24c50a5c4e2e4af4969d049e909d5f2e.jpg\n",
      "./datasets/videos/test/7398_NF2.mp4\n",
      "['7398', 'NF2', 'f000217', 'jpg.rf.fffe8426890ab8ea356476e849a7fc54.jpg']\n",
      "7398_NF2 f000217jpg.rf.fffe8426890ab8ea356476e849a7fc54.jpg\n",
      "./datasets/videos/test/7398_NF2.mp4\n",
      "['7426', 'F1', 'f000020', 'jpg.rf.5c3d09515a1aeb5c964635ff2c2545f4.jpg']\n",
      "7426_F1 f000020jpg.rf.5c3d09515a1aeb5c964635ff2c2545f4.jpg\n",
      "./datasets/videos/test/7426_F1.mp4\n",
      "Starting a new video for 7426_F1\n",
      "['7426', 'F1', 'f000024', 'jpg.rf.ddadaa05e1164e10e742ae61d29d3bd4.jpg']\n",
      "7426_F1 f000024jpg.rf.ddadaa05e1164e10e742ae61d29d3bd4.jpg\n",
      "./datasets/videos/test/7426_F1.mp4\n",
      "['7426', 'F1', 'f000036', 'jpg.rf.54c9fe46bb41d9e934e8655268708948.jpg']\n",
      "7426_F1 f000036jpg.rf.54c9fe46bb41d9e934e8655268708948.jpg\n",
      "./datasets/videos/test/7426_F1.mp4\n",
      "['7426', 'F1', 'f000048', 'jpg.rf.fc4003a22676f638c5e6485ad62191d7.jpg']\n",
      "7426_F1 f000048jpg.rf.fc4003a22676f638c5e6485ad62191d7.jpg\n",
      "./datasets/videos/test/7426_F1.mp4\n",
      "['7426', 'F1', 'f000073', 'jpg.rf.f3f10712097ddfe20cbc54f8277787c6.jpg']\n",
      "7426_F1 f000073jpg.rf.f3f10712097ddfe20cbc54f8277787c6.jpg\n",
      "./datasets/videos/test/7426_F1.mp4\n",
      "['7426', 'F1', 'f000076', 'jpg.rf.7ee6f1800b0b73e4c5a7c437559eeb11.jpg']\n",
      "7426_F1 f000076jpg.rf.7ee6f1800b0b73e4c5a7c437559eeb11.jpg\n",
      "./datasets/videos/test/7426_F1.mp4\n",
      "['7426', 'F1', 'f000087', 'jpg.rf.46d6a01fd70a857832c5b66206afcdf7.jpg']\n",
      "7426_F1 f000087jpg.rf.46d6a01fd70a857832c5b66206afcdf7.jpg\n",
      "./datasets/videos/test/7426_F1.mp4\n",
      "['7426', 'F1', 'f000098', 'jpg.rf.7d1a43c49aa70cceab804d1a5fe04d33.jpg']\n",
      "7426_F1 f000098jpg.rf.7d1a43c49aa70cceab804d1a5fe04d33.jpg\n",
      "./datasets/videos/test/7426_F1.mp4\n",
      "['7426', 'F1', 'f000101', 'jpg.rf.1d329039b76701386fa84a89655ba37c.jpg']\n",
      "7426_F1 f000101jpg.rf.1d329039b76701386fa84a89655ba37c.jpg\n",
      "./datasets/videos/test/7426_F1.mp4\n",
      "['7426', 'F2', 'f000044', 'jpg.rf.c83110726f27ab18af39f0b405823714.jpg']\n",
      "7426_F2 f000044jpg.rf.c83110726f27ab18af39f0b405823714.jpg\n",
      "./datasets/videos/test/7426_F2.mp4\n",
      "Starting a new video for 7426_F2\n",
      "['7426', 'F2', 'f000054', 'jpg.rf.29384ae9334cd0e9b1971782afb10a82.jpg']\n",
      "7426_F2 f000054jpg.rf.29384ae9334cd0e9b1971782afb10a82.jpg\n",
      "./datasets/videos/test/7426_F2.mp4\n",
      "['7426', 'F2', 'f000063', 'jpg.rf.c94ab071582c32008be1db10e747ca55.jpg']\n",
      "7426_F2 f000063jpg.rf.c94ab071582c32008be1db10e747ca55.jpg\n",
      "./datasets/videos/test/7426_F2.mp4\n",
      "['7426', 'F2', 'f000074', 'jpg.rf.c8389b081b78ae6878bb8f0432b5c55b.jpg']\n",
      "7426_F2 f000074jpg.rf.c8389b081b78ae6878bb8f0432b5c55b.jpg\n",
      "./datasets/videos/test/7426_F2.mp4\n",
      "['7426', 'F2', 'f000091', 'jpg.rf.322fc9683889ce97bd42286b2753e310.jpg']\n",
      "7426_F2 f000091jpg.rf.322fc9683889ce97bd42286b2753e310.jpg\n",
      "./datasets/videos/test/7426_F2.mp4\n",
      "['7426', 'F2', 'f000104', 'jpg.rf.270486ba16d75fae6e572c490ddbb047.jpg']\n",
      "7426_F2 f000104jpg.rf.270486ba16d75fae6e572c490ddbb047.jpg\n",
      "./datasets/videos/test/7426_F2.mp4\n",
      "['7426', 'F2', 'f000214', 'jpg.rf.f32a109735f4a7f2d15699c9bc63ecdc.jpg']\n",
      "7426_F2 f000214jpg.rf.f32a109735f4a7f2d15699c9bc63ecdc.jpg\n",
      "./datasets/videos/test/7426_F2.mp4\n",
      "['7426', 'F2', 'f000218', 'jpg.rf.1763088329e818440455b93c0cb70cdb.jpg']\n",
      "7426_F2 f000218jpg.rf.1763088329e818440455b93c0cb70cdb.jpg\n",
      "./datasets/videos/test/7426_F2.mp4\n",
      "['7426', 'F2', 'f000219', 'jpg.rf.7777658999adc16925ef1de697cd408e.jpg']\n",
      "7426_F2 f000219jpg.rf.7777658999adc16925ef1de697cd408e.jpg\n",
      "./datasets/videos/test/7426_F2.mp4\n",
      "['7426', 'F2', 'f000220', 'jpg.rf.2f3f3fccbd1dec5b2fbfd7ab052cd8fc.jpg']\n",
      "7426_F2 f000220jpg.rf.2f3f3fccbd1dec5b2fbfd7ab052cd8fc.jpg\n",
      "./datasets/videos/test/7426_F2.mp4\n",
      "['7426', 'F2', 'f000223', 'jpg.rf.8dd63da52ba3f90d6363fee424c82562.jpg']\n",
      "7426_F2 f000223jpg.rf.8dd63da52ba3f90d6363fee424c82562.jpg\n",
      "./datasets/videos/test/7426_F2.mp4\n",
      "['7426', 'F2', 'f000225', 'jpg.rf.f77d431f0c253750dbf320fa15c31b34.jpg']\n",
      "7426_F2 f000225jpg.rf.f77d431f0c253750dbf320fa15c31b34.jpg\n",
      "./datasets/videos/test/7426_F2.mp4\n",
      "['7426', 'F2', 'f000232', 'jpg.rf.87a76c4f565f9829e6c38d0bd1ed9b55.jpg']\n",
      "7426_F2 f000232jpg.rf.87a76c4f565f9829e6c38d0bd1ed9b55.jpg\n",
      "./datasets/videos/test/7426_F2.mp4\n",
      "['7426', 'F3', 'f000031', 'jpg.rf.9cff845acce3b9472dc09594a21eff99.jpg']\n",
      "7426_F3 f000031jpg.rf.9cff845acce3b9472dc09594a21eff99.jpg\n",
      "./datasets/videos/test/7426_F3.mp4\n",
      "Starting a new video for 7426_F3\n",
      "['7426', 'F3', 'f000039', 'jpg.rf.b38a8723e45671cda7cdfeb371b3b724.jpg']\n",
      "7426_F3 f000039jpg.rf.b38a8723e45671cda7cdfeb371b3b724.jpg\n",
      "./datasets/videos/test/7426_F3.mp4\n",
      "['7426', 'F3', 'f000041', 'jpg.rf.3cf1b76fb1f0c970a2d3acd5fb836460.jpg']\n",
      "7426_F3 f000041jpg.rf.3cf1b76fb1f0c970a2d3acd5fb836460.jpg\n",
      "./datasets/videos/test/7426_F3.mp4\n",
      "['7426', 'F3', 'f000055', 'jpg.rf.ef0fb3849b8f28c1b2184e10d37febe6.jpg']\n",
      "7426_F3 f000055jpg.rf.ef0fb3849b8f28c1b2184e10d37febe6.jpg\n",
      "./datasets/videos/test/7426_F3.mp4\n",
      "['7426', 'NF1', 'f000115', 'jpg.rf.ca2681eeec26448a4ee6937749a10fa3.jpg']\n",
      "7426_NF1 f000115jpg.rf.ca2681eeec26448a4ee6937749a10fa3.jpg\n",
      "./datasets/videos/test/7426_NF1.mp4\n",
      "Starting a new video for 7426_NF1\n",
      "['7426', 'NF1', 'f000123', 'jpg.rf.142231bd28976dff5bc01f541bd4a7f4.jpg']\n",
      "7426_NF1 f000123jpg.rf.142231bd28976dff5bc01f541bd4a7f4.jpg\n",
      "./datasets/videos/test/7426_NF1.mp4\n",
      "['7426', 'NF1', 'f000133', 'jpg.rf.8a8a7e1f981f607ee7a846de5fcf8d4d.jpg']\n",
      "7426_NF1 f000133jpg.rf.8a8a7e1f981f607ee7a846de5fcf8d4d.jpg\n",
      "./datasets/videos/test/7426_NF1.mp4\n",
      "['7426', 'NF1', 'f000140', 'jpg.rf.e9fdb74ce895a8064cf0b1d217fe3dff.jpg']\n",
      "7426_NF1 f000140jpg.rf.e9fdb74ce895a8064cf0b1d217fe3dff.jpg\n",
      "./datasets/videos/test/7426_NF1.mp4\n",
      "['7426', 'NF1', 'f000147', 'jpg.rf.416cfde8ddd58888f234838fb71d4939.jpg']\n",
      "7426_NF1 f000147jpg.rf.416cfde8ddd58888f234838fb71d4939.jpg\n",
      "./datasets/videos/test/7426_NF1.mp4\n",
      "['7426', 'NF1', 'f000157', 'jpg.rf.23122fd72a4c8f742b41bbae9420a58b.jpg']\n",
      "7426_NF1 f000157jpg.rf.23122fd72a4c8f742b41bbae9420a58b.jpg\n",
      "./datasets/videos/test/7426_NF1.mp4\n",
      "['7426', 'NF1', 'f000161', 'jpg.rf.45f3b8a59bfd59ebf932d0c0de0d0b91.jpg']\n",
      "7426_NF1 f000161jpg.rf.45f3b8a59bfd59ebf932d0c0de0d0b91.jpg\n",
      "./datasets/videos/test/7426_NF1.mp4\n",
      "['7426', 'NF1', 'f000172', 'jpg.rf.c0065296ebd7ae3119217f925e6a46d1.jpg']\n",
      "7426_NF1 f000172jpg.rf.c0065296ebd7ae3119217f925e6a46d1.jpg\n",
      "./datasets/videos/test/7426_NF1.mp4\n",
      "['7426', 'NF1', 'f000203', 'jpg.rf.6f8d17675e1ab0dad19fa4d87caa5c82.jpg']\n",
      "7426_NF1 f000203jpg.rf.6f8d17675e1ab0dad19fa4d87caa5c82.jpg\n",
      "./datasets/videos/test/7426_NF1.mp4\n",
      "['7426', 'NF1', 'f000223', 'jpg.rf.c398c92ca9b2d60a5a135f7fdea7558e.jpg']\n",
      "7426_NF1 f000223jpg.rf.c398c92ca9b2d60a5a135f7fdea7558e.jpg\n",
      "./datasets/videos/test/7426_NF1.mp4\n",
      "['7426', 'NF1', 'f000247', 'jpg.rf.d782d1b3853326e7c103482fcad74207.jpg']\n",
      "7426_NF1 f000247jpg.rf.d782d1b3853326e7c103482fcad74207.jpg\n",
      "./datasets/videos/test/7426_NF1.mp4\n",
      "['7426', 'NF1', 'f000248', 'jpg.rf.088beaeeda63ab1306307f8b28005269.jpg']\n",
      "7426_NF1 f000248jpg.rf.088beaeeda63ab1306307f8b28005269.jpg\n",
      "./datasets/videos/test/7426_NF1.mp4\n",
      "['7426', 'NF1', 'f000251', 'jpg.rf.31367575611f60670dbadb86544d4a0a.jpg']\n",
      "7426_NF1 f000251jpg.rf.31367575611f60670dbadb86544d4a0a.jpg\n",
      "./datasets/videos/test/7426_NF1.mp4\n",
      "['7434', 'F1', 'f000083', 'jpg.rf.ffb1106754c413dcbe0db1e48fadcec7.jpg']\n",
      "7434_F1 f000083jpg.rf.ffb1106754c413dcbe0db1e48fadcec7.jpg\n",
      "./datasets/videos/test/7434_F1.mp4\n",
      "Starting a new video for 7434_F1\n",
      "['7434', 'F1', 'f000096', 'jpg.rf.01ecdd9a5b3a9442e0757d2deee03b79.jpg']\n",
      "7434_F1 f000096jpg.rf.01ecdd9a5b3a9442e0757d2deee03b79.jpg\n",
      "./datasets/videos/test/7434_F1.mp4\n",
      "['7434', 'F1', 'f000100', 'jpg.rf.e6b0c7850c1237f532ea628903685275.jpg']\n",
      "7434_F1 f000100jpg.rf.e6b0c7850c1237f532ea628903685275.jpg\n",
      "./datasets/videos/test/7434_F1.mp4\n",
      "['7434', 'F1', 'f000105', 'jpg.rf.325a81df341baa8306ed0176091cf43e.jpg']\n",
      "7434_F1 f000105jpg.rf.325a81df341baa8306ed0176091cf43e.jpg\n",
      "./datasets/videos/test/7434_F1.mp4\n",
      "['7434', 'F1', 'f000111', 'jpg.rf.0c7a08951387aec7bb73327c53a63335.jpg']\n",
      "7434_F1 f000111jpg.rf.0c7a08951387aec7bb73327c53a63335.jpg\n",
      "./datasets/videos/test/7434_F1.mp4\n",
      "['7434', 'F1', 'f000263', 'jpg.rf.354604af6764a24d4cafe2303b089d31.jpg']\n",
      "7434_F1 f000263jpg.rf.354604af6764a24d4cafe2303b089d31.jpg\n",
      "./datasets/videos/test/7434_F1.mp4\n",
      "['7434', 'F1', 'f000266', 'jpg.rf.3add6baf000f259c92044e0fd985a06d.jpg']\n",
      "7434_F1 f000266jpg.rf.3add6baf000f259c92044e0fd985a06d.jpg\n",
      "./datasets/videos/test/7434_F1.mp4\n",
      "['7434', 'F1', 'f000281', 'jpg.rf.f2fdde1f46857b8c3e5aec433813b179.jpg']\n",
      "7434_F1 f000281jpg.rf.f2fdde1f46857b8c3e5aec433813b179.jpg\n",
      "./datasets/videos/test/7434_F1.mp4\n",
      "['7434', 'F1', 'f000284', 'jpg.rf.cf263b3362d9e129c5930f08eea2d822.jpg']\n",
      "7434_F1 f000284jpg.rf.cf263b3362d9e129c5930f08eea2d822.jpg\n",
      "./datasets/videos/test/7434_F1.mp4\n",
      "['7434', 'F1', 'f000522', 'jpg.rf.b6899ae6ab3a68a4a8bdd0f83e77bf47.jpg']\n",
      "7434_F1 f000522jpg.rf.b6899ae6ab3a68a4a8bdd0f83e77bf47.jpg\n",
      "./datasets/videos/test/7434_F1.mp4\n",
      "['7434', 'F1', 'f000525', 'jpg.rf.592f62dd6d38317efbe314aa4e62ff75.jpg']\n",
      "7434_F1 f000525jpg.rf.592f62dd6d38317efbe314aa4e62ff75.jpg\n",
      "./datasets/videos/test/7434_F1.mp4\n",
      "['7434', 'F1', 'f000529', 'jpg.rf.fd20e562b22e0d392be42fa1f633fc38.jpg']\n",
      "7434_F1 f000529jpg.rf.fd20e562b22e0d392be42fa1f633fc38.jpg\n",
      "./datasets/videos/test/7434_F1.mp4\n",
      "['7434', 'F1', 'f000534', 'jpg.rf.f90a0fbc6cb81fe23f5217f376fd40f5.jpg']\n",
      "7434_F1 f000534jpg.rf.f90a0fbc6cb81fe23f5217f376fd40f5.jpg\n",
      "./datasets/videos/test/7434_F1.mp4\n",
      "['7434', 'F1', 'f000539', 'jpg.rf.9c6179e9b2b6dd06526a32a3a3b94808.jpg']\n",
      "7434_F1 f000539jpg.rf.9c6179e9b2b6dd06526a32a3a3b94808.jpg\n",
      "./datasets/videos/test/7434_F1.mp4\n",
      "['7434', 'F1', 'f000543', 'jpg.rf.e80e99e273635f8e80961f08117bbefb.jpg']\n",
      "7434_F1 f000543jpg.rf.e80e99e273635f8e80961f08117bbefb.jpg\n",
      "./datasets/videos/test/7434_F1.mp4\n",
      "['7434', 'F1', 'f000547', 'jpg.rf.d69ffa7f7497bc1f05551ff6c5e2c3be.jpg']\n",
      "7434_F1 f000547jpg.rf.d69ffa7f7497bc1f05551ff6c5e2c3be.jpg\n",
      "./datasets/videos/test/7434_F1.mp4\n",
      "['7434', 'F1', 'f000548', 'jpg.rf.59513cc8d348e9ec0d89cb98d0bad123.jpg']\n",
      "7434_F1 f000548jpg.rf.59513cc8d348e9ec0d89cb98d0bad123.jpg\n",
      "./datasets/videos/test/7434_F1.mp4\n",
      "['7434', 'F1', 'f000553', 'jpg.rf.a048d4d9557fe70a5e107674013c04c7.jpg']\n",
      "7434_F1 f000553jpg.rf.a048d4d9557fe70a5e107674013c04c7.jpg\n",
      "./datasets/videos/test/7434_F1.mp4\n",
      "['7434', 'F1', 'f000629', 'jpg.rf.101d948c12d4539d568ff415451525c6.jpg']\n",
      "7434_F1 f000629jpg.rf.101d948c12d4539d568ff415451525c6.jpg\n",
      "./datasets/videos/test/7434_F1.mp4\n",
      "['7434', 'F1', 'f000641', 'jpg.rf.7985bc17afce061e9fdcb5447dbc4321.jpg']\n",
      "7434_F1 f000641jpg.rf.7985bc17afce061e9fdcb5447dbc4321.jpg\n",
      "./datasets/videos/test/7434_F1.mp4\n",
      "['7434', 'F1', 'f000647', 'jpg.rf.08f3c255d6e4270b2c04643a61fbb0bc.jpg']\n",
      "7434_F1 f000647jpg.rf.08f3c255d6e4270b2c04643a61fbb0bc.jpg\n",
      "./datasets/videos/test/7434_F1.mp4\n",
      "['7434', 'F1', 'f000717', 'jpg.rf.a94a98c0dddeba46b7f9576345bcc684.jpg']\n",
      "7434_F1 f000717jpg.rf.a94a98c0dddeba46b7f9576345bcc684.jpg\n",
      "./datasets/videos/test/7434_F1.mp4\n",
      "['7434', 'F1', 'f000726', 'jpg.rf.69405d3b4e713a3dca679b774de08c42.jpg']\n",
      "7434_F1 f000726jpg.rf.69405d3b4e713a3dca679b774de08c42.jpg\n",
      "./datasets/videos/test/7434_F1.mp4\n",
      "['7434', 'F1', 'f000733', 'jpg.rf.10eeabaaa46e28af0cd1923682ce0e46.jpg']\n",
      "7434_F1 f000733jpg.rf.10eeabaaa46e28af0cd1923682ce0e46.jpg\n",
      "./datasets/videos/test/7434_F1.mp4\n",
      "['7434', 'F1', 'f000744', 'jpg.rf.1f7d5440cfd74b08540ee13190d0e52f.jpg']\n",
      "7434_F1 f000744jpg.rf.1f7d5440cfd74b08540ee13190d0e52f.jpg\n",
      "./datasets/videos/test/7434_F1.mp4\n",
      "['7434', 'F1', 'f000746', 'jpg.rf.7034b4f6349c67fd1ff86bcc667ff9bf.jpg']\n",
      "7434_F1 f000746jpg.rf.7034b4f6349c67fd1ff86bcc667ff9bf.jpg\n",
      "./datasets/videos/test/7434_F1.mp4\n",
      "['7434', 'F1', 'f000749', 'jpg.rf.0b92c7047e128d56200e7543cbceae39.jpg']\n",
      "7434_F1 f000749jpg.rf.0b92c7047e128d56200e7543cbceae39.jpg\n",
      "./datasets/videos/test/7434_F1.mp4\n",
      "['7434', 'F1', 'f000821', 'jpg.rf.30431aefbe17a8f9d3600ab6c4888b69.jpg']\n",
      "7434_F1 f000821jpg.rf.30431aefbe17a8f9d3600ab6c4888b69.jpg\n",
      "./datasets/videos/test/7434_F1.mp4\n",
      "['7434', 'F1', 'f000823', 'jpg.rf.68dc52823dc4de06923b2123b07a0a97.jpg']\n",
      "7434_F1 f000823jpg.rf.68dc52823dc4de06923b2123b07a0a97.jpg\n",
      "./datasets/videos/test/7434_F1.mp4\n",
      "['7434', 'F1', 'f000862', 'jpg.rf.d2b251c70662cd56ef91b1f6c5132495.jpg']\n",
      "7434_F1 f000862jpg.rf.d2b251c70662cd56ef91b1f6c5132495.jpg\n",
      "./datasets/videos/test/7434_F1.mp4\n",
      "['7434', 'F1', 'f000867', 'jpg.rf.af6577cdd16a977d47261ebd92e6b144.jpg']\n",
      "7434_F1 f000867jpg.rf.af6577cdd16a977d47261ebd92e6b144.jpg\n",
      "./datasets/videos/test/7434_F1.mp4\n",
      "['7434', 'F1', 'f000885', 'jpg.rf.71b044438c295dbcfd5b1f41db1e3990.jpg']\n",
      "7434_F1 f000885jpg.rf.71b044438c295dbcfd5b1f41db1e3990.jpg\n",
      "./datasets/videos/test/7434_F1.mp4\n",
      "['7434', 'F1', 'f000889', 'jpg.rf.e211bc0cedbf8bdc80955da05b401fb3.jpg']\n",
      "7434_F1 f000889jpg.rf.e211bc0cedbf8bdc80955da05b401fb3.jpg\n",
      "./datasets/videos/test/7434_F1.mp4\n",
      "['7434', 'F1', 'f000908', 'jpg.rf.0cd1f4ac93a313dda69e654e12a2fa65.jpg']\n",
      "7434_F1 f000908jpg.rf.0cd1f4ac93a313dda69e654e12a2fa65.jpg\n",
      "./datasets/videos/test/7434_F1.mp4\n",
      "['7434', 'F1', 'f000911', 'jpg.rf.f8c2fafa088e6e41ccd5b0e32d63faae.jpg']\n",
      "7434_F1 f000911jpg.rf.f8c2fafa088e6e41ccd5b0e32d63faae.jpg\n",
      "./datasets/videos/test/7434_F1.mp4\n",
      "['7434', 'F1', 'f000916', 'jpg.rf.28cb9b7404d06d22b9dbefad45f7885b.jpg']\n",
      "7434_F1 f000916jpg.rf.28cb9b7404d06d22b9dbefad45f7885b.jpg\n",
      "./datasets/videos/test/7434_F1.mp4\n",
      "['7434', 'F1', 'f001019', 'jpg.rf.273f581280638e29c61d1a490f9e2e93.jpg']\n",
      "7434_F1 f001019jpg.rf.273f581280638e29c61d1a490f9e2e93.jpg\n",
      "./datasets/videos/test/7434_F1.mp4\n",
      "['7434', 'F1', 'f001027', 'jpg.rf.121919f79129154e16dc052c1d4b7d9d.jpg']\n",
      "7434_F1 f001027jpg.rf.121919f79129154e16dc052c1d4b7d9d.jpg\n",
      "./datasets/videos/test/7434_F1.mp4\n",
      "['7434', 'F1', 'f001033', 'jpg.rf.84c76f39aa550b667c7a858ed9046c9a.jpg']\n",
      "7434_F1 f001033jpg.rf.84c76f39aa550b667c7a858ed9046c9a.jpg\n",
      "./datasets/videos/test/7434_F1.mp4\n",
      "['7434', 'F2', 'f000013', 'jpg.rf.d77aa0be42599debe768ac05f85307f9.jpg']\n",
      "7434_F2 f000013jpg.rf.d77aa0be42599debe768ac05f85307f9.jpg\n",
      "./datasets/videos/test/7434_F2.mp4\n",
      "Starting a new video for 7434_F2\n",
      "['7434', 'F2', 'f000025', 'jpg.rf.80bb61f5bfbe9f2e77fd8493316f8d3f.jpg']\n",
      "7434_F2 f000025jpg.rf.80bb61f5bfbe9f2e77fd8493316f8d3f.jpg\n",
      "./datasets/videos/test/7434_F2.mp4\n",
      "['7434', 'F2', 'f000031', 'jpg.rf.74a3ecabe0b61ab01f16540211481ca1.jpg']\n",
      "7434_F2 f000031jpg.rf.74a3ecabe0b61ab01f16540211481ca1.jpg\n",
      "./datasets/videos/test/7434_F2.mp4\n",
      "['7434', 'F2', 'f000033', 'jpg.rf.6ed41f48edcb9bbd070e5fe6c8129d82.jpg']\n",
      "7434_F2 f000033jpg.rf.6ed41f48edcb9bbd070e5fe6c8129d82.jpg\n",
      "./datasets/videos/test/7434_F2.mp4\n",
      "['7434', 'F2', 'f000037', 'jpg.rf.49774a7f5975a2125583760aeff29e47.jpg']\n",
      "7434_F2 f000037jpg.rf.49774a7f5975a2125583760aeff29e47.jpg\n",
      "./datasets/videos/test/7434_F2.mp4\n",
      "['7434', 'F2', 'f000046', 'jpg.rf.9378256ee33e09acacdefcfa4c72b3b4.jpg']\n",
      "7434_F2 f000046jpg.rf.9378256ee33e09acacdefcfa4c72b3b4.jpg\n",
      "./datasets/videos/test/7434_F2.mp4\n",
      "['7434', 'NF2', 'f000018', 'jpg.rf.85f0a416da7cfdbf0e0228454404cfdc.jpg']\n",
      "7434_NF2 f000018jpg.rf.85f0a416da7cfdbf0e0228454404cfdc.jpg\n",
      "./datasets/videos/test/7434_NF2.mp4\n",
      "Starting a new video for 7434_NF2\n",
      "['7434', 'NF2', 'f000019', 'jpg.rf.72b0e2a8587682d55b85d130685b47e1.jpg']\n",
      "7434_NF2 f000019jpg.rf.72b0e2a8587682d55b85d130685b47e1.jpg\n",
      "./datasets/videos/test/7434_NF2.mp4\n",
      "['7434', 'NF2', 'f000029', 'jpg.rf.34620eeed17c56c5caf97f7db2745905.jpg']\n",
      "7434_NF2 f000029jpg.rf.34620eeed17c56c5caf97f7db2745905.jpg\n",
      "./datasets/videos/test/7434_NF2.mp4\n",
      "['7434', 'NF2', 'f000031', 'jpg.rf.5968cea4e0e30968d8632d4be4c0ed08.jpg']\n",
      "7434_NF2 f000031jpg.rf.5968cea4e0e30968d8632d4be4c0ed08.jpg\n",
      "./datasets/videos/test/7434_NF2.mp4\n",
      "['7434', 'NF2', 'f000037', 'jpg.rf.189ba489538b53ad26af255986ce0df1.jpg']\n",
      "7434_NF2 f000037jpg.rf.189ba489538b53ad26af255986ce0df1.jpg\n",
      "./datasets/videos/test/7434_NF2.mp4\n",
      "['7434', 'NF2', 'f000056', 'jpg.rf.fbb12a98748177344d51a7a1006e7602.jpg']\n",
      "7434_NF2 f000056jpg.rf.fbb12a98748177344d51a7a1006e7602.jpg\n",
      "./datasets/videos/test/7434_NF2.mp4\n",
      "['7434', 'NF2', 'f000058', 'jpg.rf.0a7612af3f776368cd2e9e53707419be.jpg']\n",
      "7434_NF2 f000058jpg.rf.0a7612af3f776368cd2e9e53707419be.jpg\n",
      "./datasets/videos/test/7434_NF2.mp4\n",
      "['7434', 'NF2', 'f000060', 'jpg.rf.470f800cfd909bc26a8ab7245f8ce6ac.jpg']\n",
      "7434_NF2 f000060jpg.rf.470f800cfd909bc26a8ab7245f8ce6ac.jpg\n",
      "./datasets/videos/test/7434_NF2.mp4\n",
      "['7434', 'NF2', 'f000061', 'jpg.rf.c3ff9344882f61c38483d01fa08ec2ff.jpg']\n",
      "7434_NF2 f000061jpg.rf.c3ff9344882f61c38483d01fa08ec2ff.jpg\n",
      "./datasets/videos/test/7434_NF2.mp4\n",
      "['7434', 'NF2', 'f000064', 'jpg.rf.5dba8a4698173c3c1fc034189dcac75a.jpg']\n",
      "7434_NF2 f000064jpg.rf.5dba8a4698173c3c1fc034189dcac75a.jpg\n",
      "./datasets/videos/test/7434_NF2.mp4\n",
      "['7434', 'NF2', 'f000067', 'jpg.rf.22189d5a6c68cf72e485fbd268f6f539.jpg']\n",
      "7434_NF2 f000067jpg.rf.22189d5a6c68cf72e485fbd268f6f539.jpg\n",
      "./datasets/videos/test/7434_NF2.mp4\n",
      "['7434', 'NF2', 'f000075', 'jpg.rf.56a1cdd10c066d0e06d69e93434fb712.jpg']\n",
      "7434_NF2 f000075jpg.rf.56a1cdd10c066d0e06d69e93434fb712.jpg\n",
      "./datasets/videos/test/7434_NF2.mp4\n",
      "['7434', 'NF2', 'f000082', 'jpg.rf.0081c31b69e54318c52c62bc14330cf6.jpg']\n",
      "7434_NF2 f000082jpg.rf.0081c31b69e54318c52c62bc14330cf6.jpg\n",
      "./datasets/videos/test/7434_NF2.mp4\n",
      "['7434', 'NF2', 'f000083', 'jpg.rf.9358bd9e7392b4d11a2582227c0cb8e1.jpg']\n",
      "7434_NF2 f000083jpg.rf.9358bd9e7392b4d11a2582227c0cb8e1.jpg\n",
      "./datasets/videos/test/7434_NF2.mp4\n",
      "['7434', 'NF2', 'f000087', 'jpg.rf.37fe40db777d5e329e2878905dac131c.jpg']\n",
      "7434_NF2 f000087jpg.rf.37fe40db777d5e329e2878905dac131c.jpg\n",
      "./datasets/videos/test/7434_NF2.mp4\n",
      "['7434', 'NF2', 'f000091', 'jpg.rf.e409bb94cc762f7837e83bcab4f46bf5.jpg']\n",
      "7434_NF2 f000091jpg.rf.e409bb94cc762f7837e83bcab4f46bf5.jpg\n",
      "./datasets/videos/test/7434_NF2.mp4\n",
      "['7434', 'NF2', 'f000095', 'jpg.rf.1fad47bad800cfea6956aaf1e8202d8c.jpg']\n",
      "7434_NF2 f000095jpg.rf.1fad47bad800cfea6956aaf1e8202d8c.jpg\n",
      "./datasets/videos/test/7434_NF2.mp4\n",
      "['7434', 'NF2', 'f000096', 'jpg.rf.10189e7ce0d4cc3f1d75089f82560335.jpg']\n",
      "7434_NF2 f000096jpg.rf.10189e7ce0d4cc3f1d75089f82560335.jpg\n",
      "./datasets/videos/test/7434_NF2.mp4\n",
      "['7434', 'NF2', 'f000106', 'jpg.rf.b459e8503788f18b3fd1d5723e315aa5.jpg']\n",
      "7434_NF2 f000106jpg.rf.b459e8503788f18b3fd1d5723e315aa5.jpg\n",
      "./datasets/videos/test/7434_NF2.mp4\n",
      "['7434', 'NF2', 'f000107', 'jpg.rf.c197dde3fd4ace8c381b0600cce2180b.jpg']\n",
      "7434_NF2 f000107jpg.rf.c197dde3fd4ace8c381b0600cce2180b.jpg\n",
      "./datasets/videos/test/7434_NF2.mp4\n",
      "['7434', 'NF2', 'f000111', 'jpg.rf.f288a6cae34af47ff9c63f67aa00f9e8.jpg']\n",
      "7434_NF2 f000111jpg.rf.f288a6cae34af47ff9c63f67aa00f9e8.jpg\n",
      "./datasets/videos/test/7434_NF2.mp4\n",
      "['7434', 'NF3', 'f000000', 'jpg.rf.93694cdb042ccbf360dca390f711b765.jpg']\n",
      "7434_NF3 f000000jpg.rf.93694cdb042ccbf360dca390f711b765.jpg\n",
      "./datasets/videos/test/7434_NF3.mp4\n",
      "Starting a new video for 7434_NF3\n",
      "['7434', 'NF3', 'f000007', 'jpg.rf.c6a1e3479c39f84152a2c0f8c9f6144a.jpg']\n",
      "7434_NF3 f000007jpg.rf.c6a1e3479c39f84152a2c0f8c9f6144a.jpg\n",
      "./datasets/videos/test/7434_NF3.mp4\n",
      "['7434', 'NF3', 'f000021', 'jpg.rf.1ac0aec684f8a85d331918f5a1a7f053.jpg']\n",
      "7434_NF3 f000021jpg.rf.1ac0aec684f8a85d331918f5a1a7f053.jpg\n",
      "./datasets/videos/test/7434_NF3.mp4\n",
      "['7434', 'NF3', 'f000031', 'jpg.rf.f98e823fdf05d26e543995960695d5ad.jpg']\n",
      "7434_NF3 f000031jpg.rf.f98e823fdf05d26e543995960695d5ad.jpg\n",
      "./datasets/videos/test/7434_NF3.mp4\n",
      "['7434', 'NF3', 'f000054', 'jpg.rf.033f25c00a53b38a41c08cd7da83c67b.jpg']\n",
      "7434_NF3 f000054jpg.rf.033f25c00a53b38a41c08cd7da83c67b.jpg\n",
      "./datasets/videos/test/7434_NF3.mp4\n",
      "['7434', 'NF3', 'f000063', 'jpg.rf.8557d455597bcaa8a30d315adccaf13f.jpg']\n",
      "7434_NF3 f000063jpg.rf.8557d455597bcaa8a30d315adccaf13f.jpg\n",
      "./datasets/videos/test/7434_NF3.mp4\n",
      "['7434', 'NF3', 'f000087', 'jpg.rf.f77ead23f3888a3ff9956e202b3de32a.jpg']\n",
      "7434_NF3 f000087jpg.rf.f77ead23f3888a3ff9956e202b3de32a.jpg\n",
      "./datasets/videos/test/7434_NF3.mp4\n",
      "['7434', 'NF3', 'f000091', 'jpg.rf.74713d94cb4ee6c44340123b299cfaec.jpg']\n",
      "7434_NF3 f000091jpg.rf.74713d94cb4ee6c44340123b299cfaec.jpg\n",
      "./datasets/videos/test/7434_NF3.mp4\n",
      "['7434', 'NF3', 'f000101', 'jpg.rf.b7623ad3464fab618319c51fb708be76.jpg']\n",
      "7434_NF3 f000101jpg.rf.b7623ad3464fab618319c51fb708be76.jpg\n",
      "./datasets/videos/test/7434_NF3.mp4\n",
      "['7434', 'NF3', 'f000107', 'jpg.rf.8fe92d9e88858fab88c9c20e20d0a205.jpg']\n",
      "7434_NF3 f000107jpg.rf.8fe92d9e88858fab88c9c20e20d0a205.jpg\n",
      "./datasets/videos/test/7434_NF3.mp4\n",
      "['7434', 'NF3', 'f000116', 'jpg.rf.41d91cdb896b750c35d0561798420a87.jpg']\n",
      "7434_NF3 f000116jpg.rf.41d91cdb896b750c35d0561798420a87.jpg\n",
      "./datasets/videos/test/7434_NF3.mp4\n",
      "['7434', 'NF3', 'f000121', 'jpg.rf.da6b628839650384f6c345d1053f559f.jpg']\n",
      "7434_NF3 f000121jpg.rf.da6b628839650384f6c345d1053f559f.jpg\n",
      "./datasets/videos/test/7434_NF3.mp4\n",
      "['7434', 'NF3', 'f000134', 'jpg.rf.97d630c1e6053669ad3e837cbad8c681.jpg']\n",
      "7434_NF3 f000134jpg.rf.97d630c1e6053669ad3e837cbad8c681.jpg\n",
      "./datasets/videos/test/7434_NF3.mp4\n",
      "['7463', 'F1', 'f000009', 'jpg.rf.83a01a5c90922411f1298b2f5a154f2d.jpg']\n",
      "7463_F1 f000009jpg.rf.83a01a5c90922411f1298b2f5a154f2d.jpg\n",
      "./datasets/videos/test/7463_F1.mp4\n",
      "Starting a new video for 7463_F1\n",
      "['7463', 'F1', 'f000011', 'jpg.rf.a58f718ae83bbe76ff37167b9018ba2a.jpg']\n",
      "7463_F1 f000011jpg.rf.a58f718ae83bbe76ff37167b9018ba2a.jpg\n",
      "./datasets/videos/test/7463_F1.mp4\n",
      "['7463', 'F1', 'f000013', 'jpg.rf.37e79bb5ec1f0d60caec357a776c44c3.jpg']\n",
      "7463_F1 f000013jpg.rf.37e79bb5ec1f0d60caec357a776c44c3.jpg\n",
      "./datasets/videos/test/7463_F1.mp4\n",
      "['7463', 'F1', 'f000016', 'jpg.rf.9d2f5471f6c42efa09a0eca7d608f717.jpg']\n",
      "7463_F1 f000016jpg.rf.9d2f5471f6c42efa09a0eca7d608f717.jpg\n",
      "./datasets/videos/test/7463_F1.mp4\n",
      "['7463', 'F1', 'f000020', 'jpg.rf.d6b5cd8b816c6a332821a6b1d94663bc.jpg']\n",
      "7463_F1 f000020jpg.rf.d6b5cd8b816c6a332821a6b1d94663bc.jpg\n",
      "./datasets/videos/test/7463_F1.mp4\n",
      "['7463', 'F1', 'f000022', 'jpg.rf.fd30783d285781b84a9211ca7a0cf9bb.jpg']\n",
      "7463_F1 f000022jpg.rf.fd30783d285781b84a9211ca7a0cf9bb.jpg\n",
      "./datasets/videos/test/7463_F1.mp4\n",
      "['7463', 'F1', 'f000030', 'jpg.rf.996b489c4ad046998e8bacf666c78f44.jpg']\n",
      "7463_F1 f000030jpg.rf.996b489c4ad046998e8bacf666c78f44.jpg\n",
      "./datasets/videos/test/7463_F1.mp4\n",
      "['7463', 'F1', 'f000031', 'jpg.rf.f854d57fd54bc2a606e8055f402ad5d3.jpg']\n",
      "7463_F1 f000031jpg.rf.f854d57fd54bc2a606e8055f402ad5d3.jpg\n",
      "./datasets/videos/test/7463_F1.mp4\n",
      "['7463', 'F1', 'f000032', 'jpg.rf.cba08686794eec5622f6dae48aa9f186.jpg']\n",
      "7463_F1 f000032jpg.rf.cba08686794eec5622f6dae48aa9f186.jpg\n",
      "./datasets/videos/test/7463_F1.mp4\n",
      "['7463', 'F1', 'f000039', 'jpg.rf.018a3b88da9f7fbe0732410d5e55ad67.jpg']\n",
      "7463_F1 f000039jpg.rf.018a3b88da9f7fbe0732410d5e55ad67.jpg\n",
      "./datasets/videos/test/7463_F1.mp4\n",
      "['7463', 'F1', 'f000174', 'jpg.rf.e4ecd023178ff567178569f6fb8b1dcd.jpg']\n",
      "7463_F1 f000174jpg.rf.e4ecd023178ff567178569f6fb8b1dcd.jpg\n",
      "./datasets/videos/test/7463_F1.mp4\n",
      "['7463', 'F1', 'f000182', 'jpg.rf.a8f4e94b9c6a451560eabc39eac00212.jpg']\n",
      "7463_F1 f000182jpg.rf.a8f4e94b9c6a451560eabc39eac00212.jpg\n",
      "./datasets/videos/test/7463_F1.mp4\n",
      "['7463', 'F1', 'f000192', 'jpg.rf.d6cff2e8b366ff2e601937e0ac8f0f75.jpg']\n",
      "7463_F1 f000192jpg.rf.d6cff2e8b366ff2e601937e0ac8f0f75.jpg\n",
      "./datasets/videos/test/7463_F1.mp4\n",
      "['7463', 'F2', 'f000078', 'jpg.rf.a4fe46c8612d502d79e90b4140b7103b.jpg']\n",
      "7463_F2 f000078jpg.rf.a4fe46c8612d502d79e90b4140b7103b.jpg\n",
      "./datasets/videos/test/7463_F2.mp4\n",
      "Starting a new video for 7463_F2\n",
      "['7463', 'F2', 'f000084', 'jpg.rf.3d7864e8ae72d3451f278b0c59046198.jpg']\n",
      "7463_F2 f000084jpg.rf.3d7864e8ae72d3451f278b0c59046198.jpg\n",
      "./datasets/videos/test/7463_F2.mp4\n",
      "['7463', 'F2', 'f000236', 'jpg.rf.25f36c30fc44d870d0d4606fb77b611c.jpg']\n",
      "7463_F2 f000236jpg.rf.25f36c30fc44d870d0d4606fb77b611c.jpg\n",
      "./datasets/videos/test/7463_F2.mp4\n",
      "['7463', 'F3', 'f000011', 'jpg.rf.dace355eddcb193c4da58ef21edbdf67.jpg']\n",
      "7463_F3 f000011jpg.rf.dace355eddcb193c4da58ef21edbdf67.jpg\n",
      "./datasets/videos/test/7463_F3.mp4\n",
      "Starting a new video for 7463_F3\n",
      "['7463', 'F3', 'f000016', 'jpg.rf.87d088bd3e8d659ead87c146d3b6fba9.jpg']\n",
      "7463_F3 f000016jpg.rf.87d088bd3e8d659ead87c146d3b6fba9.jpg\n",
      "./datasets/videos/test/7463_F3.mp4\n",
      "['7463', 'F3', 'f000018', 'jpg.rf.7be4c2cd18adddbb6fe2f8d54973e58a.jpg']\n",
      "7463_F3 f000018jpg.rf.7be4c2cd18adddbb6fe2f8d54973e58a.jpg\n",
      "./datasets/videos/test/7463_F3.mp4\n",
      "['7463', 'F4', 'f000220', 'jpg.rf.37e3214d60a02004dbfaa12bd2b15fa8.jpg']\n",
      "7463_F4 f000220jpg.rf.37e3214d60a02004dbfaa12bd2b15fa8.jpg\n",
      "./datasets/videos/test/7463_F4.mp4\n",
      "Starting a new video for 7463_F4\n",
      "['7463', 'F4', 'f000352', 'jpg.rf.baf3cb4a366f5781de239062c91e04e8.jpg']\n",
      "7463_F4 f000352jpg.rf.baf3cb4a366f5781de239062c91e04e8.jpg\n",
      "./datasets/videos/test/7463_F4.mp4\n",
      "['7463', 'F4', 'f000353', 'jpg.rf.b4d4225eb978de6bb372e1d234533065.jpg']\n",
      "7463_F4 f000353jpg.rf.b4d4225eb978de6bb372e1d234533065.jpg\n",
      "./datasets/videos/test/7463_F4.mp4\n",
      "['7463', 'F4', 'f000358', 'jpg.rf.20e5fca4f0cbd92c52a889945822a39f.jpg']\n",
      "7463_F4 f000358jpg.rf.20e5fca4f0cbd92c52a889945822a39f.jpg\n",
      "./datasets/videos/test/7463_F4.mp4\n",
      "['7463', 'F4', 'f000451', 'jpg.rf.b17d62c031883e6867f084b55b6dd99a.jpg']\n",
      "7463_F4 f000451jpg.rf.b17d62c031883e6867f084b55b6dd99a.jpg\n",
      "./datasets/videos/test/7463_F4.mp4\n",
      "['7463', 'F4', 'f000615', 'jpg.rf.f33b6be97a337b27f09e76f256e46e11.jpg']\n",
      "7463_F4 f000615jpg.rf.f33b6be97a337b27f09e76f256e46e11.jpg\n",
      "./datasets/videos/test/7463_F4.mp4\n",
      "['7463', 'F5', 'f000012', 'jpg.rf.f88b213b43813627f930e288e5c3db82.jpg']\n",
      "7463_F5 f000012jpg.rf.f88b213b43813627f930e288e5c3db82.jpg\n",
      "./datasets/videos/test/7463_F5.mp4\n",
      "Starting a new video for 7463_F5\n",
      "['7463', 'F6', 'f000028', 'jpg.rf.c75fba57606e3ac356c09c357add1d94.jpg']\n",
      "7463_F6 f000028jpg.rf.c75fba57606e3ac356c09c357add1d94.jpg\n",
      "./datasets/videos/test/7463_F6.mp4\n",
      "Starting a new video for 7463_F6\n",
      "['7463', 'F6', 'f000032', 'jpg.rf.1953fb7a9d7b1eb5aa444c517f5bded5.jpg']\n",
      "7463_F6 f000032jpg.rf.1953fb7a9d7b1eb5aa444c517f5bded5.jpg\n",
      "./datasets/videos/test/7463_F6.mp4\n",
      "['7463', 'F6', 'f000035', 'jpg.rf.49a877b30acd42dcc327f63dc1fd34df.jpg']\n",
      "7463_F6 f000035jpg.rf.49a877b30acd42dcc327f63dc1fd34df.jpg\n",
      "./datasets/videos/test/7463_F6.mp4\n",
      "['7463', 'F6', 'f000049', 'jpg.rf.feaf425c41b9ab0d8d426d4dc9fc84b3.jpg']\n",
      "7463_F6 f000049jpg.rf.feaf425c41b9ab0d8d426d4dc9fc84b3.jpg\n",
      "./datasets/videos/test/7463_F6.mp4\n",
      "['7463', 'F6', 'f000060', 'jpg.rf.2ea42e21ca81de46ae19cc1a8f99c021.jpg']\n",
      "7463_F6 f000060jpg.rf.2ea42e21ca81de46ae19cc1a8f99c021.jpg\n",
      "./datasets/videos/test/7463_F6.mp4\n",
      "['7463', 'F6', 'f000077', 'jpg.rf.678a2d7a818cc8f3518d1d58a6e63903.jpg']\n",
      "7463_F6 f000077jpg.rf.678a2d7a818cc8f3518d1d58a6e63903.jpg\n",
      "./datasets/videos/test/7463_F6.mp4\n",
      "['7463', 'F6', 'f000100', 'jpg.rf.0ed4cbf9712bf715062c53df6475d3f6.jpg']\n",
      "7463_F6 f000100jpg.rf.0ed4cbf9712bf715062c53df6475d3f6.jpg\n",
      "./datasets/videos/test/7463_F6.mp4\n",
      "['7463', 'F6', 'f000106', 'jpg.rf.f60d77d99742834360d3721d290de6ed.jpg']\n",
      "7463_F6 f000106jpg.rf.f60d77d99742834360d3721d290de6ed.jpg\n",
      "./datasets/videos/test/7463_F6.mp4\n",
      "['7463', 'F6', 'f000112', 'jpg.rf.85e0b199333ca8afc2464fa781f48584.jpg']\n",
      "7463_F6 f000112jpg.rf.85e0b199333ca8afc2464fa781f48584.jpg\n",
      "./datasets/videos/test/7463_F6.mp4\n",
      "['7463', 'F7', 'f000003', 'jpg.rf.a5131c04b8c1c354dc87079cdd6d67c2.jpg']\n",
      "7463_F7 f000003jpg.rf.a5131c04b8c1c354dc87079cdd6d67c2.jpg\n",
      "./datasets/videos/test/7463_F7.mp4\n",
      "Starting a new video for 7463_F7\n",
      "['7463', 'F7', 'f000004', 'jpg.rf.1c3a19f0720dbc30896af5e9f99a07af.jpg']\n",
      "7463_F7 f000004jpg.rf.1c3a19f0720dbc30896af5e9f99a07af.jpg\n",
      "./datasets/videos/test/7463_F7.mp4\n",
      "['7463', 'F7', 'f000038', 'jpg.rf.72780d8d3a4e9f6c8e08f0170bc25fff.jpg']\n",
      "7463_F7 f000038jpg.rf.72780d8d3a4e9f6c8e08f0170bc25fff.jpg\n",
      "./datasets/videos/test/7463_F7.mp4\n",
      "['7463', 'F7', 'f000076', 'jpg.rf.661718373333d7c82946e48c97222bba.jpg']\n",
      "7463_F7 f000076jpg.rf.661718373333d7c82946e48c97222bba.jpg\n",
      "./datasets/videos/test/7463_F7.mp4\n",
      "['7463', 'F7', 'f000081', 'jpg.rf.a2a85978019b6ef8ef62101a60721d1d.jpg']\n",
      "7463_F7 f000081jpg.rf.a2a85978019b6ef8ef62101a60721d1d.jpg\n",
      "./datasets/videos/test/7463_F7.mp4\n",
      "['7463', 'F7', 'f000091', 'jpg.rf.73f02b97172093d8de5aa03b3e49fe82.jpg']\n",
      "7463_F7 f000091jpg.rf.73f02b97172093d8de5aa03b3e49fe82.jpg\n",
      "./datasets/videos/test/7463_F7.mp4\n",
      "['7463', 'F7', 'f000095', 'jpg.rf.437d98c8906e58cab0c211336d59d1ea.jpg']\n",
      "7463_F7 f000095jpg.rf.437d98c8906e58cab0c211336d59d1ea.jpg\n",
      "./datasets/videos/test/7463_F7.mp4\n",
      "['7463', 'F7', 'f000097', 'jpg.rf.38d9cff6b0ead098ce804c67eea8c6b0.jpg']\n",
      "7463_F7 f000097jpg.rf.38d9cff6b0ead098ce804c67eea8c6b0.jpg\n",
      "./datasets/videos/test/7463_F7.mp4\n",
      "['7463', 'F7', 'f000142', 'jpg.rf.ac7019f3194fa419d7e6eead4c708b5e.jpg']\n",
      "7463_F7 f000142jpg.rf.ac7019f3194fa419d7e6eead4c708b5e.jpg\n",
      "./datasets/videos/test/7463_F7.mp4\n",
      "['7463', 'NF1', 'f000002', 'jpg.rf.1f679fb5f45dc14d0dbd274e39f32a73.jpg']\n",
      "7463_NF1 f000002jpg.rf.1f679fb5f45dc14d0dbd274e39f32a73.jpg\n",
      "./datasets/videos/test/7463_NF1.mp4\n",
      "Starting a new video for 7463_NF1\n",
      "['7463', 'NF1', 'f000068', 'jpg.rf.2d4de4dbef6e7c53d33140986b9c592b.jpg']\n",
      "7463_NF1 f000068jpg.rf.2d4de4dbef6e7c53d33140986b9c592b.jpg\n",
      "./datasets/videos/test/7463_NF1.mp4\n",
      "['7463', 'NF1', 'f000069', 'jpg.rf.061c4b6c8263d0be36ef8bc48d8ab3cc.jpg']\n",
      "7463_NF1 f000069jpg.rf.061c4b6c8263d0be36ef8bc48d8ab3cc.jpg\n",
      "./datasets/videos/test/7463_NF1.mp4\n",
      "['7463', 'NF1', 'f000070', 'jpg.rf.80484604483778a02337015da6230d62.jpg']\n",
      "7463_NF1 f000070jpg.rf.80484604483778a02337015da6230d62.jpg\n",
      "./datasets/videos/test/7463_NF1.mp4\n",
      "['7463', 'NF1', 'f000089', 'jpg.rf.e17373aaeea09809dd06e31aa9ef5385.jpg']\n",
      "7463_NF1 f000089jpg.rf.e17373aaeea09809dd06e31aa9ef5385.jpg\n",
      "./datasets/videos/test/7463_NF1.mp4\n",
      "['7463', 'NF1', 'f000112', 'jpg.rf.5d5eb95832d20d474172343d4cf6640e.jpg']\n",
      "7463_NF1 f000112jpg.rf.5d5eb95832d20d474172343d4cf6640e.jpg\n",
      "./datasets/videos/test/7463_NF1.mp4\n",
      "['7463', 'NF1', 'f000121', 'jpg.rf.8299a5e25371b72fe49e59732a536a3b.jpg']\n",
      "7463_NF1 f000121jpg.rf.8299a5e25371b72fe49e59732a536a3b.jpg\n",
      "./datasets/videos/test/7463_NF1.mp4\n",
      "['7463', 'NF1', 'f000152', 'jpg.rf.ffb059ab5678aac8b0ab30701ec93d42.jpg']\n",
      "7463_NF1 f000152jpg.rf.ffb059ab5678aac8b0ab30701ec93d42.jpg\n",
      "./datasets/videos/test/7463_NF1.mp4\n",
      "['7463', 'NF1', 'f000174', 'jpg.rf.02fb0bf5237f19fe621b61926423838a.jpg']\n",
      "7463_NF1 f000174jpg.rf.02fb0bf5237f19fe621b61926423838a.jpg\n",
      "./datasets/videos/test/7463_NF1.mp4\n",
      "['7463', 'NF1', 'f000193', 'jpg.rf.39734610a28faec4b9b2d8a91264fca8.jpg']\n",
      "7463_NF1 f000193jpg.rf.39734610a28faec4b9b2d8a91264fca8.jpg\n",
      "./datasets/videos/test/7463_NF1.mp4\n",
      "['7463', 'NF1', 'f000200', 'jpg.rf.418b15b4ae0c164bc287f755bb21264b.jpg']\n",
      "7463_NF1 f000200jpg.rf.418b15b4ae0c164bc287f755bb21264b.jpg\n",
      "./datasets/videos/test/7463_NF1.mp4\n",
      "['7463', 'NF3', 'f000000', 'jpg.rf.ce99616efa33ff74590daf05c6ea715f.jpg']\n",
      "7463_NF3 f000000jpg.rf.ce99616efa33ff74590daf05c6ea715f.jpg\n",
      "./datasets/videos/test/7463_NF3.mp4\n",
      "Starting a new video for 7463_NF3\n",
      "['7463', 'NF3', 'f000001', 'jpg.rf.bd096b8f89d835d1063223304d5a4e19.jpg']\n",
      "7463_NF3 f000001jpg.rf.bd096b8f89d835d1063223304d5a4e19.jpg\n",
      "./datasets/videos/test/7463_NF3.mp4\n",
      "['7463', 'NF3', 'f000010', 'jpg.rf.41e0812d5b6582577979e7afc6f139a7.jpg']\n",
      "7463_NF3 f000010jpg.rf.41e0812d5b6582577979e7afc6f139a7.jpg\n",
      "./datasets/videos/test/7463_NF3.mp4\n",
      "['7463', 'NF3', 'f000014', 'jpg.rf.c341bedf84b89093d83e4a31aeebb80e.jpg']\n",
      "7463_NF3 f000014jpg.rf.c341bedf84b89093d83e4a31aeebb80e.jpg\n",
      "./datasets/videos/test/7463_NF3.mp4\n",
      "['7463', 'NF3', 'f000018', 'jpg.rf.9f52046f9ae9d3e4fab51a196aa8828d.jpg']\n",
      "7463_NF3 f000018jpg.rf.9f52046f9ae9d3e4fab51a196aa8828d.jpg\n",
      "./datasets/videos/test/7463_NF3.mp4\n",
      "['7463', 'NF3', 'f000019', 'jpg.rf.0b16c7306db4efb4b0253143fa9949d9.jpg']\n",
      "7463_NF3 f000019jpg.rf.0b16c7306db4efb4b0253143fa9949d9.jpg\n",
      "./datasets/videos/test/7463_NF3.mp4\n",
      "['7463', 'NF3', 'f000032', 'jpg.rf.39df9a963cf44f85fa84a6a98f955ba5.jpg']\n",
      "7463_NF3 f000032jpg.rf.39df9a963cf44f85fa84a6a98f955ba5.jpg\n",
      "./datasets/videos/test/7463_NF3.mp4\n",
      "['7463', 'NF3', 'f000053', 'jpg.rf.14fea5bca8f1b75189266348a5d65d9a.jpg']\n",
      "7463_NF3 f000053jpg.rf.14fea5bca8f1b75189266348a5d65d9a.jpg\n",
      "./datasets/videos/test/7463_NF3.mp4\n",
      "['7482', 'F1', 'f000000', 'jpg.rf.94d263db4ee28cbc420df8a02393636c.jpg']\n",
      "7482_F1 f000000jpg.rf.94d263db4ee28cbc420df8a02393636c.jpg\n",
      "./datasets/videos/test/7482_F1.mp4\n",
      "Starting a new video for 7482_F1\n",
      "['7482', 'F1', 'f000011', 'jpg.rf.646e863b23cd41de949546950fbde3f1.jpg']\n",
      "7482_F1 f000011jpg.rf.646e863b23cd41de949546950fbde3f1.jpg\n",
      "./datasets/videos/test/7482_F1.mp4\n",
      "['7482', 'F1', 'f000023', 'jpg.rf.3a10526d6fa66b0b62a37d6cb745193d.jpg']\n",
      "7482_F1 f000023jpg.rf.3a10526d6fa66b0b62a37d6cb745193d.jpg\n",
      "./datasets/videos/test/7482_F1.mp4\n",
      "['7482', 'F1', 'f000036', 'jpg.rf.acb31a3f0f4f43a9cfb13965adabde32.jpg']\n",
      "7482_F1 f000036jpg.rf.acb31a3f0f4f43a9cfb13965adabde32.jpg\n",
      "./datasets/videos/test/7482_F1.mp4\n",
      "['7482', 'F1', 'f000047', 'jpg.rf.cc89fb6105f3791b0bc783baf8a8df49.jpg']\n",
      "7482_F1 f000047jpg.rf.cc89fb6105f3791b0bc783baf8a8df49.jpg\n",
      "./datasets/videos/test/7482_F1.mp4\n",
      "['7482', 'F1', 'f000068', 'jpg.rf.adce3f91f706c13d85096bcf4541df52.jpg']\n",
      "7482_F1 f000068jpg.rf.adce3f91f706c13d85096bcf4541df52.jpg\n",
      "./datasets/videos/test/7482_F1.mp4\n",
      "['7482', 'F1', 'f000310', 'jpg.rf.ff56ca6909792d4f790589bb0e73a477.jpg']\n",
      "7482_F1 f000310jpg.rf.ff56ca6909792d4f790589bb0e73a477.jpg\n",
      "./datasets/videos/test/7482_F1.mp4\n",
      "['7482', 'F1', 'f000312', 'jpg.rf.8bf042e110fcfbaf4f51ceeddb7d633c.jpg']\n",
      "7482_F1 f000312jpg.rf.8bf042e110fcfbaf4f51ceeddb7d633c.jpg\n",
      "./datasets/videos/test/7482_F1.mp4\n",
      "['7482', 'F2', 'f000074', 'jpg.rf.24d57a869b9779888419fc261fc4defb.jpg']\n",
      "7482_F2 f000074jpg.rf.24d57a869b9779888419fc261fc4defb.jpg\n",
      "./datasets/videos/test/7482_F2.mp4\n",
      "Starting a new video for 7482_F2\n",
      "['7482', 'F2', 'f000093', 'jpg.rf.c755317d69206bae123a49fc4d45b314.jpg']\n",
      "7482_F2 f000093jpg.rf.c755317d69206bae123a49fc4d45b314.jpg\n",
      "./datasets/videos/test/7482_F2.mp4\n",
      "['7482', 'F2', 'f000096', 'jpg.rf.db8435853fda503a4a135e1ad07b0731.jpg']\n",
      "7482_F2 f000096jpg.rf.db8435853fda503a4a135e1ad07b0731.jpg\n",
      "./datasets/videos/test/7482_F2.mp4\n",
      "['7482', 'F2', 'f000102', 'jpg.rf.771735b6a4bdfdf2ba5d1da19635ea65.jpg']\n",
      "7482_F2 f000102jpg.rf.771735b6a4bdfdf2ba5d1da19635ea65.jpg\n",
      "./datasets/videos/test/7482_F2.mp4\n",
      "['7482', 'F2', 'f000105', 'jpg.rf.61111bd764625edfc0fc938b7df7d9d3.jpg']\n",
      "7482_F2 f000105jpg.rf.61111bd764625edfc0fc938b7df7d9d3.jpg\n",
      "./datasets/videos/test/7482_F2.mp4\n",
      "['7482', 'F2', 'f000111', 'jpg.rf.c554db3c245da928a687d6e7a3ec6403.jpg']\n",
      "7482_F2 f000111jpg.rf.c554db3c245da928a687d6e7a3ec6403.jpg\n",
      "./datasets/videos/test/7482_F2.mp4\n",
      "['7482', 'F2', 'f000113', 'jpg.rf.7fb42eab10b8bfae9d2b41d5171d4e2d.jpg']\n",
      "7482_F2 f000113jpg.rf.7fb42eab10b8bfae9d2b41d5171d4e2d.jpg\n",
      "./datasets/videos/test/7482_F2.mp4\n",
      "['7482', 'F2', 'f000131', 'jpg.rf.bfaa09dc072d566020e1ccf70ce40cd1.jpg']\n",
      "7482_F2 f000131jpg.rf.bfaa09dc072d566020e1ccf70ce40cd1.jpg\n",
      "./datasets/videos/test/7482_F2.mp4\n",
      "['7482', 'F2', 'f000138', 'jpg.rf.2082409ff31c0e6295bb0a483ebc7771.jpg']\n",
      "7482_F2 f000138jpg.rf.2082409ff31c0e6295bb0a483ebc7771.jpg\n",
      "./datasets/videos/test/7482_F2.mp4\n",
      "['7482', 'F2', 'f000142', 'jpg.rf.25859a68985f3b653ca5b4d595338fc6.jpg']\n",
      "7482_F2 f000142jpg.rf.25859a68985f3b653ca5b4d595338fc6.jpg\n",
      "./datasets/videos/test/7482_F2.mp4\n",
      "['7482', 'F2', 'f000239', 'jpg.rf.475d1cf4370f7d97998e7445fe5865a7.jpg']\n",
      "7482_F2 f000239jpg.rf.475d1cf4370f7d97998e7445fe5865a7.jpg\n",
      "./datasets/videos/test/7482_F2.mp4\n",
      "['7482', 'F2', 'f000278', 'jpg.rf.d63910a6021c5acacee95ceede47b1ec.jpg']\n",
      "7482_F2 f000278jpg.rf.d63910a6021c5acacee95ceede47b1ec.jpg\n",
      "./datasets/videos/test/7482_F2.mp4\n",
      "['7482', 'F2', 'f000286', 'jpg.rf.1c2eae24ea0ea075e8a75b40db85b25f.jpg']\n",
      "7482_F2 f000286jpg.rf.1c2eae24ea0ea075e8a75b40db85b25f.jpg\n",
      "./datasets/videos/test/7482_F2.mp4\n",
      "['7482', 'F2', 'f000291', 'jpg.rf.1931f6ebf20bdf6839db191c4ffe6746.jpg']\n",
      "7482_F2 f000291jpg.rf.1931f6ebf20bdf6839db191c4ffe6746.jpg\n",
      "./datasets/videos/test/7482_F2.mp4\n",
      "['7482', 'F2', 'f000355', 'jpg.rf.2cf6bcd87780fc9cffbc2938ac5b25ce.jpg']\n",
      "7482_F2 f000355jpg.rf.2cf6bcd87780fc9cffbc2938ac5b25ce.jpg\n",
      "./datasets/videos/test/7482_F2.mp4\n",
      "['7482', 'F2', 'f000359', 'jpg.rf.60a62a386a94b35c9564ca17766a7742.jpg']\n",
      "7482_F2 f000359jpg.rf.60a62a386a94b35c9564ca17766a7742.jpg\n",
      "./datasets/videos/test/7482_F2.mp4\n",
      "['7482', 'F2', 'f000374', 'jpg.rf.81815f1453cd690b633eca5e11da4785.jpg']\n",
      "7482_F2 f000374jpg.rf.81815f1453cd690b633eca5e11da4785.jpg\n",
      "./datasets/videos/test/7482_F2.mp4\n",
      "['7482', 'F2', 'f000375', 'jpg.rf.93d12493857e0b5c06b7c94dcd67fa95.jpg']\n",
      "7482_F2 f000375jpg.rf.93d12493857e0b5c06b7c94dcd67fa95.jpg\n",
      "./datasets/videos/test/7482_F2.mp4\n",
      "['7482', 'F2', 'f000385', 'jpg.rf.699e59efc33fc63a462071b995e8ac3d.jpg']\n",
      "7482_F2 f000385jpg.rf.699e59efc33fc63a462071b995e8ac3d.jpg\n",
      "./datasets/videos/test/7482_F2.mp4\n",
      "['7482', 'F2', 'f000457', 'jpg.rf.be565b9c57acca3d97ab8090c69eeb41.jpg']\n",
      "7482_F2 f000457jpg.rf.be565b9c57acca3d97ab8090c69eeb41.jpg\n",
      "./datasets/videos/test/7482_F2.mp4\n",
      "['7482', 'F2', 'f000458', 'jpg.rf.ec8f99bb379e7bb5c600238346b66e62.jpg']\n",
      "7482_F2 f000458jpg.rf.ec8f99bb379e7bb5c600238346b66e62.jpg\n",
      "./datasets/videos/test/7482_F2.mp4\n",
      "['7482', 'F2', 'f000461', 'jpg.rf.6710b30f6ec7268e076b5e23bbe48ec8.jpg']\n",
      "7482_F2 f000461jpg.rf.6710b30f6ec7268e076b5e23bbe48ec8.jpg\n",
      "./datasets/videos/test/7482_F2.mp4\n",
      "['7482', 'NF1', 'f000014', 'jpg.rf.93e12c623b062dd0a17048d9ead502a8.jpg']\n",
      "7482_NF1 f000014jpg.rf.93e12c623b062dd0a17048d9ead502a8.jpg\n",
      "./datasets/videos/test/7482_NF1.mp4\n",
      "Starting a new video for 7482_NF1\n",
      "['7482', 'NF1', 'f000021', 'jpg.rf.d4fc61949f80056fe4cbf343ce9354fd.jpg']\n",
      "7482_NF1 f000021jpg.rf.d4fc61949f80056fe4cbf343ce9354fd.jpg\n",
      "./datasets/videos/test/7482_NF1.mp4\n",
      "['7482', 'NF1', 'f000038', 'jpg.rf.f83e303c763fd4e03b9eb54942dbee27.jpg']\n",
      "7482_NF1 f000038jpg.rf.f83e303c763fd4e03b9eb54942dbee27.jpg\n",
      "./datasets/videos/test/7482_NF1.mp4\n",
      "['7482', 'NF1', 'f000042', 'jpg.rf.b9d902d4612658a5e5cc642efae312be.jpg']\n",
      "7482_NF1 f000042jpg.rf.b9d902d4612658a5e5cc642efae312be.jpg\n",
      "./datasets/videos/test/7482_NF1.mp4\n",
      "['7482', 'NF1', 'f000049', 'jpg.rf.8c8a572e0ba2fde79431f04183401d01.jpg']\n",
      "7482_NF1 f000049jpg.rf.8c8a572e0ba2fde79431f04183401d01.jpg\n",
      "./datasets/videos/test/7482_NF1.mp4\n",
      "['7482', 'NF1', 'f000058', 'jpg.rf.e9fa81abe6785e76fc3f930135ff5071.jpg']\n",
      "7482_NF1 f000058jpg.rf.e9fa81abe6785e76fc3f930135ff5071.jpg\n",
      "./datasets/videos/test/7482_NF1.mp4\n",
      "['7482', 'NF1', 'f000061', 'jpg.rf.e68d5e7704ef753a1d479b375619be85.jpg']\n",
      "7482_NF1 f000061jpg.rf.e68d5e7704ef753a1d479b375619be85.jpg\n",
      "./datasets/videos/test/7482_NF1.mp4\n",
      "['7482', 'NF1', 'f000066', 'jpg.rf.5562af342448a6b408c54231febdcd93.jpg']\n",
      "7482_NF1 f000066jpg.rf.5562af342448a6b408c54231febdcd93.jpg\n",
      "./datasets/videos/test/7482_NF1.mp4\n",
      "['7482', 'NF1', 'f000070', 'jpg.rf.2a1d083d5aed1d3bf786b212f94a872c.jpg']\n",
      "7482_NF1 f000070jpg.rf.2a1d083d5aed1d3bf786b212f94a872c.jpg\n",
      "./datasets/videos/test/7482_NF1.mp4\n",
      "['7482', 'NF1', 'f000076', 'jpg.rf.9b9b80e042c824532dd992341115a9fe.jpg']\n",
      "7482_NF1 f000076jpg.rf.9b9b80e042c824532dd992341115a9fe.jpg\n",
      "./datasets/videos/test/7482_NF1.mp4\n",
      "['7482', 'NF1', 'f000078', 'jpg.rf.f7521bc467c77b710b009d45c228e8f0.jpg']\n",
      "7482_NF1 f000078jpg.rf.f7521bc467c77b710b009d45c228e8f0.jpg\n",
      "./datasets/videos/test/7482_NF1.mp4\n",
      "['7482', 'NF1', 'f000088', 'jpg.rf.fa5e009822332473151175678ee9e2b2.jpg']\n",
      "7482_NF1 f000088jpg.rf.fa5e009822332473151175678ee9e2b2.jpg\n",
      "./datasets/videos/test/7482_NF1.mp4\n",
      "['7482', 'NF1', 'f000099', 'jpg.rf.9db05471578362f3e8f53dac2be82790.jpg']\n",
      "7482_NF1 f000099jpg.rf.9db05471578362f3e8f53dac2be82790.jpg\n",
      "./datasets/videos/test/7482_NF1.mp4\n",
      "['7482', 'NF1', 'f000107', 'jpg.rf.9424fcc85423cec986cc2e42e3241d12.jpg']\n",
      "7482_NF1 f000107jpg.rf.9424fcc85423cec986cc2e42e3241d12.jpg\n",
      "./datasets/videos/test/7482_NF1.mp4\n",
      "['7482', 'NF1', 'f000109', 'jpg.rf.58e385e4e5433a1b01620132a148b915.jpg']\n",
      "7482_NF1 f000109jpg.rf.58e385e4e5433a1b01620132a148b915.jpg\n",
      "./datasets/videos/test/7482_NF1.mp4\n",
      "['7482', 'NF1', 'f000119', 'jpg.rf.ff9deddd3aaf162a17dd834c9d6a532a.jpg']\n",
      "7482_NF1 f000119jpg.rf.ff9deddd3aaf162a17dd834c9d6a532a.jpg\n",
      "./datasets/videos/test/7482_NF1.mp4\n",
      "['7482', 'NF1', 'f000126', 'jpg.rf.61f85ff9378c464f2e80f0e9d8ee4751.jpg']\n",
      "7482_NF1 f000126jpg.rf.61f85ff9378c464f2e80f0e9d8ee4751.jpg\n",
      "./datasets/videos/test/7482_NF1.mp4\n",
      "['7482', 'NF1', 'f000127', 'jpg.rf.c996f6162a5578b680a4e5e9933abf79.jpg']\n",
      "7482_NF1 f000127jpg.rf.c996f6162a5578b680a4e5e9933abf79.jpg\n",
      "./datasets/videos/test/7482_NF1.mp4\n",
      "['7482', 'NF1', 'f000148', 'jpg.rf.0b0b1041f3514e0a2ea6f0d3402677f0.jpg']\n",
      "7482_NF1 f000148jpg.rf.0b0b1041f3514e0a2ea6f0d3402677f0.jpg\n",
      "./datasets/videos/test/7482_NF1.mp4\n",
      "['7490', 'F1', 'f000017', 'jpg.rf.622ef4a696df42ab4dcac1d9251aa5d8.jpg']\n",
      "7490_F1 f000017jpg.rf.622ef4a696df42ab4dcac1d9251aa5d8.jpg\n",
      "./datasets/videos/test/7490_F1.mp4\n",
      "Starting a new video for 7490_F1\n",
      "['7490', 'F1', 'f000029', 'jpg.rf.aa03f0661d858cf30974cf971048cbdd.jpg']\n",
      "7490_F1 f000029jpg.rf.aa03f0661d858cf30974cf971048cbdd.jpg\n",
      "./datasets/videos/test/7490_F1.mp4\n",
      "['7490', 'F1', 'f000030', 'jpg.rf.b07ec7e5f67358cb7ce27a75f345295c.jpg']\n",
      "7490_F1 f000030jpg.rf.b07ec7e5f67358cb7ce27a75f345295c.jpg\n",
      "./datasets/videos/test/7490_F1.mp4\n",
      "['7490', 'F2', 'f000123', 'jpg.rf.c39fd0326a1cd716678599e48061a3ad.jpg']\n",
      "7490_F2 f000123jpg.rf.c39fd0326a1cd716678599e48061a3ad.jpg\n",
      "./datasets/videos/test/7490_F2.mp4\n",
      "Starting a new video for 7490_F2\n",
      "['7490', 'F2', 'f000124', 'jpg.rf.96afb913ef69870b6cef8c0659a47a99.jpg']\n",
      "7490_F2 f000124jpg.rf.96afb913ef69870b6cef8c0659a47a99.jpg\n",
      "./datasets/videos/test/7490_F2.mp4\n",
      "['7490', 'F3', 'f000006', 'jpg.rf.431ca6114ec5cb228df6e52069673c1b.jpg']\n",
      "7490_F3 f000006jpg.rf.431ca6114ec5cb228df6e52069673c1b.jpg\n",
      "./datasets/videos/test/7490_F3.mp4\n",
      "Starting a new video for 7490_F3\n",
      "['7490', 'F3', 'f000009', 'jpg.rf.4f0de048001eac4fb54a9fb5cc4f2026.jpg']\n",
      "7490_F3 f000009jpg.rf.4f0de048001eac4fb54a9fb5cc4f2026.jpg\n",
      "./datasets/videos/test/7490_F3.mp4\n",
      "['7490', 'F3', 'f000015', 'jpg.rf.22be9ba86aeb3a34bc1fa3432f4cd4d8.jpg']\n",
      "7490_F3 f000015jpg.rf.22be9ba86aeb3a34bc1fa3432f4cd4d8.jpg\n",
      "./datasets/videos/test/7490_F3.mp4\n",
      "['7490', 'F3', 'f000020', 'jpg.rf.7608cbe8838620abd1e536ed14bee6a1.jpg']\n",
      "7490_F3 f000020jpg.rf.7608cbe8838620abd1e536ed14bee6a1.jpg\n",
      "./datasets/videos/test/7490_F3.mp4\n",
      "['7490', 'F3', 'f000035', 'jpg.rf.64f9299ca3730998d6d5cb5a0462f9df.jpg']\n",
      "7490_F3 f000035jpg.rf.64f9299ca3730998d6d5cb5a0462f9df.jpg\n",
      "./datasets/videos/test/7490_F3.mp4\n",
      "['7490', 'F3', 'f000061', 'jpg.rf.2c062ee6c50b36e91a551309e9c072fb.jpg']\n",
      "7490_F3 f000061jpg.rf.2c062ee6c50b36e91a551309e9c072fb.jpg\n",
      "./datasets/videos/test/7490_F3.mp4\n",
      "['7490', 'F7', 'f000014', 'jpg.rf.5b15031840c8299eae351a3d12da3463.jpg']\n",
      "7490_F7 f000014jpg.rf.5b15031840c8299eae351a3d12da3463.jpg\n",
      "./datasets/videos/test/7490_F7.mp4\n",
      "Starting a new video for 7490_F7\n",
      "['7490', 'F7', 'f000058', 'jpg.rf.47e8edf0d3957a2efa269d23db455509.jpg']\n",
      "7490_F7 f000058jpg.rf.47e8edf0d3957a2efa269d23db455509.jpg\n",
      "./datasets/videos/test/7490_F7.mp4\n",
      "['7490', 'NF2', 'f000001', 'jpg.rf.18c8f88bdbda09d2dbb984619fa7e306.jpg']\n",
      "7490_NF2 f000001jpg.rf.18c8f88bdbda09d2dbb984619fa7e306.jpg\n",
      "./datasets/videos/test/7490_NF2.mp4\n",
      "Starting a new video for 7490_NF2\n",
      "['7490', 'NF2', 'f000015', 'jpg.rf.a26a46ee99bcb68b9fdb9928427efb40.jpg']\n",
      "7490_NF2 f000015jpg.rf.a26a46ee99bcb68b9fdb9928427efb40.jpg\n",
      "./datasets/videos/test/7490_NF2.mp4\n",
      "['7490', 'NF2', 'f000021', 'jpg.rf.bec7d3bd74d1953ce866d5a48f1cd4dc.jpg']\n",
      "7490_NF2 f000021jpg.rf.bec7d3bd74d1953ce866d5a48f1cd4dc.jpg\n",
      "./datasets/videos/test/7490_NF2.mp4\n",
      "['7490', 'NF2', 'f000065', 'jpg.rf.ab12c77668dc4cc4d8175203fa0c7447.jpg']\n",
      "7490_NF2 f000065jpg.rf.ab12c77668dc4cc4d8175203fa0c7447.jpg\n",
      "./datasets/videos/test/7490_NF2.mp4\n",
      "['7585', 'F1', 'f000008', 'jpg.rf.bb3dbe327b0a05dc33dbc2c753f2398e.jpg']\n",
      "7585_F1 f000008jpg.rf.bb3dbe327b0a05dc33dbc2c753f2398e.jpg\n",
      "./datasets/videos/test/7585_F1.mp4\n",
      "Starting a new video for 7585_F1\n",
      "['7585', 'F1', 'f000015', 'jpg.rf.80843f6fd28f56433aa714061b95befd.jpg']\n",
      "7585_F1 f000015jpg.rf.80843f6fd28f56433aa714061b95befd.jpg\n",
      "./datasets/videos/test/7585_F1.mp4\n",
      "['7585', 'F1', 'f000025', 'jpg.rf.a0408bc6bad265af0df7c40a392c0eda.jpg']\n",
      "7585_F1 f000025jpg.rf.a0408bc6bad265af0df7c40a392c0eda.jpg\n",
      "./datasets/videos/test/7585_F1.mp4\n",
      "['7585', 'F1', 'f000080', 'jpg.rf.d3784619c3d1f01eaf50fe288f042685.jpg']\n",
      "7585_F1 f000080jpg.rf.d3784619c3d1f01eaf50fe288f042685.jpg\n",
      "./datasets/videos/test/7585_F1.mp4\n",
      "['7585', 'F1', 'f000083', 'jpg.rf.511fad1000938dd3592bf15c92f275a3.jpg']\n",
      "7585_F1 f000083jpg.rf.511fad1000938dd3592bf15c92f275a3.jpg\n",
      "./datasets/videos/test/7585_F1.mp4\n",
      "['7585', 'F1', 'f000084', 'jpg.rf.94b61908dfaccb3f7088ecc5564f96d3.jpg']\n",
      "7585_F1 f000084jpg.rf.94b61908dfaccb3f7088ecc5564f96d3.jpg\n",
      "./datasets/videos/test/7585_F1.mp4\n",
      "['7585', 'F1', 'f000115', 'jpg.rf.d866e3befd28b1cedbbbbbc330a3fc4c.jpg']\n",
      "7585_F1 f000115jpg.rf.d866e3befd28b1cedbbbbbc330a3fc4c.jpg\n",
      "./datasets/videos/test/7585_F1.mp4\n",
      "['7585', 'F1', 'f000311', 'jpg.rf.e9e5641a04901755917d0740d57e9dc3.jpg']\n",
      "7585_F1 f000311jpg.rf.e9e5641a04901755917d0740d57e9dc3.jpg\n",
      "./datasets/videos/test/7585_F1.mp4\n",
      "['7585', 'F1', 'f000317', 'jpg.rf.38b732c34caf83c73f5bf8c5761005cb.jpg']\n",
      "7585_F1 f000317jpg.rf.38b732c34caf83c73f5bf8c5761005cb.jpg\n",
      "./datasets/videos/test/7585_F1.mp4\n",
      "['7585', 'F1', 'f000346', 'jpg.rf.712db0cc1462237fd18ab13bd161981c.jpg']\n",
      "7585_F1 f000346jpg.rf.712db0cc1462237fd18ab13bd161981c.jpg\n",
      "./datasets/videos/test/7585_F1.mp4\n",
      "['7585', 'F1', 'f000454', 'jpg.rf.990903387df199c5fd710ed262fcf458.jpg']\n",
      "7585_F1 f000454jpg.rf.990903387df199c5fd710ed262fcf458.jpg\n",
      "./datasets/videos/test/7585_F1.mp4\n",
      "['7585', 'NF2', 'f000000', 'jpg.rf.551059df0ed844e414cce2999236339f.jpg']\n",
      "7585_NF2 f000000jpg.rf.551059df0ed844e414cce2999236339f.jpg\n",
      "./datasets/videos/test/7585_NF2.mp4\n",
      "Starting a new video for 7585_NF2\n",
      "['7585', 'NF2', 'f000002', 'jpg.rf.c1f0755cca0519aa943ba931bb0f1781.jpg']\n",
      "7585_NF2 f000002jpg.rf.c1f0755cca0519aa943ba931bb0f1781.jpg\n",
      "./datasets/videos/test/7585_NF2.mp4\n",
      "['7585', 'NF2', 'f000004', 'jpg.rf.6c2d8d8294de4c4bb3ae2c3dc43f7fa8.jpg']\n",
      "7585_NF2 f000004jpg.rf.6c2d8d8294de4c4bb3ae2c3dc43f7fa8.jpg\n",
      "./datasets/videos/test/7585_NF2.mp4\n",
      "['7585', 'NF2', 'f000013', 'jpg.rf.965c5dfe7b19d4de085d7b96f00d19a5.jpg']\n",
      "7585_NF2 f000013jpg.rf.965c5dfe7b19d4de085d7b96f00d19a5.jpg\n",
      "./datasets/videos/test/7585_NF2.mp4\n",
      "['7585', 'NF2', 'f000015', 'jpg.rf.c6bcfe9171da9e975013e50ff3f5e501.jpg']\n",
      "7585_NF2 f000015jpg.rf.c6bcfe9171da9e975013e50ff3f5e501.jpg\n",
      "./datasets/videos/test/7585_NF2.mp4\n",
      "['7585', 'NF2', 'f000021', 'jpg.rf.ba849d7826126433bd8ebbc4eb5b16e3.jpg']\n",
      "7585_NF2 f000021jpg.rf.ba849d7826126433bd8ebbc4eb5b16e3.jpg\n",
      "./datasets/videos/test/7585_NF2.mp4\n",
      "['7585', 'NF2', 'f000032', 'jpg.rf.0cb217e4aea447c6f11d9bde3f93ef26.jpg']\n",
      "7585_NF2 f000032jpg.rf.0cb217e4aea447c6f11d9bde3f93ef26.jpg\n",
      "./datasets/videos/test/7585_NF2.mp4\n",
      "['7585', 'NF2', 'f000036', 'jpg.rf.37d1febf0cb28325bff8315dfe8eafa2.jpg']\n",
      "7585_NF2 f000036jpg.rf.37d1febf0cb28325bff8315dfe8eafa2.jpg\n",
      "./datasets/videos/test/7585_NF2.mp4\n",
      "['7585', 'NF2', 'f001180', 'jpg.rf.d1f0cd55d85bdb9607e543a15ea6d603.jpg']\n",
      "7585_NF2 f001180jpg.rf.d1f0cd55d85bdb9607e543a15ea6d603.jpg\n",
      "./datasets/videos/test/7585_NF2.mp4\n",
      "['7623', 'F1', 'f000111', 'jpg.rf.0dac2248aadbfdf073094bc9b691cbd4.jpg']\n",
      "7623_F1 f000111jpg.rf.0dac2248aadbfdf073094bc9b691cbd4.jpg\n",
      "./datasets/videos/test/7623_F1.mp4\n",
      "Starting a new video for 7623_F1\n",
      "['7623', 'F1', 'f000118', 'jpg.rf.a27eb6936325ac5a6f5a9e21eec5cd35.jpg']\n",
      "7623_F1 f000118jpg.rf.a27eb6936325ac5a6f5a9e21eec5cd35.jpg\n",
      "./datasets/videos/test/7623_F1.mp4\n",
      "['7623', 'F1', 'f000122', 'jpg.rf.506fb209ab5413596194806dc737c2df.jpg']\n",
      "7623_F1 f000122jpg.rf.506fb209ab5413596194806dc737c2df.jpg\n",
      "./datasets/videos/test/7623_F1.mp4\n",
      "['7623', 'F1', 'f000133', 'jpg.rf.e526e34cb77a08d74272dfd6d5a3cc72.jpg']\n",
      "7623_F1 f000133jpg.rf.e526e34cb77a08d74272dfd6d5a3cc72.jpg\n",
      "./datasets/videos/test/7623_F1.mp4\n",
      "['7623', 'F1', 'f000392', 'jpg.rf.a1dc5cb7e3b5822c975cb19eab40f20b.jpg']\n",
      "7623_F1 f000392jpg.rf.a1dc5cb7e3b5822c975cb19eab40f20b.jpg\n",
      "./datasets/videos/test/7623_F1.mp4\n",
      "['7623', 'F2', 'f000007', 'jpg.rf.f74a9150bf003fe0b6606160e26a3e39.jpg']\n",
      "7623_F2 f000007jpg.rf.f74a9150bf003fe0b6606160e26a3e39.jpg\n",
      "./datasets/videos/test/7623_F2.mp4\n",
      "Starting a new video for 7623_F2\n",
      "['7623', 'F2', 'f000036', 'jpg.rf.f0bfe78a60a9d2853e73cce44f8cf558.jpg']\n",
      "7623_F2 f000036jpg.rf.f0bfe78a60a9d2853e73cce44f8cf558.jpg\n",
      "./datasets/videos/test/7623_F2.mp4\n",
      "['7623', 'F2', 'f000054', 'jpg.rf.86e6d4c6ea89d907836feb337b3639f4.jpg']\n",
      "7623_F2 f000054jpg.rf.86e6d4c6ea89d907836feb337b3639f4.jpg\n",
      "./datasets/videos/test/7623_F2.mp4\n",
      "['7623', 'F2', 'f000077', 'jpg.rf.2975a0bb493c264883f5cbe3c93d7b98.jpg']\n",
      "7623_F2 f000077jpg.rf.2975a0bb493c264883f5cbe3c93d7b98.jpg\n",
      "./datasets/videos/test/7623_F2.mp4\n",
      "['7623', 'F2', 'f000081', 'jpg.rf.d0c796128c01403593387504db4348fe.jpg']\n",
      "7623_F2 f000081jpg.rf.d0c796128c01403593387504db4348fe.jpg\n",
      "./datasets/videos/test/7623_F2.mp4\n",
      "['7623', 'F2', 'f000096', 'jpg.rf.e79674b05cd77985a848440fbafb20fb.jpg']\n",
      "7623_F2 f000096jpg.rf.e79674b05cd77985a848440fbafb20fb.jpg\n",
      "./datasets/videos/test/7623_F2.mp4\n",
      "['7623', 'F2', 'f000109', 'jpg.rf.879a05afcbe47549296ff20b70394734.jpg']\n",
      "7623_F2 f000109jpg.rf.879a05afcbe47549296ff20b70394734.jpg\n",
      "./datasets/videos/test/7623_F2.mp4\n",
      "['7623', 'F2', 'f000111', 'jpg.rf.10a98fb833a4448f56f68194dbcccb17.jpg']\n",
      "7623_F2 f000111jpg.rf.10a98fb833a4448f56f68194dbcccb17.jpg\n",
      "./datasets/videos/test/7623_F2.mp4\n",
      "['7623', 'F2', 'f000238', 'jpg.rf.f78075df27992499f95f65dd57308ac2.jpg']\n",
      "7623_F2 f000238jpg.rf.f78075df27992499f95f65dd57308ac2.jpg\n",
      "./datasets/videos/test/7623_F2.mp4\n",
      "['7623', 'F2', 'f000248', 'jpg.rf.69c2587b5e81409d372a9e06932ba051.jpg']\n",
      "7623_F2 f000248jpg.rf.69c2587b5e81409d372a9e06932ba051.jpg\n",
      "./datasets/videos/test/7623_F2.mp4\n",
      "['7623', 'F2', 'f000260', 'jpg.rf.93adb53b14f20f7878fb380f52b79e0b.jpg']\n",
      "7623_F2 f000260jpg.rf.93adb53b14f20f7878fb380f52b79e0b.jpg\n",
      "./datasets/videos/test/7623_F2.mp4\n",
      "['7623', 'F2', 'f000261', 'jpg.rf.baac9a685a39b308e8c96f2e87b3569b.jpg']\n",
      "7623_F2 f000261jpg.rf.baac9a685a39b308e8c96f2e87b3569b.jpg\n",
      "./datasets/videos/test/7623_F2.mp4\n",
      "['7623', 'F2', 'f000262', 'jpg.rf.57a8ada136918128b74e3d955948131a.jpg']\n",
      "7623_F2 f000262jpg.rf.57a8ada136918128b74e3d955948131a.jpg\n",
      "./datasets/videos/test/7623_F2.mp4\n",
      "['7623', 'F2', 'f000272', 'jpg.rf.5ad3eab5fd01c03073ddee8010ee6297.jpg']\n",
      "7623_F2 f000272jpg.rf.5ad3eab5fd01c03073ddee8010ee6297.jpg\n",
      "./datasets/videos/test/7623_F2.mp4\n",
      "['7623', 'F2', 'f000358', 'jpg.rf.ffb7ae20db842f48a8650e5af938001f.jpg']\n",
      "7623_F2 f000358jpg.rf.ffb7ae20db842f48a8650e5af938001f.jpg\n",
      "./datasets/videos/test/7623_F2.mp4\n",
      "['7623', 'F2', 'f000360', 'jpg.rf.b0d6f19e54ee1649d5c273ad6a7cb2c0.jpg']\n",
      "7623_F2 f000360jpg.rf.b0d6f19e54ee1649d5c273ad6a7cb2c0.jpg\n",
      "./datasets/videos/test/7623_F2.mp4\n",
      "['7623', 'F2', 'f000405', 'jpg.rf.895b13669ebaefa1d8a6537de94c3c57.jpg']\n",
      "7623_F2 f000405jpg.rf.895b13669ebaefa1d8a6537de94c3c57.jpg\n",
      "./datasets/videos/test/7623_F2.mp4\n",
      "['7623', 'F2', 'f000409', 'jpg.rf.b1ac2db25140de1541bb66edfde3204d.jpg']\n",
      "7623_F2 f000409jpg.rf.b1ac2db25140de1541bb66edfde3204d.jpg\n",
      "./datasets/videos/test/7623_F2.mp4\n",
      "['7623', 'NF1', 'f000002', 'jpg.rf.1e5a53d5ab45ce9a0cb1eae284bcfb58.jpg']\n",
      "7623_NF1 f000002jpg.rf.1e5a53d5ab45ce9a0cb1eae284bcfb58.jpg\n",
      "./datasets/videos/test/7623_NF1.mp4\n",
      "Starting a new video for 7623_NF1\n",
      "['7623', 'NF1', 'f000006', 'jpg.rf.2d1b18fe32f6190c91a88896dfbb700f.jpg']\n",
      "7623_NF1 f000006jpg.rf.2d1b18fe32f6190c91a88896dfbb700f.jpg\n",
      "./datasets/videos/test/7623_NF1.mp4\n",
      "['7623', 'NF1', 'f000017', 'jpg.rf.8a9115fde1e7e18023fc2ab1863eb69f.jpg']\n",
      "7623_NF1 f000017jpg.rf.8a9115fde1e7e18023fc2ab1863eb69f.jpg\n",
      "./datasets/videos/test/7623_NF1.mp4\n",
      "['7623', 'NF1', 'f000022', 'jpg.rf.a84aafed9ccc4bc2503078810d3b0b78.jpg']\n",
      "7623_NF1 f000022jpg.rf.a84aafed9ccc4bc2503078810d3b0b78.jpg\n",
      "./datasets/videos/test/7623_NF1.mp4\n",
      "['7623', 'NF1', 'f000033', 'jpg.rf.f12564ac87df3a4347f3a5322843455b.jpg']\n",
      "7623_NF1 f000033jpg.rf.f12564ac87df3a4347f3a5322843455b.jpg\n",
      "./datasets/videos/test/7623_NF1.mp4\n",
      "['7623', 'NF1', 'f000074', 'jpg.rf.41f529009b8e9e58f209b14cfef0b136.jpg']\n",
      "7623_NF1 f000074jpg.rf.41f529009b8e9e58f209b14cfef0b136.jpg\n",
      "./datasets/videos/test/7623_NF1.mp4\n",
      "['7623', 'NF1', 'f000079', 'jpg.rf.cefedd78794e8def7c280b6f848bdc9d.jpg']\n",
      "7623_NF1 f000079jpg.rf.cefedd78794e8def7c280b6f848bdc9d.jpg\n",
      "./datasets/videos/test/7623_NF1.mp4\n",
      "['7623', 'NF1', 'f000080', 'jpg.rf.64d2a73626ad4941a9f8972394e60aa3.jpg']\n",
      "7623_NF1 f000080jpg.rf.64d2a73626ad4941a9f8972394e60aa3.jpg\n",
      "./datasets/videos/test/7623_NF1.mp4\n",
      "['7623', 'NF1', 'f000082', 'jpg.rf.f20539624b4db9578f95f6c72613c838.jpg']\n",
      "7623_NF1 f000082jpg.rf.f20539624b4db9578f95f6c72613c838.jpg\n",
      "./datasets/videos/test/7623_NF1.mp4\n",
      "['7623', 'NF1', 'f000086', 'jpg.rf.147895b3c1af7db576378c9f0d797922.jpg']\n",
      "7623_NF1 f000086jpg.rf.147895b3c1af7db576378c9f0d797922.jpg\n",
      "./datasets/videos/test/7623_NF1.mp4\n",
      "['7623', 'NF1', 'f000096', 'jpg.rf.582761f9bc99d1860eb09e3933a9d6a7.jpg']\n",
      "7623_NF1 f000096jpg.rf.582761f9bc99d1860eb09e3933a9d6a7.jpg\n",
      "./datasets/videos/test/7623_NF1.mp4\n",
      "['7623', 'NF1', 'f000101', 'jpg.rf.4f11610e1c5fc8ae4a339301beeb1d74.jpg']\n",
      "7623_NF1 f000101jpg.rf.4f11610e1c5fc8ae4a339301beeb1d74.jpg\n",
      "./datasets/videos/test/7623_NF1.mp4\n",
      "['9852', 'Acanthopagrus', 'palmaris', 'f000000', 'jpg.rf.1fcc6962db43a3b9e177177d6c1f5864.jpg']\n",
      "9852_Acanthopagrus_palmaris f000000jpg.rf.1fcc6962db43a3b9e177177d6c1f5864.jpg\n",
      "./datasets/videos/test/9852_Acanthopagrus_palmaris.mp4\n",
      "Starting a new video for 9852_Acanthopagrus_palmaris\n",
      "['9852', 'Acanthopagrus', 'palmaris', 'f000010', 'jpg.rf.fa30b488c1a13599041a9344deba69e1.jpg']\n",
      "9852_Acanthopagrus_palmaris f000010jpg.rf.fa30b488c1a13599041a9344deba69e1.jpg\n",
      "./datasets/videos/test/9852_Acanthopagrus_palmaris.mp4\n",
      "['9852', 'Acanthopagrus', 'palmaris', 'f000018', 'jpg.rf.9d0d5327b155b0840954bf70968883dc.jpg']\n",
      "9852_Acanthopagrus_palmaris f000018jpg.rf.9d0d5327b155b0840954bf70968883dc.jpg\n",
      "./datasets/videos/test/9852_Acanthopagrus_palmaris.mp4\n",
      "['9852', 'Acanthopagrus', 'palmaris', 'f000030', 'jpg.rf.4f0c58c66d5cf053daf32fe0d6315938.jpg']\n",
      "9852_Acanthopagrus_palmaris f000030jpg.rf.4f0c58c66d5cf053daf32fe0d6315938.jpg\n",
      "./datasets/videos/test/9852_Acanthopagrus_palmaris.mp4\n",
      "['9852', 'Acanthopagrus', 'palmaris', 'f000114', 'jpg.rf.910371cc3492bc37c4bcaf5fd3604afa.jpg']\n",
      "9852_Acanthopagrus_palmaris f000114jpg.rf.910371cc3492bc37c4bcaf5fd3604afa.jpg\n",
      "./datasets/videos/test/9852_Acanthopagrus_palmaris.mp4\n",
      "['9852', 'Acanthopagrus', 'palmaris', 'f000116', 'jpg.rf.b684dd67743cfe920fe07032d7e7357c.jpg']\n",
      "9852_Acanthopagrus_palmaris f000116jpg.rf.b684dd67743cfe920fe07032d7e7357c.jpg\n",
      "./datasets/videos/test/9852_Acanthopagrus_palmaris.mp4\n",
      "['9852', 'Acanthopagrus', 'palmaris', 'f000120', 'jpg.rf.06a6ee78581a3c13baf9267f80b596e1.jpg']\n",
      "9852_Acanthopagrus_palmaris f000120jpg.rf.06a6ee78581a3c13baf9267f80b596e1.jpg\n",
      "./datasets/videos/test/9852_Acanthopagrus_palmaris.mp4\n",
      "['9852', 'Acanthopagrus', 'palmaris', 'f000134', 'jpg.rf.5cda0ca4fc9de05bb1cfd789186e203a.jpg']\n",
      "9852_Acanthopagrus_palmaris f000134jpg.rf.5cda0ca4fc9de05bb1cfd789186e203a.jpg\n",
      "./datasets/videos/test/9852_Acanthopagrus_palmaris.mp4\n",
      "['9852', 'Lutjanus', 'russellii', 'EJP', 'f000000', 'jpg.rf.6e5f20b8326e5d9366332cab0a23e876.jpg']\n",
      "9852_Lutjanus_russellii_EJP f000000jpg.rf.6e5f20b8326e5d9366332cab0a23e876.jpg\n",
      "./datasets/videos/test/9852_Lutjanus_russellii_EJP.mp4\n",
      "Starting a new video for 9852_Lutjanus_russellii_EJP\n",
      "['9852', 'Lutjanus', 'russellii', 'EJP', 'f000009', 'jpg.rf.b1052d2a569a4b5f02766559be49cec0.jpg']\n",
      "9852_Lutjanus_russellii_EJP f000009jpg.rf.b1052d2a569a4b5f02766559be49cec0.jpg\n",
      "./datasets/videos/test/9852_Lutjanus_russellii_EJP.mp4\n",
      "['9852', 'no', 'fish', '2', 'f000012', 'jpg.rf.bd2fa48bbfa0db117911aa15e34305e7.jpg']\n",
      "9852_no_fish_2 f000012jpg.rf.bd2fa48bbfa0db117911aa15e34305e7.jpg\n",
      "./datasets/videos/test/9852_no_fish_2.mp4\n",
      "Starting a new video for 9852_no_fish_2\n",
      "['9852', 'no', 'fish', '2', 'f000018', 'jpg.rf.b14291febf9e234493ef7abbe8a61ab1.jpg']\n",
      "9852_no_fish_2 f000018jpg.rf.b14291febf9e234493ef7abbe8a61ab1.jpg\n",
      "./datasets/videos/test/9852_no_fish_2.mp4\n",
      "['9852', 'no', 'fish', '2', 'f000027', 'jpg.rf.a2ab744f0e0926c99347395376015772.jpg']\n",
      "9852_no_fish_2 f000027jpg.rf.a2ab744f0e0926c99347395376015772.jpg\n",
      "./datasets/videos/test/9852_no_fish_2.mp4\n",
      "['9852', 'no', 'fish', '2', 'f000030', 'jpg.rf.f67513699855e6a0c2c0ce722750b514.jpg']\n",
      "9852_no_fish_2 f000030jpg.rf.f67513699855e6a0c2c0ce722750b514.jpg\n",
      "./datasets/videos/test/9852_no_fish_2.mp4\n",
      "['9852', 'no', 'fish', '2', 'f000045', 'jpg.rf.8bf9f458c69ea6285ad1657c12f17d65.jpg']\n",
      "9852_no_fish_2 f000045jpg.rf.8bf9f458c69ea6285ad1657c12f17d65.jpg\n",
      "./datasets/videos/test/9852_no_fish_2.mp4\n",
      "['9862', 'Acanthopagrus', 'palmaris', 'f000004', 'jpg.rf.67afffa0db74b2320b8a404e5b45868a.jpg']\n",
      "9862_Acanthopagrus_palmaris f000004jpg.rf.67afffa0db74b2320b8a404e5b45868a.jpg\n",
      "./datasets/videos/test/9862_Acanthopagrus_palmaris.mp4\n",
      "Starting a new video for 9862_Acanthopagrus_palmaris\n",
      "['9862', 'Acanthopagrus', 'palmaris', 'f000012', 'jpg.rf.8be97835d5bf1c943853597842c0dba0.jpg']\n",
      "9862_Acanthopagrus_palmaris f000012jpg.rf.8be97835d5bf1c943853597842c0dba0.jpg\n",
      "./datasets/videos/test/9862_Acanthopagrus_palmaris.mp4\n",
      "['9862', 'Acanthopagrus', 'palmaris', 'f000015', 'jpg.rf.96d91b8f27d061fbacddde47627cad0d.jpg']\n",
      "9862_Acanthopagrus_palmaris f000015jpg.rf.96d91b8f27d061fbacddde47627cad0d.jpg\n",
      "./datasets/videos/test/9862_Acanthopagrus_palmaris.mp4\n",
      "['9862', 'Acanthopagrus', 'palmaris', 'f000046', 'jpg.rf.88ce6ce2e28190023e53facaabe83c3e.jpg']\n",
      "9862_Acanthopagrus_palmaris f000046jpg.rf.88ce6ce2e28190023e53facaabe83c3e.jpg\n",
      "./datasets/videos/test/9862_Acanthopagrus_palmaris.mp4\n",
      "['9862', 'Acanthopagrus', 'palmaris', 'f000055', 'jpg.rf.48fb5a313d6a00404999a2dff1f17dc3.jpg']\n",
      "9862_Acanthopagrus_palmaris f000055jpg.rf.48fb5a313d6a00404999a2dff1f17dc3.jpg\n",
      "./datasets/videos/test/9862_Acanthopagrus_palmaris.mp4\n",
      "['9862', 'Acanthopagrus', 'palmaris', 'f000072', 'jpg.rf.5eb8d6c585d4474c18f62b934f090b97.jpg']\n",
      "9862_Acanthopagrus_palmaris f000072jpg.rf.5eb8d6c585d4474c18f62b934f090b97.jpg\n",
      "./datasets/videos/test/9862_Acanthopagrus_palmaris.mp4\n",
      "['9862', 'Acanthopagrus', 'palmaris', 'f000077', 'jpg.rf.4e4c5548392b553760c6bb2618515489.jpg']\n",
      "9862_Acanthopagrus_palmaris f000077jpg.rf.4e4c5548392b553760c6bb2618515489.jpg\n",
      "./datasets/videos/test/9862_Acanthopagrus_palmaris.mp4\n",
      "['9862', 'Acanthopagrus', 'palmaris', 'f000105', 'jpg.rf.4f1b8d362ecc192ff91bbd6aa0eea4fe.jpg']\n",
      "9862_Acanthopagrus_palmaris f000105jpg.rf.4f1b8d362ecc192ff91bbd6aa0eea4fe.jpg\n",
      "./datasets/videos/test/9862_Acanthopagrus_palmaris.mp4\n",
      "['9862', 'Acanthopagrus', 'palmaris', 'f000109', 'jpg.rf.48ab7116c404db2d384bff745d22a5b9.jpg']\n",
      "9862_Acanthopagrus_palmaris f000109jpg.rf.48ab7116c404db2d384bff745d22a5b9.jpg\n",
      "./datasets/videos/test/9862_Acanthopagrus_palmaris.mp4\n",
      "['9862', 'no', 'fish', 'f000004', 'jpg.rf.a010f123f9c39a07def1bbcf6a0d1f30.jpg']\n",
      "9862_no_fish f000004jpg.rf.a010f123f9c39a07def1bbcf6a0d1f30.jpg\n",
      "./datasets/videos/test/9862_no_fish.mp4\n",
      "Starting a new video for 9862_no_fish\n",
      "['9862', 'no', 'fish', 'f000008', 'jpg.rf.e76c39fd2818661c0f323b2f4cc2d3a3.jpg']\n",
      "9862_no_fish f000008jpg.rf.e76c39fd2818661c0f323b2f4cc2d3a3.jpg\n",
      "./datasets/videos/test/9862_no_fish.mp4\n",
      "['9862', 'no', 'fish', 'f000032', 'jpg.rf.65f8db40aaf63d1d00a39d13d88356fd.jpg']\n",
      "9862_no_fish f000032jpg.rf.65f8db40aaf63d1d00a39d13d88356fd.jpg\n",
      "./datasets/videos/test/9862_no_fish.mp4\n",
      "['9862', 'no', 'fish', 'f000043', 'jpg.rf.c9f85cccc9e2cd64b6730a6559157dff.jpg']\n",
      "9862_no_fish f000043jpg.rf.c9f85cccc9e2cd64b6730a6559157dff.jpg\n",
      "./datasets/videos/test/9862_no_fish.mp4\n",
      "['9862', 'no', 'fish', 'f000047', 'jpg.rf.1109126e50ffe75787dfc933d146d682.jpg']\n",
      "9862_no_fish f000047jpg.rf.1109126e50ffe75787dfc933d146d682.jpg\n",
      "./datasets/videos/test/9862_no_fish.mp4\n",
      "['9866', 'acanthopagrus', 'and', 'caranx', 'f000031', 'jpg.rf.f39ad2c2efe5213e85e51836a63789dc.jpg']\n",
      "9866_acanthopagrus_and_caranx f000031jpg.rf.f39ad2c2efe5213e85e51836a63789dc.jpg\n",
      "./datasets/videos/test/9866_acanthopagrus_and_caranx.mp4\n",
      "Starting a new video for 9866_acanthopagrus_and_caranx\n",
      "['9866', 'acanthopagrus', 'and', 'caranx', 'f000057', 'jpg.rf.a1b5a7a536f89b950f8d0d0705d0431d.jpg']\n",
      "9866_acanthopagrus_and_caranx f000057jpg.rf.a1b5a7a536f89b950f8d0d0705d0431d.jpg\n",
      "./datasets/videos/test/9866_acanthopagrus_and_caranx.mp4\n",
      "['9866', 'acanthopagrus', 'and', 'caranx', 'f000061', 'jpg.rf.632234eaebc5c5221d6d1be2575d3bad.jpg']\n",
      "9866_acanthopagrus_and_caranx f000061jpg.rf.632234eaebc5c5221d6d1be2575d3bad.jpg\n",
      "./datasets/videos/test/9866_acanthopagrus_and_caranx.mp4\n",
      "['9866', 'acanthopagrus', 'and', 'caranx', 'f000070', 'jpg.rf.d4b0ac89c4c414839d7c51ed8cd0db4c.jpg']\n",
      "9866_acanthopagrus_and_caranx f000070jpg.rf.d4b0ac89c4c414839d7c51ed8cd0db4c.jpg\n",
      "./datasets/videos/test/9866_acanthopagrus_and_caranx.mp4\n",
      "['9866', 'acanthopagrus', 'and', 'caranx', 'f000073', 'jpg.rf.947e40d986a300b124fc4c9c732644ed.jpg']\n",
      "9866_acanthopagrus_and_caranx f000073jpg.rf.947e40d986a300b124fc4c9c732644ed.jpg\n",
      "./datasets/videos/test/9866_acanthopagrus_and_caranx.mp4\n",
      "['9866', 'acanthopagrus', 'and', 'caranx', 'f000075', 'jpg.rf.c3ec42a7e1cd8a8c7af3463add8709ed.jpg']\n",
      "9866_acanthopagrus_and_caranx f000075jpg.rf.c3ec42a7e1cd8a8c7af3463add8709ed.jpg\n",
      "./datasets/videos/test/9866_acanthopagrus_and_caranx.mp4\n",
      "['9866', 'acanthopagrus', 'and', 'caranx', 'f000099', 'jpg.rf.a93b7904134e964d5da63cdf21ea790d.jpg']\n",
      "9866_acanthopagrus_and_caranx f000099jpg.rf.a93b7904134e964d5da63cdf21ea790d.jpg\n",
      "./datasets/videos/test/9866_acanthopagrus_and_caranx.mp4\n",
      "['9866', 'acanthopagrus', 'and', 'caranx', 'f000104', 'jpg.rf.4121c2af6a348d46c520e6d59a60a2b7.jpg']\n",
      "9866_acanthopagrus_and_caranx f000104jpg.rf.4121c2af6a348d46c520e6d59a60a2b7.jpg\n",
      "./datasets/videos/test/9866_acanthopagrus_and_caranx.mp4\n",
      "['9866', 'acanthopagrus', 'and', 'caranx', 'f000105', 'jpg.rf.84246846a623f48270b5d88edadc09ec.jpg']\n",
      "9866_acanthopagrus_and_caranx f000105jpg.rf.84246846a623f48270b5d88edadc09ec.jpg\n",
      "./datasets/videos/test/9866_acanthopagrus_and_caranx.mp4\n",
      "['9866', 'acanthopagrus', 'and', 'caranx', 'f000106', 'jpg.rf.21309ac9904ecccab55f74c86260c408.jpg']\n",
      "9866_acanthopagrus_and_caranx f000106jpg.rf.21309ac9904ecccab55f74c86260c408.jpg\n",
      "./datasets/videos/test/9866_acanthopagrus_and_caranx.mp4\n",
      "['9866', 'acanthopagrus', 'and', 'caranx', 'f000119', 'jpg.rf.f8a68addf3c0e586752e1f9d3292a40f.jpg']\n",
      "9866_acanthopagrus_and_caranx f000119jpg.rf.f8a68addf3c0e586752e1f9d3292a40f.jpg\n",
      "./datasets/videos/test/9866_acanthopagrus_and_caranx.mp4\n",
      "['9866', 'acanthopagrus', 'and', 'caranx', 'f000133', 'jpg.rf.7c0cd61b337e8cd0d749bf8001ca4afc.jpg']\n",
      "9866_acanthopagrus_and_caranx f000133jpg.rf.7c0cd61b337e8cd0d749bf8001ca4afc.jpg\n",
      "./datasets/videos/test/9866_acanthopagrus_and_caranx.mp4\n",
      "['9866', 'acanthopagrus', 'and', 'caranx', 'f000134', 'jpg.rf.12807b4899289cb7fc67a4be7afd947c.jpg']\n",
      "9866_acanthopagrus_and_caranx f000134jpg.rf.12807b4899289cb7fc67a4be7afd947c.jpg\n",
      "./datasets/videos/test/9866_acanthopagrus_and_caranx.mp4\n",
      "['9866', 'acanthopagrus', 'and', 'caranx', 'f000182', 'jpg.rf.2b201ef3ebdfe87a5c3bf5362a87315d.jpg']\n",
      "9866_acanthopagrus_and_caranx f000182jpg.rf.2b201ef3ebdfe87a5c3bf5362a87315d.jpg\n",
      "./datasets/videos/test/9866_acanthopagrus_and_caranx.mp4\n",
      "['9866', 'acanthopagrus', 'and', 'caranx', 'f000184', 'jpg.rf.090c7d06dcdfe5f73a4f80ec25bfa1ff.jpg']\n",
      "9866_acanthopagrus_and_caranx f000184jpg.rf.090c7d06dcdfe5f73a4f80ec25bfa1ff.jpg\n",
      "./datasets/videos/test/9866_acanthopagrus_and_caranx.mp4\n",
      "['9866', 'acanthopagrus', 'and', 'caranx', 'f000187', 'jpg.rf.e81f7de7650e6895bf6a2bdf35bea54b.jpg']\n",
      "9866_acanthopagrus_and_caranx f000187jpg.rf.e81f7de7650e6895bf6a2bdf35bea54b.jpg\n",
      "./datasets/videos/test/9866_acanthopagrus_and_caranx.mp4\n",
      "['9866', 'acanthopagrus', 'and', 'caranx', 'f000307', 'jpg.rf.b44e0fe216d9dccb12d99b39b4937c84.jpg']\n",
      "9866_acanthopagrus_and_caranx f000307jpg.rf.b44e0fe216d9dccb12d99b39b4937c84.jpg\n",
      "./datasets/videos/test/9866_acanthopagrus_and_caranx.mp4\n",
      "['9866', 'acanthopagrus', 'palmaris', 'f000043', 'jpg.rf.3e055dec40dae46363f3e9e24e18449a.jpg']\n",
      "9866_acanthopagrus_palmaris f000043jpg.rf.3e055dec40dae46363f3e9e24e18449a.jpg\n",
      "./datasets/videos/test/9866_acanthopagrus_palmaris.mp4\n",
      "Starting a new video for 9866_acanthopagrus_palmaris\n",
      "['9866', 'acanthopagrus', 'palmaris', 'f000092', 'jpg.rf.76a8371d0070c9289571dbee63180ab6.jpg']\n",
      "9866_acanthopagrus_palmaris f000092jpg.rf.76a8371d0070c9289571dbee63180ab6.jpg\n",
      "./datasets/videos/test/9866_acanthopagrus_palmaris.mp4\n",
      "['9866', 'acanthopagrus', 'palmaris', 'f000100', 'jpg.rf.4ee5ad321f295d473f9b33e19d2f738a.jpg']\n",
      "9866_acanthopagrus_palmaris f000100jpg.rf.4ee5ad321f295d473f9b33e19d2f738a.jpg\n",
      "./datasets/videos/test/9866_acanthopagrus_palmaris.mp4\n",
      "['9866', 'acanthopagrus', 'palmaris', 'f000178', 'jpg.rf.aef8bfc81e978f6cd9cb702b31dfe130.jpg']\n",
      "9866_acanthopagrus_palmaris f000178jpg.rf.aef8bfc81e978f6cd9cb702b31dfe130.jpg\n",
      "./datasets/videos/test/9866_acanthopagrus_palmaris.mp4\n",
      "['9866', 'acanthopagrus', 'palmaris', 'f000189', 'jpg.rf.380b2e7b2942b8f1b0bedcc436591a31.jpg']\n",
      "9866_acanthopagrus_palmaris f000189jpg.rf.380b2e7b2942b8f1b0bedcc436591a31.jpg\n",
      "./datasets/videos/test/9866_acanthopagrus_palmaris.mp4\n",
      "['9866', 'acanthopagrus', 'palmaris', 'f000190', 'jpg.rf.c28bb891b60ef41f68716dbd29e6a292.jpg']\n",
      "9866_acanthopagrus_palmaris f000190jpg.rf.c28bb891b60ef41f68716dbd29e6a292.jpg\n",
      "./datasets/videos/test/9866_acanthopagrus_palmaris.mp4\n",
      "['9866', 'acanthopagrus', 'palmaris', 'f000236', 'jpg.rf.bc7b60a0a1d458c79e79beecae6ccb51.jpg']\n",
      "9866_acanthopagrus_palmaris f000236jpg.rf.bc7b60a0a1d458c79e79beecae6ccb51.jpg\n",
      "./datasets/videos/test/9866_acanthopagrus_palmaris.mp4\n",
      "['9866', 'acanthopagrus', 'palmaris', 'f000240', 'jpg.rf.98aba92d09363f2f6956ddba40c719e3.jpg']\n",
      "9866_acanthopagrus_palmaris f000240jpg.rf.98aba92d09363f2f6956ddba40c719e3.jpg\n",
      "./datasets/videos/test/9866_acanthopagrus_palmaris.mp4\n",
      "['9866', 'acanthopagrus', 'palmaris', 'f000262', 'jpg.rf.9c1faa25c74488529b783cb3f60eb341.jpg']\n",
      "9866_acanthopagrus_palmaris f000262jpg.rf.9c1faa25c74488529b783cb3f60eb341.jpg\n",
      "./datasets/videos/test/9866_acanthopagrus_palmaris.mp4\n",
      "['9866', 'acanthopagrus', 'palmaris', 'f000264', 'jpg.rf.a30eaa6cc25c9548fa20693a66eef1e6.jpg']\n",
      "9866_acanthopagrus_palmaris f000264jpg.rf.a30eaa6cc25c9548fa20693a66eef1e6.jpg\n",
      "./datasets/videos/test/9866_acanthopagrus_palmaris.mp4\n",
      "['9866', 'acanthopagrus', 'palmaris', 'f000275', 'jpg.rf.12cfdd106ed7664f7253c5475e4331e3.jpg']\n",
      "9866_acanthopagrus_palmaris f000275jpg.rf.12cfdd106ed7664f7253c5475e4331e3.jpg\n",
      "./datasets/videos/test/9866_acanthopagrus_palmaris.mp4\n",
      "['9866', 'acanthopagrus', 'palmaris', 'f000290', 'jpg.rf.337c6ee1b3651b89055d7521c9359a86.jpg']\n",
      "9866_acanthopagrus_palmaris f000290jpg.rf.337c6ee1b3651b89055d7521c9359a86.jpg\n",
      "./datasets/videos/test/9866_acanthopagrus_palmaris.mp4\n",
      "['9866', 'acanthopagrus', 'palmaris', 'f000296', 'jpg.rf.1857ea366f27fe0cc96ea46ca3ee07a4.jpg']\n",
      "9866_acanthopagrus_palmaris f000296jpg.rf.1857ea366f27fe0cc96ea46ca3ee07a4.jpg\n",
      "./datasets/videos/test/9866_acanthopagrus_palmaris.mp4\n",
      "['9866', 'acanthopagrus', 'palmaris', 'f000299', 'jpg.rf.67f62135ef22cac1a9819f10dea6254e.jpg']\n",
      "9866_acanthopagrus_palmaris f000299jpg.rf.67f62135ef22cac1a9819f10dea6254e.jpg\n",
      "./datasets/videos/test/9866_acanthopagrus_palmaris.mp4\n",
      "['9866', 'acanthopagrus', 'palmaris', 'f000302', 'jpg.rf.e5b92435b971421eabf1c73c0817a0da.jpg']\n",
      "9866_acanthopagrus_palmaris f000302jpg.rf.e5b92435b971421eabf1c73c0817a0da.jpg\n",
      "./datasets/videos/test/9866_acanthopagrus_palmaris.mp4\n",
      "['9866', 'acanthopagrus', 'palmaris', 'f000355', 'jpg.rf.8aa060d4618aa2d3535b498aa096f295.jpg']\n",
      "9866_acanthopagrus_palmaris f000355jpg.rf.8aa060d4618aa2d3535b498aa096f295.jpg\n",
      "./datasets/videos/test/9866_acanthopagrus_palmaris.mp4\n",
      "['9866', 'acanthopagrus', 'palmaris', 'f000359', 'jpg.rf.64ba282858abf933950c4b1a2492a84a.jpg']\n",
      "9866_acanthopagrus_palmaris f000359jpg.rf.64ba282858abf933950c4b1a2492a84a.jpg\n",
      "./datasets/videos/test/9866_acanthopagrus_palmaris.mp4\n",
      "['9866', 'acanthopagrus', 'palmaris', 'f000360', 'jpg.rf.a9a8ad4b56a62d46740dc98a5f26d8a0.jpg']\n",
      "9866_acanthopagrus_palmaris f000360jpg.rf.a9a8ad4b56a62d46740dc98a5f26d8a0.jpg\n",
      "./datasets/videos/test/9866_acanthopagrus_palmaris.mp4\n",
      "['9866', 'acanthopagrus', 'palmaris', 'f000362', 'jpg.rf.749fbf387135b85a9be9d3417a72342d.jpg']\n",
      "9866_acanthopagrus_palmaris f000362jpg.rf.749fbf387135b85a9be9d3417a72342d.jpg\n",
      "./datasets/videos/test/9866_acanthopagrus_palmaris.mp4\n",
      "['9866', 'acanthopagrus', 'palmaris', 'f000364', 'jpg.rf.4fb1354c5c2eada80a500d4b08025487.jpg']\n",
      "9866_acanthopagrus_palmaris f000364jpg.rf.4fb1354c5c2eada80a500d4b08025487.jpg\n",
      "./datasets/videos/test/9866_acanthopagrus_palmaris.mp4\n",
      "['9866', 'acanthopagrus', 'palmaris', 'f000370', 'jpg.rf.3f74972fea03772652d6c6ef5859381d.jpg']\n",
      "9866_acanthopagrus_palmaris f000370jpg.rf.3f74972fea03772652d6c6ef5859381d.jpg\n",
      "./datasets/videos/test/9866_acanthopagrus_palmaris.mp4\n",
      "['9866', 'acanthopagrus', 'palmaris', 'f000419', 'jpg.rf.f36ccabbb44e9daaea6e00aa8e29e059.jpg']\n",
      "9866_acanthopagrus_palmaris f000419jpg.rf.f36ccabbb44e9daaea6e00aa8e29e059.jpg\n",
      "./datasets/videos/test/9866_acanthopagrus_palmaris.mp4\n",
      "['9866', 'acanthopagrus', 'palmaris', 'f000436', 'jpg.rf.453623282b87884a9aa7d0d1ab78f8f2.jpg']\n",
      "9866_acanthopagrus_palmaris f000436jpg.rf.453623282b87884a9aa7d0d1ab78f8f2.jpg\n",
      "./datasets/videos/test/9866_acanthopagrus_palmaris.mp4\n",
      "['9866', 'no', 'fish', 'f000003', 'jpg.rf.83cd558bf871ae33119c923557834409.jpg']\n",
      "9866_no_fish f000003jpg.rf.83cd558bf871ae33119c923557834409.jpg\n",
      "./datasets/videos/test/9866_no_fish.mp4\n",
      "Starting a new video for 9866_no_fish\n",
      "['9866', 'no', 'fish', 'f000006', 'jpg.rf.8de4c0033ad8a4a8a7755aeea304ec17.jpg']\n",
      "9866_no_fish f000006jpg.rf.8de4c0033ad8a4a8a7755aeea304ec17.jpg\n",
      "./datasets/videos/test/9866_no_fish.mp4\n",
      "['9866', 'no', 'fish', 'f000009', 'jpg.rf.1b691c7ed3043cedc5f1eb3e4f4e7b21.jpg']\n",
      "9866_no_fish f000009jpg.rf.1b691c7ed3043cedc5f1eb3e4f4e7b21.jpg\n",
      "./datasets/videos/test/9866_no_fish.mp4\n",
      "['9866', 'no', 'fish', 'f000011', 'jpg.rf.511c2cb488fcb7734b09040c267b0be3.jpg']\n",
      "9866_no_fish f000011jpg.rf.511c2cb488fcb7734b09040c267b0be3.jpg\n",
      "./datasets/videos/test/9866_no_fish.mp4\n",
      "['9866', 'no', 'fish', 'f000016', 'jpg.rf.7640e1c5f77af38583667966ee5ff1a2.jpg']\n",
      "9866_no_fish f000016jpg.rf.7640e1c5f77af38583667966ee5ff1a2.jpg\n",
      "./datasets/videos/test/9866_no_fish.mp4\n",
      "['9866', 'no', 'fish', 'f000051', 'jpg.rf.52d4a37c1b5908d526ebd3ad1d8ee8c2.jpg']\n",
      "9866_no_fish f000051jpg.rf.52d4a37c1b5908d526ebd3ad1d8ee8c2.jpg\n",
      "./datasets/videos/test/9866_no_fish.mp4\n",
      "['9866', 'no', 'fish', 'f000053', 'jpg.rf.02e8506493913a1de593ab7b91c9c815.jpg']\n",
      "9866_no_fish f000053jpg.rf.02e8506493913a1de593ab7b91c9c815.jpg\n",
      "./datasets/videos/test/9866_no_fish.mp4\n",
      "['9866', 'no', 'fish', 'f000054', 'jpg.rf.8d211c0e887e41ba0a85333a0af7db7b.jpg']\n",
      "9866_no_fish f000054jpg.rf.8d211c0e887e41ba0a85333a0af7db7b.jpg\n",
      "./datasets/videos/test/9866_no_fish.mp4\n",
      "['9866', 'no', 'fish', 'f000057', 'jpg.rf.1110bf4d57371ec0ee4e70dc447ab7b3.jpg']\n",
      "9866_no_fish f000057jpg.rf.1110bf4d57371ec0ee4e70dc447ab7b3.jpg\n",
      "./datasets/videos/test/9866_no_fish.mp4\n",
      "['9866', 'no', 'fish', 'f000065', 'jpg.rf.cfe74fd3d1b7357d1395ab45f7f2499c.jpg']\n",
      "9866_no_fish f000065jpg.rf.cfe74fd3d1b7357d1395ab45f7f2499c.jpg\n",
      "./datasets/videos/test/9866_no_fish.mp4\n",
      "['9866', 'no', 'fish', 'f000086', 'jpg.rf.05880633adc902a9416d5182a4c31a5f.jpg']\n",
      "9866_no_fish f000086jpg.rf.05880633adc902a9416d5182a4c31a5f.jpg\n",
      "./datasets/videos/test/9866_no_fish.mp4\n",
      "['9866', 'no', 'fish', 'f000095', 'jpg.rf.2e445c6a18ca5e25e0569cafbd7d9c2c.jpg']\n",
      "9866_no_fish f000095jpg.rf.2e445c6a18ca5e25e0569cafbd7d9c2c.jpg\n",
      "./datasets/videos/test/9866_no_fish.mp4\n",
      "['9866', 'no', 'fish', 'f000097', 'jpg.rf.db6b8f374fc6ee9824a658e09240fa53.jpg']\n",
      "9866_no_fish f000097jpg.rf.db6b8f374fc6ee9824a658e09240fa53.jpg\n",
      "./datasets/videos/test/9866_no_fish.mp4\n",
      "['9866', 'no', 'fish', 'f000099', 'jpg.rf.90154e389a0e71886441ac310bae0380.jpg']\n",
      "9866_no_fish f000099jpg.rf.90154e389a0e71886441ac310bae0380.jpg\n",
      "./datasets/videos/test/9866_no_fish.mp4\n",
      "['9866', 'no', 'fish', 'f000114', 'jpg.rf.76a5a808de38f07f408896c7544e2e1f.jpg']\n",
      "9866_no_fish f000114jpg.rf.76a5a808de38f07f408896c7544e2e1f.jpg\n",
      "./datasets/videos/test/9866_no_fish.mp4\n",
      "['9866', 'no', 'fish', 'f000121', 'jpg.rf.06f661d4e645c401d370d024478bf8d3.jpg']\n",
      "9866_no_fish f000121jpg.rf.06f661d4e645c401d370d024478bf8d3.jpg\n",
      "./datasets/videos/test/9866_no_fish.mp4\n",
      "['9866', 'no', 'fish', 'f000137', 'jpg.rf.b9499cbdbe2194ed27d329cedcd64d62.jpg']\n",
      "9866_no_fish f000137jpg.rf.b9499cbdbe2194ed27d329cedcd64d62.jpg\n",
      "./datasets/videos/test/9866_no_fish.mp4\n",
      "['9866', 'no', 'fish', 'f000145', 'jpg.rf.78770f7c04c2850766b8f2f765f7a315.jpg']\n",
      "9866_no_fish f000145jpg.rf.78770f7c04c2850766b8f2f765f7a315.jpg\n",
      "./datasets/videos/test/9866_no_fish.mp4\n",
      "['9866', 'no', 'fish', 'f000149', 'jpg.rf.8b608baf20b12efa175caba3768487aa.jpg']\n",
      "9866_no_fish f000149jpg.rf.8b608baf20b12efa175caba3768487aa.jpg\n",
      "./datasets/videos/test/9866_no_fish.mp4\n",
      "['9866', 'no', 'fish', 'f000154', 'jpg.rf.a2cdc6c1812c9c30eaa6cbd697991eaa.jpg']\n",
      "9866_no_fish f000154jpg.rf.a2cdc6c1812c9c30eaa6cbd697991eaa.jpg\n",
      "./datasets/videos/test/9866_no_fish.mp4\n",
      "['9866', 'no', 'fish', 'f000155', 'jpg.rf.f12496ff3a4d1f5edb91b35049a7662b.jpg']\n",
      "9866_no_fish f000155jpg.rf.f12496ff3a4d1f5edb91b35049a7662b.jpg\n",
      "./datasets/videos/test/9866_no_fish.mp4\n",
      "['9866', 'no', 'fish', 'f000166', 'jpg.rf.9dc1a6c9db2dc760fd9335d4c9cb8771.jpg']\n",
      "9866_no_fish f000166jpg.rf.9dc1a6c9db2dc760fd9335d4c9cb8771.jpg\n",
      "./datasets/videos/test/9866_no_fish.mp4\n",
      "['9870', 'Gerres', 'f000022', 'jpg.rf.f603bff0eab11bba6d2217f9e2e7a178.jpg']\n",
      "9870_Gerres f000022jpg.rf.f603bff0eab11bba6d2217f9e2e7a178.jpg\n",
      "./datasets/videos/test/9870_Gerres.mp4\n",
      "Starting a new video for 9870_Gerres\n",
      "['9870', 'Gerres', 'f000023', 'jpg.rf.aa37ba0d78a9e112b8e33bc31f044404.jpg']\n",
      "9870_Gerres f000023jpg.rf.aa37ba0d78a9e112b8e33bc31f044404.jpg\n",
      "./datasets/videos/test/9870_Gerres.mp4\n",
      "['9870', 'Gerres', 'f000104', 'jpg.rf.07b12f94694e47448a5ec0bab25f0642.jpg']\n",
      "9870_Gerres f000104jpg.rf.07b12f94694e47448a5ec0bab25f0642.jpg\n",
      "./datasets/videos/test/9870_Gerres.mp4\n",
      "['9870', 'Gerres', 'f000119', 'jpg.rf.ede085ff8d4d93c9c25411ad6ed8d258.jpg']\n",
      "9870_Gerres f000119jpg.rf.ede085ff8d4d93c9c25411ad6ed8d258.jpg\n",
      "./datasets/videos/test/9870_Gerres.mp4\n",
      "['9870', 'Gerres', 'f000121', 'jpg.rf.896a28d0e5ff1d4c0e1f5cc396a85567.jpg']\n",
      "9870_Gerres f000121jpg.rf.896a28d0e5ff1d4c0e1f5cc396a85567.jpg\n",
      "./datasets/videos/test/9870_Gerres.mp4\n",
      "['9870', 'Gerres', 'f000127', 'jpg.rf.07eb7c660c7a624590884985f3aaf41e.jpg']\n",
      "9870_Gerres f000127jpg.rf.07eb7c660c7a624590884985f3aaf41e.jpg\n",
      "./datasets/videos/test/9870_Gerres.mp4\n",
      "['9870', 'Gerres', 'f000137', 'jpg.rf.4fdc0c06f9816a7b58f73b6a5e0704fb.jpg']\n",
      "9870_Gerres f000137jpg.rf.4fdc0c06f9816a7b58f73b6a5e0704fb.jpg\n",
      "./datasets/videos/test/9870_Gerres.mp4\n",
      "['9870', 'no', 'fish', 'f000045', 'jpg.rf.555c81cfde7d2cbac92637752ce1acc4.jpg']\n",
      "9870_no_fish f000045jpg.rf.555c81cfde7d2cbac92637752ce1acc4.jpg\n",
      "./datasets/videos/test/9870_no_fish.mp4\n",
      "Starting a new video for 9870_no_fish\n",
      "['9870', 'no', 'fish', 'f000046', 'jpg.rf.3fd5e4d19ed8a3ceabeb36056509830e.jpg']\n",
      "9870_no_fish f000046jpg.rf.3fd5e4d19ed8a3ceabeb36056509830e.jpg\n",
      "./datasets/videos/test/9870_no_fish.mp4\n",
      "['9870', 'no', 'fish', 'f000049', 'jpg.rf.a0e827ffd5021c0a751bd5dbe4290362.jpg']\n",
      "9870_no_fish f000049jpg.rf.a0e827ffd5021c0a751bd5dbe4290362.jpg\n",
      "./datasets/videos/test/9870_no_fish.mp4\n",
      "['9870', 'no', 'fish', 'f000050', 'jpg.rf.4766f72610580b54e7df22979aa0394f.jpg']\n",
      "9870_no_fish f000050jpg.rf.4766f72610580b54e7df22979aa0394f.jpg\n",
      "./datasets/videos/test/9870_no_fish.mp4\n",
      "['9892', 'Acanthopagrus', 'palmaris', '2', 'f000009', 'jpg.rf.53d0a089845cad2034ac4bb4d41ee3b3.jpg']\n",
      "9892_Acanthopagrus_palmaris_2 f000009jpg.rf.53d0a089845cad2034ac4bb4d41ee3b3.jpg\n",
      "./datasets/videos/test/9892_Acanthopagrus_palmaris_2.mp4\n",
      "Starting a new video for 9892_Acanthopagrus_palmaris_2\n",
      "['9892', 'Acanthopagrus', 'palmaris', '2', 'f000011', 'jpg.rf.974625dd8eaad06f27aa2709534085df.jpg']\n",
      "9892_Acanthopagrus_palmaris_2 f000011jpg.rf.974625dd8eaad06f27aa2709534085df.jpg\n",
      "./datasets/videos/test/9892_Acanthopagrus_palmaris_2.mp4\n",
      "['9892', 'Caranx', 'f000011', 'jpg.rf.014bfdfe593e1f41235c4d6009316817.jpg']\n",
      "9892_Caranx f000011jpg.rf.014bfdfe593e1f41235c4d6009316817.jpg\n",
      "./datasets/videos/test/9892_Caranx.mp4\n",
      "Starting a new video for 9892_Caranx\n",
      "['9892', 'Caranx', 'f000014', 'jpg.rf.91c0899b6c29552ad409b26ca6a170d3.jpg']\n",
      "9892_Caranx f000014jpg.rf.91c0899b6c29552ad409b26ca6a170d3.jpg\n",
      "./datasets/videos/test/9892_Caranx.mp4\n",
      "['9892', 'Caranx', 'f000015', 'jpg.rf.a56ddfd8ec7540c92ef9b56451597428.jpg']\n",
      "9892_Caranx f000015jpg.rf.a56ddfd8ec7540c92ef9b56451597428.jpg\n",
      "./datasets/videos/test/9892_Caranx.mp4\n",
      "['9892', 'Caranx', 'f000017', 'jpg.rf.98c9c62b8c9528d54bbf76deb86e89bc.jpg']\n",
      "9892_Caranx f000017jpg.rf.98c9c62b8c9528d54bbf76deb86e89bc.jpg\n",
      "./datasets/videos/test/9892_Caranx.mp4\n",
      "['9892', 'Caranx', 'f000037', 'jpg.rf.98fe5bf02b0b22dbb927ada696c5a970.jpg']\n",
      "9892_Caranx f000037jpg.rf.98fe5bf02b0b22dbb927ada696c5a970.jpg\n",
      "./datasets/videos/test/9892_Caranx.mp4\n",
      "['9892', 'acanthopagrus', 'palmaris', 'f000001', 'jpg.rf.a461403721ea042660a1d4bfd29b6fca.jpg']\n",
      "9892_acanthopagrus_palmaris f000001jpg.rf.a461403721ea042660a1d4bfd29b6fca.jpg\n",
      "./datasets/videos/test/9892_acanthopagrus_palmaris.mp4\n",
      "Starting a new video for 9892_acanthopagrus_palmaris\n",
      "['9892', 'acanthopagrus', 'palmaris', 'f000036', 'jpg.rf.d4b587c5f9b26167d9fd792d5906f8be.jpg']\n",
      "9892_acanthopagrus_palmaris f000036jpg.rf.d4b587c5f9b26167d9fd792d5906f8be.jpg\n",
      "./datasets/videos/test/9892_acanthopagrus_palmaris.mp4\n",
      "['9892', 'acanthopagrus', 'palmaris', 'f000053', 'jpg.rf.74c50ba4c1e693648c2f75e5fe7f3471.jpg']\n",
      "9892_acanthopagrus_palmaris f000053jpg.rf.74c50ba4c1e693648c2f75e5fe7f3471.jpg\n",
      "./datasets/videos/test/9892_acanthopagrus_palmaris.mp4\n",
      "['9892', 'acanthopagrus', 'palmaris', 'f000056', 'jpg.rf.d031f1c9433280417e3b3a22f18936c0.jpg']\n",
      "9892_acanthopagrus_palmaris f000056jpg.rf.d031f1c9433280417e3b3a22f18936c0.jpg\n",
      "./datasets/videos/test/9892_acanthopagrus_palmaris.mp4\n",
      "['9892', 'acanthopagrus', 'palmaris', 'f000061', 'jpg.rf.d8b96b6d03fa4fa7b45c6b4157a39500.jpg']\n",
      "9892_acanthopagrus_palmaris f000061jpg.rf.d8b96b6d03fa4fa7b45c6b4157a39500.jpg\n",
      "./datasets/videos/test/9892_acanthopagrus_palmaris.mp4\n",
      "['9892', 'no', 'fish', '2', 'f000000', 'jpg.rf.a9a468ba2815a28e9b9a69061770eca3.jpg']\n",
      "9892_no_fish_2 f000000jpg.rf.a9a468ba2815a28e9b9a69061770eca3.jpg\n",
      "./datasets/videos/test/9892_no_fish_2.mp4\n",
      "Starting a new video for 9892_no_fish_2\n",
      "['9892', 'no', 'fish', '2', 'f000007', 'jpg.rf.f78bf9097e17169a5c4a8b799a196efa.jpg']\n",
      "9892_no_fish_2 f000007jpg.rf.f78bf9097e17169a5c4a8b799a196efa.jpg\n",
      "./datasets/videos/test/9892_no_fish_2.mp4\n",
      "['9892', 'no', 'fish', '2', 'f000026', 'jpg.rf.d2a1db24e316c473e637e3d56c504b68.jpg']\n",
      "9892_no_fish_2 f000026jpg.rf.d2a1db24e316c473e637e3d56c504b68.jpg\n",
      "./datasets/videos/test/9892_no_fish_2.mp4\n",
      "['9892', 'no', 'fish', '2', 'f000027', 'jpg.rf.ed35b799f748b94bf9d434e8e867b49b.jpg']\n",
      "9892_no_fish_2 f000027jpg.rf.ed35b799f748b94bf9d434e8e867b49b.jpg\n",
      "./datasets/videos/test/9892_no_fish_2.mp4\n",
      "['9892', 'no', 'fish', '2', 'f000041', 'jpg.rf.a1415b54a87cb96a7956e2f803635667.jpg']\n",
      "9892_no_fish_2 f000041jpg.rf.a1415b54a87cb96a7956e2f803635667.jpg\n",
      "./datasets/videos/test/9892_no_fish_2.mp4\n",
      "['9892', 'no', 'fish', '2', 'f000044', 'jpg.rf.fe2f7f4d8a38dc3346f8733ac7df1408.jpg']\n",
      "9892_no_fish_2 f000044jpg.rf.fe2f7f4d8a38dc3346f8733ac7df1408.jpg\n",
      "./datasets/videos/test/9892_no_fish_2.mp4\n",
      "['9892', 'no', 'fish', '2', 'f000046', 'jpg.rf.e589afd78d9bb7446f12086051e4cc08.jpg']\n",
      "9892_no_fish_2 f000046jpg.rf.e589afd78d9bb7446f12086051e4cc08.jpg\n",
      "./datasets/videos/test/9892_no_fish_2.mp4\n",
      "['9892', 'no', 'fish', '2', 'f000053', 'jpg.rf.260801e312ac5958df79b9fa06f6f365.jpg']\n",
      "9892_no_fish_2 f000053jpg.rf.260801e312ac5958df79b9fa06f6f365.jpg\n",
      "./datasets/videos/test/9892_no_fish_2.mp4\n",
      "['9892', 'no', 'fish', '2', 'f000065', 'jpg.rf.f25de10ed4c5e258dcf61ca309c6c2c1.jpg']\n",
      "9892_no_fish_2 f000065jpg.rf.f25de10ed4c5e258dcf61ca309c6c2c1.jpg\n",
      "./datasets/videos/test/9892_no_fish_2.mp4\n",
      "['9894', 'Amniataba', 'caudivittatus', 'f000002', 'jpg.rf.4ed45c0d3464bc0427c7160da2a0a3a4.jpg']\n",
      "9894_Amniataba_caudivittatus f000002jpg.rf.4ed45c0d3464bc0427c7160da2a0a3a4.jpg\n",
      "./datasets/videos/test/9894_Amniataba_caudivittatus.mp4\n",
      "Starting a new video for 9894_Amniataba_caudivittatus\n",
      "['9894', 'Amniataba', 'caudivittatus', 'f000020', 'jpg.rf.c84e2cdbf9c255564f096d3502b6d819.jpg']\n",
      "9894_Amniataba_caudivittatus f000020jpg.rf.c84e2cdbf9c255564f096d3502b6d819.jpg\n",
      "./datasets/videos/test/9894_Amniataba_caudivittatus.mp4\n",
      "['9894', 'Amniataba', 'caudivittatus', 'f000021', 'jpg.rf.6feca5c3c104603cd987878bb5055178.jpg']\n",
      "9894_Amniataba_caudivittatus f000021jpg.rf.6feca5c3c104603cd987878bb5055178.jpg\n",
      "./datasets/videos/test/9894_Amniataba_caudivittatus.mp4\n",
      "['9894', 'Amniataba', 'caudivittatus', 'f000031', 'jpg.rf.b1617900ffdd8d45f8482e1c47895b3d.jpg']\n",
      "9894_Amniataba_caudivittatus f000031jpg.rf.b1617900ffdd8d45f8482e1c47895b3d.jpg\n",
      "./datasets/videos/test/9894_Amniataba_caudivittatus.mp4\n",
      "['9894', 'Amniataba', 'caudivittatus', 'f000037', 'jpg.rf.317d7839b481b1a3a74f7888cdd4677e.jpg']\n",
      "9894_Amniataba_caudivittatus f000037jpg.rf.317d7839b481b1a3a74f7888cdd4677e.jpg\n",
      "./datasets/videos/test/9894_Amniataba_caudivittatus.mp4\n",
      "['9894', 'gerres', '2', 'f000000', 'jpg.rf.b9a2d01911bd5dcc8e3bc0b21378bc3e.jpg']\n",
      "9894_gerres_2 f000000jpg.rf.b9a2d01911bd5dcc8e3bc0b21378bc3e.jpg\n",
      "./datasets/videos/test/9894_gerres_2.mp4\n",
      "Starting a new video for 9894_gerres_2\n",
      "['9894', 'gerres', '2', 'f000005', 'jpg.rf.2d3623485126e6b3da308577e5b23ce6.jpg']\n",
      "9894_gerres_2 f000005jpg.rf.2d3623485126e6b3da308577e5b23ce6.jpg\n",
      "./datasets/videos/test/9894_gerres_2.mp4\n",
      "['9894', 'gerres', '2', 'f000008', 'jpg.rf.7d28220877160d764944b6475fcb4b35.jpg']\n",
      "9894_gerres_2 f000008jpg.rf.7d28220877160d764944b6475fcb4b35.jpg\n",
      "./datasets/videos/test/9894_gerres_2.mp4\n",
      "['9894', 'gerres', '2', 'f000015', 'jpg.rf.898317b0313b5d72aed781b3976a413a.jpg']\n",
      "9894_gerres_2 f000015jpg.rf.898317b0313b5d72aed781b3976a413a.jpg\n",
      "./datasets/videos/test/9894_gerres_2.mp4\n",
      "['9894', 'gerres', '2', 'f000027', 'jpg.rf.d3903199d2bfc4ceae247d7ce1ca099e.jpg']\n",
      "9894_gerres_2 f000027jpg.rf.d3903199d2bfc4ceae247d7ce1ca099e.jpg\n",
      "./datasets/videos/test/9894_gerres_2.mp4\n",
      "['9894', 'gerres', '2', 'f000030', 'jpg.rf.716ed0c76c5be964a41e4599178bfd46.jpg']\n",
      "9894_gerres_2 f000030jpg.rf.716ed0c76c5be964a41e4599178bfd46.jpg\n",
      "./datasets/videos/test/9894_gerres_2.mp4\n",
      "['9894', 'gerres', '2', 'f000035', 'jpg.rf.a0d008b61b82d5df0f5b5f4452511d4f.jpg']\n",
      "9894_gerres_2 f000035jpg.rf.a0d008b61b82d5df0f5b5f4452511d4f.jpg\n",
      "./datasets/videos/test/9894_gerres_2.mp4\n",
      "['9894', 'gerres', '2', 'f000055', 'jpg.rf.3e2339cd079557835afd44d4f50bb541.jpg']\n",
      "9894_gerres_2 f000055jpg.rf.3e2339cd079557835afd44d4f50bb541.jpg\n",
      "./datasets/videos/test/9894_gerres_2.mp4\n",
      "['9894', 'gerres', 'f000007', 'jpg.rf.c82722eb128aff24806e0ecf99f94b8d.jpg']\n",
      "9894_gerres f000007jpg.rf.c82722eb128aff24806e0ecf99f94b8d.jpg\n",
      "./datasets/videos/test/9894_gerres.mp4\n",
      "Starting a new video for 9894_gerres\n",
      "['9894', 'gerres', 'f000022', 'jpg.rf.9715e889cf47269baf81f7d8ca3e70e4.jpg']\n",
      "9894_gerres f000022jpg.rf.9715e889cf47269baf81f7d8ca3e70e4.jpg\n",
      "./datasets/videos/test/9894_gerres.mp4\n",
      "['9894', 'gerres', 'f000032', 'jpg.rf.98224b1ec553c868f87b6e8049f2a139.jpg']\n",
      "9894_gerres f000032jpg.rf.98224b1ec553c868f87b6e8049f2a139.jpg\n",
      "./datasets/videos/test/9894_gerres.mp4\n",
      "['9894', 'gerres', 'f000037', 'jpg.rf.df874889157e14f956a27fb7fff64fa5.jpg']\n",
      "9894_gerres f000037jpg.rf.df874889157e14f956a27fb7fff64fa5.jpg\n",
      "./datasets/videos/test/9894_gerres.mp4\n",
      "['9894', 'no', 'fish', '2', 'f000002', 'jpg.rf.549cdf7bb125df6a6f0c064106a8d26e.jpg']\n",
      "9894_no_fish_2 f000002jpg.rf.549cdf7bb125df6a6f0c064106a8d26e.jpg\n",
      "./datasets/videos/test/9894_no_fish_2.mp4\n",
      "Starting a new video for 9894_no_fish_2\n",
      "['9894', 'no', 'fish', '2', 'f000010', 'jpg.rf.3333811ed453bffd0d797bffa377aba1.jpg']\n",
      "9894_no_fish_2 f000010jpg.rf.3333811ed453bffd0d797bffa377aba1.jpg\n",
      "./datasets/videos/test/9894_no_fish_2.mp4\n",
      "['9894', 'no', 'fish', '2', 'f000024', 'jpg.rf.d67ac56d1ef21d93a938b278026e9bfb.jpg']\n",
      "9894_no_fish_2 f000024jpg.rf.d67ac56d1ef21d93a938b278026e9bfb.jpg\n",
      "./datasets/videos/test/9894_no_fish_2.mp4\n",
      "['9894', 'no', 'fish', '2', 'f000025', 'jpg.rf.db1ac873ce4a8eab17f5854b344686b1.jpg']\n",
      "9894_no_fish_2 f000025jpg.rf.db1ac873ce4a8eab17f5854b344686b1.jpg\n",
      "./datasets/videos/test/9894_no_fish_2.mp4\n",
      "['9894', 'no', 'fish', '2', 'f000037', 'jpg.rf.1a517ffb7b2939ca5f0e4978e77af395.jpg']\n",
      "9894_no_fish_2 f000037jpg.rf.1a517ffb7b2939ca5f0e4978e77af395.jpg\n",
      "./datasets/videos/test/9894_no_fish_2.mp4\n",
      "['9894', 'no', 'fish', '2', 'f000060', 'jpg.rf.d028863bd2c2523526d6fcb1eae18a87.jpg']\n",
      "9894_no_fish_2 f000060jpg.rf.d028863bd2c2523526d6fcb1eae18a87.jpg\n",
      "./datasets/videos/test/9894_no_fish_2.mp4\n",
      "['9894', 'no', 'fish', '2', 'f000071', 'jpg.rf.d6241052e84d05d3ccf84c78668c1a76.jpg']\n",
      "9894_no_fish_2 f000071jpg.rf.d6241052e84d05d3ccf84c78668c1a76.jpg\n",
      "./datasets/videos/test/9894_no_fish_2.mp4\n",
      "['9898', 'Acanthopagrus', 'palmaris', 'f000032', 'jpg.rf.ad7c632ef9476ae5d9d2b82457ec252d.jpg']\n",
      "9898_Acanthopagrus_palmaris f000032jpg.rf.ad7c632ef9476ae5d9d2b82457ec252d.jpg\n",
      "./datasets/videos/test/9898_Acanthopagrus_palmaris.mp4\n",
      "Starting a new video for 9898_Acanthopagrus_palmaris\n",
      "['9898', 'Acanthopagrus', 'palmaris', 'f000041', 'jpg.rf.690cf2c012d7fc830fb6468e70c068d4.jpg']\n",
      "9898_Acanthopagrus_palmaris f000041jpg.rf.690cf2c012d7fc830fb6468e70c068d4.jpg\n",
      "./datasets/videos/test/9898_Acanthopagrus_palmaris.mp4\n",
      "['9898', 'Acanthopagrus', 'palmaris', 'f000046', 'jpg.rf.87fc9f2cca7168d62910603d8f7e3985.jpg']\n",
      "9898_Acanthopagrus_palmaris f000046jpg.rf.87fc9f2cca7168d62910603d8f7e3985.jpg\n",
      "./datasets/videos/test/9898_Acanthopagrus_palmaris.mp4\n",
      "['9898', 'Acanthopagrus', 'palmaris', 'f000054', 'jpg.rf.238b77158c466d32ad2c082edea84d04.jpg']\n",
      "9898_Acanthopagrus_palmaris f000054jpg.rf.238b77158c466d32ad2c082edea84d04.jpg\n",
      "./datasets/videos/test/9898_Acanthopagrus_palmaris.mp4\n",
      "['9898', 'Acanthopagrus', 'palmaris', 'f000066', 'jpg.rf.1957fc1db09b3e58de2352b670c93042.jpg']\n",
      "9898_Acanthopagrus_palmaris f000066jpg.rf.1957fc1db09b3e58de2352b670c93042.jpg\n",
      "./datasets/videos/test/9898_Acanthopagrus_palmaris.mp4\n",
      "['9898', 'Acanthopagrus', 'palmaris', 'f000068', 'jpg.rf.de3fcdc0277ccc8e945c18cbe40fe071.jpg']\n",
      "9898_Acanthopagrus_palmaris f000068jpg.rf.de3fcdc0277ccc8e945c18cbe40fe071.jpg\n",
      "./datasets/videos/test/9898_Acanthopagrus_palmaris.mp4\n",
      "['9898', 'Acanthopagrus', 'palmaris', 'f000078', 'jpg.rf.7b0659e9aa056165b24acb1931405bb2.jpg']\n",
      "9898_Acanthopagrus_palmaris f000078jpg.rf.7b0659e9aa056165b24acb1931405bb2.jpg\n",
      "./datasets/videos/test/9898_Acanthopagrus_palmaris.mp4\n",
      "['9898', 'Acanthopagrus', 'palmaris', 'f000079', 'jpg.rf.6b9aadb9bab4f33fe46f2700246a8ae4.jpg']\n",
      "9898_Acanthopagrus_palmaris f000079jpg.rf.6b9aadb9bab4f33fe46f2700246a8ae4.jpg\n",
      "./datasets/videos/test/9898_Acanthopagrus_palmaris.mp4\n",
      "['9898', 'Acanthopagrus', 'palmaris', 'f000081', 'jpg.rf.65ddfae0476009f3b6a8bade7e9d7347.jpg']\n",
      "9898_Acanthopagrus_palmaris f000081jpg.rf.65ddfae0476009f3b6a8bade7e9d7347.jpg\n",
      "./datasets/videos/test/9898_Acanthopagrus_palmaris.mp4\n",
      "['9898', 'Acanthopagrus', 'palmaris', 'f000084', 'jpg.rf.d11dfaa6016dadc2fa93c540e9efa807.jpg']\n",
      "9898_Acanthopagrus_palmaris f000084jpg.rf.d11dfaa6016dadc2fa93c540e9efa807.jpg\n",
      "./datasets/videos/test/9898_Acanthopagrus_palmaris.mp4\n",
      "['9898', 'Acanthopagrus', 'palmaris', 'f000086', 'jpg.rf.edb58ae625886c88e9207828d149655e.jpg']\n",
      "9898_Acanthopagrus_palmaris f000086jpg.rf.edb58ae625886c88e9207828d149655e.jpg\n",
      "./datasets/videos/test/9898_Acanthopagrus_palmaris.mp4\n",
      "['9898', 'no', 'fish', 'f000001', 'jpg.rf.129a2aef1d582e67dd26a2e20a38e4d1.jpg']\n",
      "9898_no_fish f000001jpg.rf.129a2aef1d582e67dd26a2e20a38e4d1.jpg\n",
      "./datasets/videos/test/9898_no_fish.mp4\n",
      "Starting a new video for 9898_no_fish\n",
      "['9898', 'no', 'fish', 'f000004', 'jpg.rf.528a0978ed7e68180ffc48e2ef2373fc.jpg']\n",
      "9898_no_fish f000004jpg.rf.528a0978ed7e68180ffc48e2ef2373fc.jpg\n",
      "./datasets/videos/test/9898_no_fish.mp4\n",
      "['9898', 'no', 'fish', 'f000016', 'jpg.rf.20390a147c0fd17831db374984fceb50.jpg']\n",
      "9898_no_fish f000016jpg.rf.20390a147c0fd17831db374984fceb50.jpg\n",
      "./datasets/videos/test/9898_no_fish.mp4\n",
      "['9898', 'no', 'fish', 'f000019', 'jpg.rf.3cf3ebb0d882bfd4d4b979c5e819a7bc.jpg']\n",
      "9898_no_fish f000019jpg.rf.3cf3ebb0d882bfd4d4b979c5e819a7bc.jpg\n",
      "./datasets/videos/test/9898_no_fish.mp4\n",
      "['9898', 'no', 'fish', 'f000020', 'jpg.rf.645cfd29784ee285036ff283dd16a732.jpg']\n",
      "9898_no_fish f000020jpg.rf.645cfd29784ee285036ff283dd16a732.jpg\n",
      "./datasets/videos/test/9898_no_fish.mp4\n",
      "['9898', 'no', 'fish', 'f000035', 'jpg.rf.2ec418fc5bed45e6a2cb26c9990cd114.jpg']\n",
      "9898_no_fish f000035jpg.rf.2ec418fc5bed45e6a2cb26c9990cd114.jpg\n",
      "./datasets/videos/test/9898_no_fish.mp4\n",
      "['9898', 'no', 'fish', 'f000040', 'jpg.rf.c1abea16606b01ebc116f699231f4156.jpg']\n",
      "9898_no_fish f000040jpg.rf.c1abea16606b01ebc116f699231f4156.jpg\n",
      "./datasets/videos/test/9898_no_fish.mp4\n",
      "['9907', 'acanthopagrus', 'palmaris', 'f000117', 'jpg.rf.b96f90565a7d626ed01168083200de78.jpg']\n",
      "9907_acanthopagrus_palmaris f000117jpg.rf.b96f90565a7d626ed01168083200de78.jpg\n",
      "./datasets/videos/test/9907_acanthopagrus_palmaris.mp4\n",
      "Starting a new video for 9907_acanthopagrus_palmaris\n",
      "['9907', 'acanthopagrus', 'palmaris', 'f000129', 'jpg.rf.c7ea049abc1812222de90f581aac72a6.jpg']\n",
      "9907_acanthopagrus_palmaris f000129jpg.rf.c7ea049abc1812222de90f581aac72a6.jpg\n",
      "./datasets/videos/test/9907_acanthopagrus_palmaris.mp4\n",
      "['9907', 'acanthopagrus', 'palmaris', 'f000242', 'jpg.rf.02a63ce2ac3e61a6554d975aa9bba5f7.jpg']\n",
      "9907_acanthopagrus_palmaris f000242jpg.rf.02a63ce2ac3e61a6554d975aa9bba5f7.jpg\n",
      "./datasets/videos/test/9907_acanthopagrus_palmaris.mp4\n",
      "['9907', 'acanthopagrus', 'palmaris', 'f000255', 'jpg.rf.6a69b8965d99857aa6ca1c69328c4a51.jpg']\n",
      "9907_acanthopagrus_palmaris f000255jpg.rf.6a69b8965d99857aa6ca1c69328c4a51.jpg\n",
      "./datasets/videos/test/9907_acanthopagrus_palmaris.mp4\n",
      "['9907', 'acanthopagrus', 'palmaris', 'f000267', 'jpg.rf.80bf54b2f9ab1f94d9ed23c890d748cb.jpg']\n",
      "9907_acanthopagrus_palmaris f000267jpg.rf.80bf54b2f9ab1f94d9ed23c890d748cb.jpg\n",
      "./datasets/videos/test/9907_acanthopagrus_palmaris.mp4\n",
      "['9907', 'acanthopagrus', 'palmaris', 'f000269', 'jpg.rf.4a4177f07919ebcebd58863dff9f263b.jpg']\n",
      "9907_acanthopagrus_palmaris f000269jpg.rf.4a4177f07919ebcebd58863dff9f263b.jpg\n",
      "./datasets/videos/test/9907_acanthopagrus_palmaris.mp4\n",
      "['9907', 'acanthopagrus', 'palmaris', 'f000304', 'jpg.rf.bf4c897b1a80622fa04fb0f87f949bb3.jpg']\n",
      "9907_acanthopagrus_palmaris f000304jpg.rf.bf4c897b1a80622fa04fb0f87f949bb3.jpg\n",
      "./datasets/videos/test/9907_acanthopagrus_palmaris.mp4\n",
      "['9907', 'acanthopagrus', 'palmaris', 'f000312', 'jpg.rf.7f6200c0b6f47cd857b7f5d821ea5650.jpg']\n",
      "9907_acanthopagrus_palmaris f000312jpg.rf.7f6200c0b6f47cd857b7f5d821ea5650.jpg\n",
      "./datasets/videos/test/9907_acanthopagrus_palmaris.mp4\n",
      "['9907', 'acanthopagrus', 'palmaris', 'f000336', 'jpg.rf.3490efd53624d07fce092b781ec2e67d.jpg']\n",
      "9907_acanthopagrus_palmaris f000336jpg.rf.3490efd53624d07fce092b781ec2e67d.jpg\n",
      "./datasets/videos/test/9907_acanthopagrus_palmaris.mp4\n",
      "['9907', 'acanthopagrus', 'palmaris', 'f000343', 'jpg.rf.a282885c1853bd0e332725da1b3f09e0.jpg']\n",
      "9907_acanthopagrus_palmaris f000343jpg.rf.a282885c1853bd0e332725da1b3f09e0.jpg\n",
      "./datasets/videos/test/9907_acanthopagrus_palmaris.mp4\n",
      "['9907', 'acanthopagrus', 'palmaris', 'f000386', 'jpg.rf.053e3c47c76fbf95f1524eaf5287efb7.jpg']\n",
      "9907_acanthopagrus_palmaris f000386jpg.rf.053e3c47c76fbf95f1524eaf5287efb7.jpg\n",
      "./datasets/videos/test/9907_acanthopagrus_palmaris.mp4\n",
      "['9907', 'no', 'fish', '2', 'f000025', 'jpg.rf.2ef15d6c98c1e2b73595cae4cc3c2292.jpg']\n",
      "9907_no_fish_2 f000025jpg.rf.2ef15d6c98c1e2b73595cae4cc3c2292.jpg\n",
      "./datasets/videos/test/9907_no_fish_2.mp4\n",
      "Starting a new video for 9907_no_fish_2\n",
      "['9907', 'no', 'fish', '2', 'f000053', 'jpg.rf.7c6eeb01670cb06d5b5f520ddde61b23.jpg']\n",
      "9907_no_fish_2 f000053jpg.rf.7c6eeb01670cb06d5b5f520ddde61b23.jpg\n",
      "./datasets/videos/test/9907_no_fish_2.mp4\n",
      "['9907', 'no', 'fish', '2', 'f000075', 'jpg.rf.12be49395f822488d4e10e78104e6f4c.jpg']\n",
      "9907_no_fish_2 f000075jpg.rf.12be49395f822488d4e10e78104e6f4c.jpg\n",
      "./datasets/videos/test/9907_no_fish_2.mp4\n",
      "['9907', 'no', 'fish', '2', 'f000081', 'jpg.rf.cae17d52f75c1be4e406dedd21bdf179.jpg']\n",
      "9907_no_fish_2 f000081jpg.rf.cae17d52f75c1be4e406dedd21bdf179.jpg\n",
      "./datasets/videos/test/9907_no_fish_2.mp4\n",
      "['9907', 'no', 'fish', '2', 'f000083', 'jpg.rf.3e29ec71cd3d02031500dc6c42b9cc19.jpg']\n",
      "9907_no_fish_2 f000083jpg.rf.3e29ec71cd3d02031500dc6c42b9cc19.jpg\n",
      "./datasets/videos/test/9907_no_fish_2.mp4\n",
      "['9908', 'Acanthopagrus', 'palmaris', 'f000001', 'jpg.rf.a2bdf58416968a33f18abaaf71871368.jpg']\n",
      "9908_Acanthopagrus_palmaris f000001jpg.rf.a2bdf58416968a33f18abaaf71871368.jpg\n",
      "./datasets/videos/test/9908_Acanthopagrus_palmaris.mp4\n",
      "Starting a new video for 9908_Acanthopagrus_palmaris\n",
      "['9908', 'Acanthopagrus', 'palmaris', 'f000005', 'jpg.rf.ee2c618a1b9c61cc72c65916a056ba3b.jpg']\n",
      "9908_Acanthopagrus_palmaris f000005jpg.rf.ee2c618a1b9c61cc72c65916a056ba3b.jpg\n",
      "./datasets/videos/test/9908_Acanthopagrus_palmaris.mp4\n",
      "['9908', 'Acanthopagrus', 'palmaris', 'f000057', 'jpg.rf.accecf4d89950388dc30741725dbc417.jpg']\n",
      "9908_Acanthopagrus_palmaris f000057jpg.rf.accecf4d89950388dc30741725dbc417.jpg\n",
      "./datasets/videos/test/9908_Acanthopagrus_palmaris.mp4\n",
      "['9908', 'Acanthopagrus', 'palmaris', 'f000075', 'jpg.rf.53efbc8b53132de0f8d126d9aae3b651.jpg']\n",
      "9908_Acanthopagrus_palmaris f000075jpg.rf.53efbc8b53132de0f8d126d9aae3b651.jpg\n",
      "./datasets/videos/test/9908_Acanthopagrus_palmaris.mp4\n",
      "['9908', 'Epinephelus', 'f000011', 'jpg.rf.9872537a9d9913794b0eeea31a122c10.jpg']\n",
      "9908_Epinephelus f000011jpg.rf.9872537a9d9913794b0eeea31a122c10.jpg\n",
      "./datasets/videos/test/9908_Epinephelus.mp4\n",
      "Starting a new video for 9908_Epinephelus\n",
      "['9908', 'Epinephelus', 'f000047', 'jpg.rf.508ebf5fe5469faca6a61561ca8c1075.jpg']\n",
      "9908_Epinephelus f000047jpg.rf.508ebf5fe5469faca6a61561ca8c1075.jpg\n",
      "./datasets/videos/test/9908_Epinephelus.mp4\n",
      "['9908', 'no', 'fish', '2', 'f000007', 'jpg.rf.a2150414d834a15d344697ea0928618c.jpg']\n",
      "9908_no_fish_2 f000007jpg.rf.a2150414d834a15d344697ea0928618c.jpg\n",
      "./datasets/videos/test/9908_no_fish_2.mp4\n",
      "Starting a new video for 9908_no_fish_2\n",
      "['9908', 'no', 'fish', '2', 'f000011', 'jpg.rf.0a112e4d4c948ed1720636f9ce066406.jpg']\n",
      "9908_no_fish_2 f000011jpg.rf.0a112e4d4c948ed1720636f9ce066406.jpg\n",
      "./datasets/videos/test/9908_no_fish_2.mp4\n",
      "['9908', 'no', 'fish', '2', 'f000033', 'jpg.rf.b6760aeb7c40832a72f7cf443010575a.jpg']\n",
      "9908_no_fish_2 f000033jpg.rf.b6760aeb7c40832a72f7cf443010575a.jpg\n",
      "./datasets/videos/test/9908_no_fish_2.mp4\n",
      "['9908', 'no', 'fish', '2', 'f000040', 'jpg.rf.28ec7d4260aff86a586f9a3745e89ca5.jpg']\n",
      "9908_no_fish_2 f000040jpg.rf.28ec7d4260aff86a586f9a3745e89ca5.jpg\n",
      "./datasets/videos/test/9908_no_fish_2.mp4\n"
     ]
    }
   ],
   "source": [
    "def to_mp4(img_folder: str, video_base_path: str) -> None:\n",
    "    \"\"\"\n",
    "    Converts a series of images in alphabetical order to a .mp4 video.\n",
    "    Based on code from https://stackoverflow.com/questions/44947505/how-to-make-a-movie-out-of-images-in-python\n",
    "\n",
    "    @img_folder: Path to the folder containing the .jpg images to be concatenated. \n",
    "    @video_path:\n",
    "    \"\"\"\n",
    "    images = [img for img in os.listdir(img_folder) if img.endswith(\".jpg\")]\n",
    "    images.sort()\n",
    "    frame = cv2.imread(os.path.join(img_folder, images[0]))\n",
    "    height, width, layers = frame.shape\n",
    "    \n",
    "    video = None\n",
    "    prev_key = None\n",
    "\n",
    "    os.makedirs(video_base_path)\n",
    "    \n",
    "    for img in images:\n",
    "        # The frames are being grouped together based on the image name.\n",
    "        # Basically anything before the `_f\\d\\d\\d\\d\\d\\d_jpg...` is being used as the key to group.\n",
    "        parts = img.split('_')\n",
    "        key = '_'.join(parts[0:-2])\n",
    "        fnumber_and_hash = ''.join(parts[-2:])\n",
    "        print(parts)\n",
    "        print(key, fnumber_and_hash)\n",
    "        video_path = os.path.join(video_base_path, key)\n",
    "        video_path += '.mp4'\n",
    "        print(video_path)\n",
    "        if not video or prev_key != key:  # Start a new video\n",
    "            print(f'Starting a new video for {key}')\n",
    "            video = cv2.VideoWriter(video_path, cv2.VideoWriter_fourcc(*\"mp4v\"), 1, (width, height))\n",
    "        prev_key = key\n",
    "        video.write(cv2.imread(os.path.join(img_folder, img)))\n",
    "    \n",
    "    cv2.destroyAllWindows()\n",
    "    video.release()    \n",
    "\n",
    "to_mp4(img_folder='./datasets/images/test/', video_base_path='./datasets/videos/test/')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e8e74dd-2e96-486e-8239-f8d7dc12777f",
   "metadata": {},
   "source": [
    "## Drawing boxes around figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0411dbfd-aaf0-458f-a0cf-edecdd70160e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mv datasets/fish4knowledge/test/images datasets/images/train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3e6512a0-59d4-43f6-acf5-fb2f2caaa83b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.2.89 üöÄ Python-3.11.2 torch-2.4.1+cu121 CUDA:0 (NVIDIA GeForce RTX 4060 Laptop GPU, 7943MiB)\n",
      "Model summary (fused): 168 layers, 3,005,843 parameters, 0 gradients, 8.1 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/dionisius/bdma/tue/data_challenge_3/deepfish-detection/datas\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING ‚ö†Ô∏è /home/dionisius/bdma/tue/data_challenge_3/deepfish-detection/datasets/images/val/9894_gerres_f000034_jpg.rf.077f365f7e09097b1627e75c4d237a57.jpg: 1 duplicate labels removed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1304       3033      0.931      0.918      0.958      0.594\n",
      "Speed: 0.3ms preprocess, 3.2ms inference, 0.0ms loss, 0.3ms postprocess per image\n",
      "Results saved to \u001b[1m/home/dionisius/bdma/tue/data_challenge_3/deepfish-detection/runs/detect/val3\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "model = YOLO(\"runs/detect/combined/weights/best.pt\")\n",
    "results = model.val(data='data.yaml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "240c1ef3-0b83-4b91-8d6c-c4e7ebb6a9d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.2.89 üöÄ Python-3.11.2 torch-2.4.1+cu121 CUDA:0 (NVIDIA GeForce RTX 4060 Laptop GPU, 7943MiB)\n",
      "Model summary (fused): 168 layers, 3,005,843 parameters, 0 gradients, 8.1 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/dionisius/bdma/tue/data_challenge_3/deepfish-detection/datas\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING ‚ö†Ô∏è /home/dionisius/bdma/tue/data_challenge_3/deepfish-detection/datasets/images/val/9894_gerres_f000034_jpg.rf.077f365f7e09097b1627e75c4d237a57.jpg: 1 duplicate labels removed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1304       3033      0.931      0.918      0.958      0.594\n",
      "Speed: 0.3ms preprocess, 3.2ms inference, 0.0ms loss, 0.3ms postprocess per image\n",
      "Results saved to \u001b[1m/home/dionisius/bdma/tue/data_challenge_3/deepfish-detection/runs/detect/val4\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "model = YOLO(\"runs/detect/combined/weights/best.pt\")\n",
    "results = model.val(data='data.yaml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e4d80774-4af3-4ecf-bb3a-0edfdd6d2973",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mv datasets/images/train datasets/fish4knowledge/test/images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8409424b-e25b-46dc-b299-ea6156b69cb0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING ‚ö†Ô∏è imgsz=[360, 202] must be multiple of max stride 32, updating to [384, 224]\n",
      "image 1/1 /home/dionisius/bdma/tue/data_challenge_3/deepfish-detection/datasets/fish4knowledge/test/images/4_png.rf.320329a34f9c595bb8cdd668384ce15e.jpg: 128x224 1 Fish, 2.8ms\n",
      "Speed: 8.2ms preprocess, 2.8ms inference, 0.7ms postprocess per image at shape (1, 3, 128, 224)\n",
      "Results saved to \u001b[1m/home/dionisius/bdma/tue/data_challenge_3/deepfish-detection/runs/detect/predict\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'Fish'}\n",
       " obb: None\n",
       " orig_img: array([[[  0,   0,   1],\n",
       "         [  6,   8,   9],\n",
       "         [  0,   0,   1],\n",
       "         ...,\n",
       "         [ 15,   0,   9],\n",
       "         [ 14,   0,   9],\n",
       "         [ 14,   0,   9]],\n",
       " \n",
       "        [[  6,   8,   9],\n",
       "         [  0,   0,   0],\n",
       "         [235, 237, 238],\n",
       "         ...,\n",
       "         [  7,   0,   1],\n",
       "         [  7,   0,   1],\n",
       "         [  5,   0,   1]],\n",
       " \n",
       "        [[  0,   0,   0],\n",
       "         [103, 104, 102],\n",
       "         [208, 208, 208],\n",
       "         ...,\n",
       "         [  0,   9,   0],\n",
       "         [  0,   9,   0],\n",
       "         [  1,  10,   0]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 48,  46,  35],\n",
       "         [ 48,  46,  35],\n",
       "         [ 48,  46,  35],\n",
       "         ...,\n",
       "         [ 51,  51,  39],\n",
       "         [ 53,  53,  41],\n",
       "         [ 53,  53,  41]],\n",
       " \n",
       "        [[ 49,  47,  36],\n",
       "         [ 49,  47,  36],\n",
       "         [ 49,  47,  36],\n",
       "         ...,\n",
       "         [ 50,  50,  38],\n",
       "         [ 50,  50,  38],\n",
       "         [ 50,  50,  38]],\n",
       " \n",
       "        [[ 49,  47,  36],\n",
       "         [ 49,  47,  36],\n",
       "         [ 49,  47,  36],\n",
       "         ...,\n",
       "         [ 50,  50,  38],\n",
       "         [ 50,  50,  38],\n",
       "         [ 50,  50,  38]]], dtype=uint8)\n",
       " orig_shape: (202, 360)\n",
       " path: '/home/dionisius/bdma/tue/data_challenge_3/deepfish-detection/datasets/fish4knowledge/test/images/4_png.rf.320329a34f9c595bb8cdd668384ce15e.jpg'\n",
       " probs: None\n",
       " save_dir: '/home/dionisius/bdma/tue/data_challenge_3/deepfish-detection/runs/detect/predict'\n",
       " speed: {'preprocess': 8.16655158996582, 'inference': 2.768993377685547, 'postprocess': 0.6732940673828125}]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model.predict()\n",
    "model.predict(\"./datasets/fish4knowledge/test/images/4_png.rf.320329a34f9c595bb8cdd668384ce15e.jpg\", save=True, imgsz=(360, 202), conf=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "757ae02d-4ff7-419a-b870-d5fb4cfe418b",
   "metadata": {},
   "source": [
    "## Computing test metric over Fish4Knowledge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "643f168b-d301-4de3-9f32-da907242547a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mv datasets/fish4knowledge/valid/images datasets/images/val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "aec3c763-bc6d-4e5b-aa2c-b1ca693c00e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.2.89 üöÄ Python-3.11.2 torch-2.4.1+cu121 CUDA:0 (NVIDIA GeForce RTX 4060 Laptop GPU, 7943MiB)\n",
      "Model summary (fused): 168 layers, 3,005,843 parameters, 0 gradients, 8.1 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/dionisius/bdma/tue/data_challenge_3/deepfish-detection/datas\u001b[0m\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        645       1395      0.929      0.877      0.938      0.574\n",
      "Speed: 0.4ms preprocess, 3.1ms inference, 0.0ms loss, 0.5ms postprocess per image\n",
      "Results saved to \u001b[1m/home/dionisius/bdma/tue/data_challenge_3/deepfish-detection/runs/detect/val12\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "model = YOLO(\"runs/detect/original/weights/best.pt\")\n",
    "results = model.val(data='data.yaml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36f89adb-5706-4eec-8e8c-0f05c63412a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mv datasets/images/val datasets/fish4knowledge/valid/images"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
